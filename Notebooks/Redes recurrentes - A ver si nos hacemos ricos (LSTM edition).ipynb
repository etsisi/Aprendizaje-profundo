{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div><img style=\"float: right; width: 120px; vertical-align:middle\" src=\"https://www.upm.es/sfs/Rectorado/Gabinete%20del%20Rector/Logos/EU_Informatica/ETSI%20SIST_INFORM_COLOR.png\" alt=\"ETSISI logo\" />\n",
    "\n",
    "\n",
    "# A ver si nos hacemos ricos (LSTM edition)<a id=\"top\"></a>\n",
    "\n",
    "<i>Última actualización: 2024-03-07</small></i></div>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "El intento anterior de predecir el mercado de valores no salió como esperábamos. Vamos a intentarlo de nuevo, esta vez con unas redes LSTM completamente nuevas, y utilizando únicamente el valor bursátil anterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crearemos un modelo de regresión para predecir un valor de bolsa dado el valor anterior. Al final habremos aprendido a:\n",
    "\n",
    "- Predecir la tendencia de una serie temporal utilizando LSTM.\n",
    "- Pensar dos veces antes de invertir en bolsa en base a las recomendaciones realizadas por los modelos que hemos programado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliotecas y configuración"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación importaremos las librerías que se utilizarán a lo largo del cuaderno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También configuraremos algunos parámetros para adaptar la presentación gráfica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "plt.rcParams.update({'figure.figsize': (20, 6),'figure.dpi': 64})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga y preparación de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recargaremos los datos del historial de Google como hicimos en el anterior intento de predicción bursátil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CODE = 'GOOG'\n",
    "BASE_URL = f'https://query1.finance.yahoo.com/v7/finance/download/{CODE}'\n",
    "# Interval\n",
    "today = datetime.datetime.now()\n",
    "five_years_ago = today - datetime.timedelta(days=365*5)\n",
    "# Timestamps (as integer) for the interval\n",
    "period2 = int(today.timestamp())\n",
    "period1 = int(five_years_ago.timestamp())\n",
    "# Now get the dataframe\n",
    "df = pd.read_csv(\n",
    "    f'{BASE_URL}?period1={period1}&period2={period2}&interval=1d',\n",
    "    index_col='Date',\n",
    "    parse_dates=['Date'],\n",
    "    dtype=np.float32\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a omitir el resto de valores y a centrarnos únicamente en la evolución temporal del valor de cierre de la acción. Eso sí, en lugar de utilizar el valor absoluto, lo que utilizaremos será la variación del valor respecto al día anterior. No vamos a hacer ninguna transformación más allá de normalizar y poco más, por lo que podemos convertirlo a un array de numpy sin problemas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df[['Close']].diff(axis=0).values[1:]\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora crearemos un `MinMaxScaler` para hacer la normalización y desnormalización de nuestros datos. Aprovechamos y los dejamos ya normalizados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "dataset = scaler.fit_transform(dataset)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Ya tenemos nuestro conjunto de datos casi listo para trabajar. Hemos transformado todo el conjunto de datos para hacer el ejercicio más corto, pero recuerde que en la normalización de los datos no deben entrar los datos de prueba El siguiente paso es especificar la longitud de la secuencia, que es lo mismo que el número de pasos temporales o el número de observaciones previas a considerar para hacer una predicción.\n",
    "\n",
    "Utilizaremos un tamaño de 20, lo que significa que para predecir el valor de un día se utilizarán los 20 anteriores (aproximadamente un mes). Para ello crearemos los conjuntos `X_train` y `Y_train`, dos arrays NumPy que contendrán las secuencias y el siguiente valor de esa secuencia respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQUENCE_LEN = 10\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "for i in range(len(dataset) - SEQUENCE_LEN - 9):\n",
    "    x_train.append(dataset[i:i + SEQUENCE_LEN, 0])\n",
    "    y_train.append(dataset[i + SEQUENCE_LEN + 9, 0])\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "for i in range(10):\n",
    "    print(f'... {x_train[i][-3:]} -> {y_train[i]}')\n",
    "print('-'*72)\n",
    "print(f'x_train shape: {x_train.shape}, Y_train shape: {y_train.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recordemos que los datos de entrada de una red recurrente deben tener una dimensión específica, por lo que ahora los transformaremos para adaptarlos a este requisito."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.reshape(x_train, (*x_train.shape[:2], 1))\n",
    "\n",
    "print(f'X_train shape: {x_train.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, ahora que tenemos los datos listos, extraigamos los últimos valores (por ejemplo, 100) para que sirvan como conjunto de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SIZE = 250\n",
    "\n",
    "x_train, x_test = x_train[:-TEST_SIZE], x_train[-TEST_SIZE:]\n",
    "y_train, y_test = y_train[:-TEST_SIZE], y_train[-TEST_SIZE:]\n",
    "\n",
    "print(f'X_train shape: {x_train.shape}, Y_train shape: {y_train.shape}')\n",
    "print(f'X_test shape: {x_test.shape}, Y_test shape: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementación y entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Pasamos a construir nuestra red neuronal recurrente. Crearemos una estructura apilada de 3 nodos `LSTM` de 40 nodos cada uno, con una capa `Dropout` después de cada capa. A continuación, utilizaremos como optimizador _Adam_ y como medida de pérdida el error cuadrático medio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.LSTM(128, activation='relu', return_sequences=True, input_shape=(x_train.shape[1], 1)),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.LSTM(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['root_mean_squared_error'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Ahora, entrenaremos el modelo durante... digamos $100$ _epochs_, con los datos de entrenamiento que hemos preparado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Echemos un vistazo a la evolución del entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history).plot()\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Epoch num.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez hecho todo, éste es el paso fácil. Tenemos que pasar nuestras fechas de prueba para ver cómo se comporta nuestro modelo con valores que nunca ha visto. Los compararemos con los valores reales para ver lo bien que lo hace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = model.predict(x_test)\n",
    "#predicted = scaler.inverse_transform(predicted)\n",
    "#real = scaler.inverse_transform(y_test.reshape((-1, 1)))\n",
    "real = y_test.reshape((-1, 1))\n",
    "\n",
    "plt.plot(real, label = 'Real')\n",
    "plt.plot(predicted, label = 'Predicted')\n",
    "plt.title('GOOG Stock Price Prediction')\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('GOOG Stock Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al menos no es un comportamiento como el anterior. Pero sigue siendo inútil. Aparentemente no vamos a hacernos ricos, al menos no así."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este _notebook_ hemos aprendido que es muy fácil cambiar entre tipos de unidades recurrentes. La API de Keras nos permite sustituir uno y otro prácticamente sin esfuerzo.\n",
    "\n",
    "También hemos visto que no todos los problemas de series temporales son resolubles, al menos no con los datos que tenemos a mano en un principio. Por supuesto que el valor bursátil de una acción es una serie temporal, pero hay muchas variables relacionadas con los valores, muchas de ellas emocionales de los propios propietarios de las acciones, por lo que es muy difícil identificarlas, obtenerlas y cuantificarlas. Aun así, si lo pruebas y te sale muy bien, no te olvides de nosotros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "<div><img style=\"float: right; width: 120px; vertical-align:top\" src=\"https://mirrors.creativecommons.org/presskit/buttons/88x31/png/by-nc-sa.png\" alt=\"Creative Commons by-nc-sa logo\" />\n",
    "\n",
    "[Volver al inicio](#top)\n",
    "\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
