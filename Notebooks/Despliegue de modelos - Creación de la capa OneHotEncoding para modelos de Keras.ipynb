{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45d9e09b",
   "metadata": {},
   "source": [
    "# Creación de al capa OneHotEncoding para modelos de Keras\n",
    "\n",
    "Vamos a presentar un ejemplo de creación de capa personalizara para el preprocesamiento de la entrada. Concretamente vamos a programar la codificación one-hot como capa que directamente transforma la cadena de texto y devuelve la codificación one-hot de la palabra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57300a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dff6d47e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dinos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>diplodocus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>albertosaurus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>deinonychus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>archaeopteryx</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dinos\n",
       "0     diplodocus\n",
       "1  albertosaurus\n",
       "2    deinonychus\n",
       "3  archaeopteryx"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dinos = pd.DataFrame(data=['diplodocus', 'albertosaurus', 'deinonychus', 'archaeopteryx'], columns=['dinos'])\n",
    "df_dinos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ada803d",
   "metadata": {},
   "source": [
    "El primer paso será convertir las categorías en índices de manera coherente, es decir, que una misma cadena se convierta **siempre** en el mismo índice. Para ello usaremos la capa `TextVectorization` de Keras (de las capas experimentales).\n",
    "\n",
    "Esta capa se suele usar para estandarizar y tokenizar secuencias de cadenas, como frases, pero en nuestro caso la usaremos únicamente para convertir categorías individuales en índeices de enteros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bb00ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorized words: ['', '[UNK]', 'diplodocus', 'deinonychus', 'archaeopteryx', 'albertosaurus']\n",
      "Index for word \"\": [[0]]\n",
      "Index for word \"[UNK]\": [[1]]\n",
      "Index for word \"diplodocus\": [[2]]\n",
      "Index for word \"deinonychus\": [[3]]\n",
      "Index for word \"archaeopteryx\": [[4]]\n",
      "Index for word \"albertosaurus\": [[5]]\n"
     ]
    }
   ],
   "source": [
    "text_vectorization = tf.keras.layers.experimental.preprocessing.TextVectorization(\n",
    "    output_sequence_length=1,  # Sólo queremos una única categoría\n",
    ")\n",
    "text_vectorization.adapt(\n",
    "    df_dinos.values,  # Ajusta las categorías para tener siempre las mismas categorías\n",
    ")\n",
    "\n",
    "print(f'Vectorized words: {text_vectorization.get_vocabulary()}')\n",
    "for word in text_vectorization.get_vocabulary():\n",
    "    print(f'Index for word \"{word}\": {text_vectorization([[word]])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb97f2c",
   "metadata": {},
   "source": [
    "## Creación de la capa personalizada\n",
    "\n",
    "Ahora crearemos una nueva capa de Keras para que represente una codificación de tipo one-hot en el pipeline. Para ello hay que heredar de [PreprocessingLayer](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/PreprocessingLayer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bdfe7a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i[0] for i in text_vectorization([[v] for v in text_vectorization.get_vocabulary()]).numpy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "935a2d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneHotEncodingLayer(tf.keras.layers.experimental.preprocessing.PreprocessingLayer):\n",
    "    def __init__(self, vocabulary=None, num_categories=None, min_index=None):\n",
    "        super().__init__()\n",
    "        self.vectorization = tf.keras.layers.experimental.preprocessing.TextVectorization(\n",
    "            output_sequence_length=1\n",
    "        )\n",
    "\n",
    "        if vocabulary:\n",
    "            self.vectorization.set_vocabulary(vocabulary)\n",
    "        self.num_categories = num_categories   \n",
    "        self.min_index = min_index\n",
    "\n",
    "    def adapt(self, data):\n",
    "        self.vectorization.adapt(data)\n",
    "        vocab = self.vectorization.get_vocabulary()\n",
    "        self.num_categories = len(vocab)\n",
    "        indices = [i[0] for i in self.vectorization([[v] for v in vocab]).numpy()]\n",
    "        self.minimum = min(indices)\n",
    "\n",
    "    def call(self,inputs):\n",
    "        vectorized = self.vectorization(inputs)\n",
    "        subtracted = tf.subtract(vectorized, tf.constant([self.minimum], dtype=tf.int64))\n",
    "        encoded = tf.one_hot(subtracted, self.num_categories)\n",
    "        return tf.keras.layers.Reshape((self.num_categories,))(encoded)\n",
    "\n",
    "    def get_config(self):\n",
    "        return {\n",
    "            'vocabulary': self.vectorization.get_vocabulary(),\n",
    "            'num_categories': self.num_categories,\n",
    "            'min_index': self.min_index,\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc11f55c",
   "metadata": {},
   "source": [
    "El método `adapt`, que viene de la clase `PreprocessingLayer` (el resto son de la clase `Layer`), es llamado **antes** de que comience el entrenamiento. Este es el comportamiento esperado de una capa de preproceso. En dicho paso se establecen los valores de los dos atributos principales de los objetos de la clase:\n",
    "\n",
    "- `self.num_categories`: El número de categorías únicas entre los datos de entrada\n",
    "- `self.min_index`: El índice más epqueño producido por la capa `TextVectorization`, que usaremos para restar a sus valores de salida y así que los índices resultantes partan del valor 0\n",
    "\n",
    "El método `get_config()` permitirá a TensorFlow guardar el estado de la capa cuando el modelo se salva en el disco. Si nos fijamos devuelve los valores del estado, los mismos quepedimos en el inicializador del objeto `__init__()`. La razón es que `adapt` se llama **antes** de que comience el entrenamiento, por lo que cuando se carga la capa de disco, no vamos a llamar a ese método."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b80800b",
   "metadata": {},
   "source": [
    "## Uso de la capa en nuestros modelos\n",
    "\n",
    "Tan sencillo como hemos ido usándola hasta ahora:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f56fd0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diplodocus -> [[0. 0. 1. 0. 0. 0.]]\n",
      "albertosaurus -> [[0. 0. 0. 0. 0. 1.]]\n",
      "deinonychus -> [[0. 0. 0. 1. 0. 0.]]\n",
      "archaeopteryx -> [[0. 0. 0. 0. 1. 0.]]\n",
      "UNKNOWN -> [[0. 1. 0. 0. 0. 0.]]\n",
      "EMPTY_STR -> [[1. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "model_input = tf.keras.layers.Input(shape=(1,), dtype=tf.string)\n",
    "one_hot_layer = OneHotEncodingLayer()\n",
    "one_hot_layer.adapt(df_dinos['dinos'].values)\n",
    "model_output = one_hot_layer(model_input)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=[model_input], outputs=[model_output])\n",
    "\n",
    "for dino in df_dinos['dinos']:\n",
    "    print(f'{dino} -> {model.predict([dino])}')\n",
    "print(f'UNKNOWN -> {model.predict([\"elefante\"])}')\n",
    "print(f'EMPTY_STR -> {model.predict([\"\"])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f200c7",
   "metadata": {},
   "source": [
    "Sólo por curiosidad, la clase `StringLookup` (también de `layers.keras.preprocessing`) se puede adaptar para que devuelva una codificación _one-hot_ de una cadena. Sin embargo, este ejemplo sirve para ilustrar cómo se crea una capa personalizada."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
