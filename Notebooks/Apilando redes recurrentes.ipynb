{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div><img style=\"float: right; width: 120px; vertical-align:middle\" src=\"https://www.upm.es/sfs/Rectorado/Gabinete%20del%20Rector/Logos/EU_Informatica/ETSI%20SIST_INFORM_COLOR.png\" alt=\"ETSISI logo\" />\n",
    "\n",
    "# Apilando redes recurrentes<a id=\"top\"></a>\n",
    "\n",
    "<i><small>Last update: 2023-05-07</small></i></div>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Las RNN apiladas (del inglés _stacked_) son un tipo de red neuronal formada por múltiples capas de RNN apiladas unas sobre otras.Se ha demostrado que las RNN apiladas mejoran el rendimiento de las RNN en diversas tareas al permitir que la red aprenda representaciones más complejas de datos secuenciales.\n",
    "\n",
    "En una RNN apilada, la salida de una capa de la RNN se pasa como entrada a la capa siguiente, creando una representación jerárquica de la secuencia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este cuaderno resolveremos un problema anterior con este tipo de arquitectura, viendo cómo implementar un modelo con varias capas recurrentes superpuestas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliotecas y configuración"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A continuación importaremos las librerías que se utilizarán a lo largo del cuaderno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-16 18:09:43.398100: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-16 18:09:43.560853: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-05-16 18:09:43.560869: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-05-16 18:09:44.491366: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-16 18:09:44.491450: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-16 18:09:44.491461: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También configuraremos algunos parámetros para adaptar la presentación gráfica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams.update({'figure.figsize': (20, 6),'figure.dpi': 64})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descarga y preproceso de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez más, utilizaremos el conjunto de datos `mnist`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape: (60000, 28, 28) input, (60000,) output\n",
      "Test shape:     (10000, 28, 28) input, (10000,) output\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "x_train, x_test = x_train / 255, x_test / 255\n",
    "\n",
    "print(f'Training shape: {x_train.shape} input, {y_train.shape} output')\n",
    "print(f'Test shape:     {x_test.shape} input, {y_test.shape} output')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo basado en múltiples capas de SRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Una arquitectura multicapa de SRU es casi idéntica a una multicapa tradicional. Sin embargo, hay que tener en cuenta un concepto fundamental: **las capas recurrentes se alimentan con una secuencia de entradas, no sólo con una entrada**.\n",
    "\n",
    "Para ello, haremos uso del argumento `return_sequences=True` de las unidades recurrentes. Al activarlo, hacemos que la red devuelva la secuencia completa de salidas, no sólo la última. Haciendo esto, la capa siguiente, que requiere una secuencia, será alimentada con una secuencia. Veamos la implementación utilizando dos capas `SimpleRNN` de 10 «unidades» cada una:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn (SimpleRNN)      (None, 28, 10)            390       \n",
      "                                                                 \n",
      " simple_rnn_1 (SimpleRNN)    (None, 28, 10)            210       \n",
      "                                                                 \n",
      " simple_rnn_2 (SimpleRNN)    (None, 10)                210       \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                110       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 920\n",
      "Trainable params: 920\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-16 18:13:29.981524: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-05-16 18:13:29.981585: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-05-16 18:13:29.981618: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (bulma): /proc/driver/nvidia/version does not exist\n",
      "2023-05-16 18:13:29.982029: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.SimpleRNN(units=10, return_sequences=True, input_shape=(28, 28)),\n",
    "    tf.keras.layers.SimpleRNN(units=10, return_sequences=True),\n",
    "    tf.keras.layers.SimpleRNN(units=10),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver en el resumen que la salida de la primera capa (la que tiene `return_sequences=True`) devuelve una secuencia de 28 elementos (el tamaño de la secuencia) de dimensión 10 cada uno (su número de unidades). La segunda capa, que no hace explícito el argumento (que por defecto es `False`) devuelve sólo 10 valores, los correspondientes a la última salida de la unidad recurrente después de haberla alimentado con los 28 elementos de la secuencia.\n",
    "\n",
    "Por último, vamos a compilar el modelo creado con la función de pérdida que corresponde a este tipo de problema con un optimizador de descenso de gradiente estocástico y vamos a añadir la métrica _accuracy_ (en realidad `sparse categorical accuracy`, esto es, una versión de la primera pero preparada para problemas de clasificación multiclase para salidas _sparse_) para ver cómo evoluciona este entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['sparse_categorical_accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Por último, entrenaremos nuestra red durante 10$ epochs. Sí, si con las redes recurrentes era lento, con las redes apiladas lo es aún más."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1875/1875 [==============================] - 25s 12ms/step - loss: 1.2923 - sparse_categorical_accuracy: 0.5327\n",
      "Epoch 2/25\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 0.9982 - sparse_categorical_accuracy: 0.6448\n",
      "Epoch 3/25\n",
      "1875/1875 [==============================] - 22s 12ms/step - loss: 0.9087 - sparse_categorical_accuracy: 0.6766\n",
      "Epoch 4/25\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 0.8524 - sparse_categorical_accuracy: 0.6989\n",
      "Epoch 5/25\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.7980 - sparse_categorical_accuracy: 0.7149\n",
      "Epoch 6/25\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.7649 - sparse_categorical_accuracy: 0.7283\n",
      "Epoch 7/25\n",
      "1875/1875 [==============================] - 22s 12ms/step - loss: 0.7440 - sparse_categorical_accuracy: 0.7370\n",
      "Epoch 8/25\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 0.7291 - sparse_categorical_accuracy: 0.7425\n",
      "Epoch 9/25\n",
      "1875/1875 [==============================] - 22s 12ms/step - loss: 0.7077 - sparse_categorical_accuracy: 0.7497\n",
      "Epoch 10/25\n",
      "1875/1875 [==============================] - 22s 12ms/step - loss: 0.7114 - sparse_categorical_accuracy: 0.7491\n",
      "Epoch 11/25\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 0.7352 - sparse_categorical_accuracy: 0.7429\n",
      "Epoch 12/25\n",
      "1875/1875 [==============================] - 22s 12ms/step - loss: 0.7019 - sparse_categorical_accuracy: 0.7529\n",
      "Epoch 13/25\n",
      "1875/1875 [==============================] - 22s 12ms/step - loss: 0.6594 - sparse_categorical_accuracy: 0.7701\n",
      "Epoch 14/25\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 0.6553 - sparse_categorical_accuracy: 0.7721\n",
      "Epoch 15/25\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 0.7532 - sparse_categorical_accuracy: 0.7418\n",
      "Epoch 16/25\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 0.7148 - sparse_categorical_accuracy: 0.7520\n",
      "Epoch 17/25\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 0.6908 - sparse_categorical_accuracy: 0.7614\n",
      "Epoch 18/25\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 0.6326 - sparse_categorical_accuracy: 0.7821\n",
      "Epoch 19/25\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 0.6283 - sparse_categorical_accuracy: 0.7820\n",
      "Epoch 20/25\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 0.6855 - sparse_categorical_accuracy: 0.7651\n",
      "Epoch 21/25\n",
      "1875/1875 [==============================] - 22s 12ms/step - loss: 0.6376 - sparse_categorical_accuracy: 0.7791\n",
      "Epoch 22/25\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 0.6381 - sparse_categorical_accuracy: 0.7785\n",
      "Epoch 23/25\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 0.6135 - sparse_categorical_accuracy: 0.7846\n",
      "Epoch 24/25\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 0.6280 - sparse_categorical_accuracy: 0.7814\n",
      "Epoch 25/25\n",
      "1875/1875 [==============================] - 22s 12ms/step - loss: 0.6042 - sparse_categorical_accuracy: 0.7882\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Veamos cómo ha ido el entrenamiento del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history).plot()\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Epoch num.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quizá la precisión con la que ha clasificado sea mejor, pero en este problema concreto, las redes convolucionales siguen siendo la mejor opción."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clasificación de nuevas muestras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora imprimiremos algunos de los elementos de la prueba para ver cómo se han clasificado y cuáles han sido los errores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict some of the test digits\n",
    "ROWS, COLS = 5, 5\n",
    "IMAGES = ROWS * COLS\n",
    "ŷ_test = np.argmax(model.predict(x_test[:IMAGES], verbose=0), axis=1)\n",
    "# And plot them\n",
    "fig = plt.figure(figsize=(15, 15))\n",
    "for i, (x, y, ŷ) in enumerate(zip(x_test[:IMAGES], y_test[:IMAGES], ŷ_test), 1):\n",
    "    ax = fig.add_subplot(ROWS, COLS, i)\n",
    "    ax.imshow(x, cmap='Greens' if y == ŷ else 'Reds')\n",
    "    ax.set_title(f'Expected: {y}, predicted: {ŷ}')\n",
    "    ax.grid(False)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hemos mostrado cómo implementar una red neuronal recurrente apilada en Keras, en concreto un modelo RNN de dos capas con 10 unidades en cada capa. Y aunque lo hemos aplicado al problema `mnist`, hemos comprobado que no es la mejor opción (al menos en tiempo de entrenamiento).\n",
    "\n",
    "Apilar RNN puede ser una técnica muy útil para modelar datos secuenciales, ya que permite al modelo capturar dependencias más complejas entre las entradas y las salidas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "<div><img style=\"float: right; width: 120px; vertical-align:top\" src=\"https://mirrors.creativecommons.org/presskit/buttons/88x31/png/by-nc-sa.png\" alt=\"Creative Commons by-nc-sa logo\" />\n",
    "\n",
    "[Back to top](#top)\n",
    "\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
