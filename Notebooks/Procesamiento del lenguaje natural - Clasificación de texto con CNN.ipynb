{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4480ff39",
   "metadata": {},
   "source": [
    "<div><img style=\"float: right; width: 120px; vertical-align:middle\" src=\"https://www.upm.es/sfs/Rectorado/Gabinete%20del%20Rector/Logos/EU_Informatica/ETSI%20SIST_INFORM_COLOR.png\" alt=\"ETSISI logo\" />\n",
    "\n",
    "\n",
    "# Clasificación de texto con CNN<a id=\"top\"></a>\n",
    "\n",
    "<i><small>Última actualización: 2024-03-11</small></i></div>\n",
    "\n",
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d2489222",
   "metadata": {},
   "source": [
    "## Introducción"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e17030ba",
   "metadata": {},
   "source": [
    "En el procesamiento del lenguaje natural (NLP, del inglés natural language processing_), una tarea muy típica es la clasificación de textos. En esta tarea, un texto dado se clasifica según su significado. A menudo se utiliza, por ejemplo, para el problema del análisis de sentimientos.\n",
    "\n",
    "Se trata de un problema denominado _many-to-one_, es decir, uno en el que el tamaño de la secuencia de entrada es $T_X = 1$, pero el tamaño de la secuencia de salida es $T_Y = 1$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fc7d1e17",
   "metadata": {},
   "source": [
    "## Objetivos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d0b9e324",
   "metadata": {},
   "source": [
    "Vamos a hacer un experimento en el que utilizaremos el conjunto de datos de reseñas de amazon para una tarea de análisis de sentimiento. A partir de los datos de reseñas y valoraciones, identificaremos si una reseña es positiva, neutra o negativa, y para ello utilizaremos una primera aproximación utilizando un modelo de redes neuronales convolucionales."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5d401eac",
   "metadata": {},
   "source": [
    "## Bibliotecas y configuración"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fa528aec",
   "metadata": {},
   "source": [
    "A continuación importaremos las bibliotecas que se utilizarán a lo largo del cuaderno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00a8c29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-25 18:25:27.677882: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "import requests\n",
    "from shutil import unpack_archive\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ff3a5f84",
   "metadata": {},
   "source": [
    "También configuraremos algunos parámetros para adaptar la presentación gráfica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d522d503",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "plt.rcParams.update({'figure.figsize': (20, 6),'figure.dpi': 64})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8ea7481e",
   "metadata": {},
   "source": [
    "Y crearemos los directorios necesarios en caso de que no se hayan creado previamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64979a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('tmp', exist_ok=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ee4fec89",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b6d22a2c",
   "metadata": {},
   "source": [
    "## Parámetros globales"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "231d1a4e",
   "metadata": {},
   "source": [
    "Comenzaremos definiendo los parámetros que utilizaremos a lo largo del cuaderno, que consistirán en la longitud máxima de las secuencias (recuerda que deben tener una longitud fija) y la dimensión del vector de cada palabra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51a1ad15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cuántas dimensiones tienen nuestros vectores de palabras (usaremos\n",
    "# GloVe, así que 50, 100, 200 o 300)\n",
    "EMBEDDING_DIM = 300\n",
    "# Tamaño máximo de nuestro vocabulario (se elegirán los token más\n",
    "# frecuentes)\n",
    "MAX_VOCAB_SIZE = 16384\n",
    "# Longitud máxima de las secuencias de palabras\n",
    "MAX_SEQUENCE_LEN = 32"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e86b03b1",
   "metadata": {},
   "source": [
    "## Preprocesamiento de datos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9b1ff85c",
   "metadata": {},
   "source": [
    "Vamos a cargar los datos de entrenamiento, que consistirán en los datos de reseñas de Amazon de la categoría «Música digital» (https://nijianmo.github.io/amazon/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "564710a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>vote</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>style</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>True</td>\n",
       "      <td>06 3, 2013</td>\n",
       "      <td>A2TYZ821XXK2YZ</td>\n",
       "      <td>3426958910</td>\n",
       "      <td>{'Format:': ' Audio CD'}</td>\n",
       "      <td>Garrett</td>\n",
       "      <td>This is awesome to listen to, A must-have for ...</td>\n",
       "      <td>Slayer Rules!</td>\n",
       "      <td>1370217600</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>10 11, 2014</td>\n",
       "      <td>A3OFSREZADFUDY</td>\n",
       "      <td>3426958910</td>\n",
       "      <td>{'Format:': ' Audio CD'}</td>\n",
       "      <td>Ad</td>\n",
       "      <td>bien</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1412985600</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>02 11, 2014</td>\n",
       "      <td>A2VAMODP8M77NG</td>\n",
       "      <td>3426958910</td>\n",
       "      <td>{'Format:': ' Audio CD'}</td>\n",
       "      <td>JTGabq</td>\n",
       "      <td>It was great to hear the old stuff again and I...</td>\n",
       "      <td>SLAYER!!!!!!!!!!!!!!!!!!!!!</td>\n",
       "      <td>1392076800</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>False</td>\n",
       "      <td>12 7, 2013</td>\n",
       "      <td>AAKSLZ9IDTEH0</td>\n",
       "      <td>3426958910</td>\n",
       "      <td>{'Format:': ' Audio CD'}</td>\n",
       "      <td>john F&amp;#039;n doe</td>\n",
       "      <td>well best of's are a bit poison normally but t...</td>\n",
       "      <td>slayer greatest hits! you mean everything righ...</td>\n",
       "      <td>1386374400</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>06 12, 2016</td>\n",
       "      <td>A3OH43OZJLKI09</td>\n",
       "      <td>5557706259</td>\n",
       "      <td>{'Format:': ' Audio CD'}</td>\n",
       "      <td>melinda a goodman</td>\n",
       "      <td>What can I say? This is Casting Crowns!!!This ...</td>\n",
       "      <td>This is a good, blessing filled</td>\n",
       "      <td>1465689600</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall  vote  verified   reviewTime      reviewerID        asin  \\\n",
       "0        5   3.0      True   06 3, 2013  A2TYZ821XXK2YZ  3426958910   \n",
       "1        5   NaN      True  10 11, 2014  A3OFSREZADFUDY  3426958910   \n",
       "2        5   NaN      True  02 11, 2014  A2VAMODP8M77NG  3426958910   \n",
       "3        4   3.0     False   12 7, 2013   AAKSLZ9IDTEH0  3426958910   \n",
       "4        5   NaN      True  06 12, 2016  A3OH43OZJLKI09  5557706259   \n",
       "\n",
       "                      style       reviewerName  \\\n",
       "0  {'Format:': ' Audio CD'}            Garrett   \n",
       "1  {'Format:': ' Audio CD'}                 Ad   \n",
       "2  {'Format:': ' Audio CD'}             JTGabq   \n",
       "3  {'Format:': ' Audio CD'}  john F&#039;n doe   \n",
       "4  {'Format:': ' Audio CD'}  melinda a goodman   \n",
       "\n",
       "                                          reviewText  \\\n",
       "0  This is awesome to listen to, A must-have for ...   \n",
       "1                                               bien   \n",
       "2  It was great to hear the old stuff again and I...   \n",
       "3  well best of's are a bit poison normally but t...   \n",
       "4  What can I say? This is Casting Crowns!!!This ...   \n",
       "\n",
       "                                             summary  unixReviewTime image  \n",
       "0                                      Slayer Rules!      1370217600   NaN  \n",
       "1                                         Five Stars      1412985600   NaN  \n",
       "2                        SLAYER!!!!!!!!!!!!!!!!!!!!!      1392076800   NaN  \n",
       "3  slayer greatest hits! you mean everything righ...      1386374400   NaN  \n",
       "4                    This is a good, blessing filled      1465689600   NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATASET_URL = 'https://jmcauley.ucsd.edu/data/amazon_v2/categoryFilesSmall/Digital_Music_5.json.gz'\n",
    "DATASET_ZIP = 'tmp/Digital_Music_5.json.gz'\n",
    "\n",
    "# Download the remote file if it does not exist\n",
    "if not os.path.exists(DATASET_ZIP):\n",
    "    with open(DATASET_ZIP, 'wb') as f:\n",
    "        print(f'Downloading {DATASET_ZIP}...')\n",
    "        r = requests.get(DATASET_URL, verify=False)\n",
    "        f.write(r.content)\n",
    "        print('OK')\n",
    "\n",
    "corpus = pd.read_json(DATASET_ZIP, lines=True)\n",
    "corpus.dropna(subset=['overall', 'reviewText'], inplace=True)\n",
    "corpus.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bace8799",
   "metadata": {},
   "source": [
    "El proceso que realizaremos en este _notebook_ será ver cómo construir un modelo convolucional para trabajar con este tipo de conjuntos de datos. Por lo tanto no entraremos en el detalle de obtener un conjunto de datos de prueba.\n",
    "\n",
    "Sin embargo, hay que tener en cuenta que en un problema real sería necesario entrenar con validación y contrastar con un conjunto de prueba antes de poner nuestro modelo en producción."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5719ffd0",
   "metadata": {},
   "source": [
    "### Preparando la entrada a nuestro modelo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "074e95f9",
   "metadata": {},
   "source": [
    "La entrada de nuestro modelo serán las reseñas como tales; por lo tanto, tomaremos la columna `reviewText` como nuestro conjunto de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32f62d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training input shape: (169623,)\n"
     ]
    }
   ],
   "source": [
    "x_train = corpus['reviewText'].astype(str).str.strip()\n",
    "print(f'Training input shape: {x_train.shape}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6464895c",
   "metadata": {},
   "source": [
    "Ahora crearemos una capa [`TextVectorization`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/TextVectorization), que se encargará de:\n",
    "\n",
    "1. Convertir una reseña completa en una secuencia de enteros (palabras), asignando a cada palabra un valor único.\n",
    "2. Truncar o rellenar las sencuencias para que estas mantengan una longitud fija previamente establecida (en nuestro caso `MAX_SEQUENCE_LEN`).\n",
    "\n",
    "El vocabulario se extraerá de nuestra entrada, tomando las `MAX_VOCAB_SIZE` palabras más comunes. Hemos añadido `+ 2` a la longitud ya que hay dos tokens preasignados: Padding (`''`) y palabras fuera del vocabulario (`'[UNK]'`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c3221f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-25 18:25:33.556974: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2023-05-25 18:25:33.589490: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:37:00.0 name: Quadro RTX 8000 computeCapability: 7.5\n",
      "coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 47.46GiB deviceMemoryBandwidth: 625.94GiB/s\n",
      "2023-05-25 18:25:33.591575: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 1 with properties: \n",
      "pciBusID: 0000:86:00.0 name: Quadro RTX 8000 computeCapability: 7.5\n",
      "coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 47.46GiB deviceMemoryBandwidth: 625.94GiB/s\n",
      "2023-05-25 18:25:33.591614: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2023-05-25 18:25:33.595726: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2023-05-25 18:25:33.595806: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2023-05-25 18:25:33.597465: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2023-05-25 18:25:33.597807: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2023-05-25 18:25:33.598044: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.0/lib:/usr/local/cuda-11.0/lib\n",
      "2023-05-25 18:25:33.598961: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2023-05-25 18:25:33.599162: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2023-05-25 18:25:33.599176: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1766] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-05-25 18:25:33.599720: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-25 18:25:33.600482: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-05-25 18:25:33.600496: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary length: 16386\n"
     ]
    }
   ],
   "source": [
    "vectorize_layer = tf.keras.layers.experimental.preprocessing.TextVectorization(\n",
    "    max_tokens=MAX_VOCAB_SIZE + 2,\n",
    "    output_sequence_length=MAX_SEQUENCE_LEN,\n",
    ")\n",
    "vectorize_layer.adapt(x_train.to_numpy())\n",
    "\n",
    "print(f'Vocabulary length: {len(vectorize_layer.get_vocabulary())}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "88b782d0",
   "metadata": {},
   "source": [
    "### Preparando la salida de nuestro modelo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b394b67f",
   "metadata": {},
   "source": [
    "Partiendo de la base de que las reseñas con valoraciones altas serán positivas y las que tengan valoraciones bajas serán negativas, conservaremos sólo la reseña y la valoración del producto del conjunto de datos.\n",
    "\n",
    "En concreto, convertiremos las valoraciones de las reseñas en 0 si son malas (1 o 2 estrellas), 1 si son mediocres (3 estrellas) y 2 si son buenas (4 o más estrellas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d03f799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training output shape: (169623,)\n"
     ]
    }
   ],
   "source": [
    "y_train = corpus['overall'].astype(int).replace({\n",
    "    1: 0,\n",
    "    2: 0,\n",
    "    3: 1,\n",
    "    4: 2,\n",
    "    5: 2,\n",
    "})\n",
    "print(f'Training output shape: {y_train.shape}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d7223928",
   "metadata": {},
   "source": [
    "## Uso de _embeddings_ preentrenados en nuestro modelo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d9977840",
   "metadata": {},
   "source": [
    "Ya hemos visto que, a la hora de construir un modelo lingüístico, un aspecto importante es la representación de las palabras. Para captar el significado semántico de las palabras, utilizamos _embeddings_ de palabras, que son representaciones vectoriales de palabras en un espacio donde cada una de las muchas dimensiones representan una característica semántica.\n",
    "\n",
    "Esta vez, en lugar de entrenar nuestros _embeddings_ desde cero, aprovecharemos uno preentrenado, _Global Vectors for Word Representation_ (GLoVe), entrenado con un conjunto de datos de más de 6.000 millones de tokens. Cuenta con varios vectores de palabras preentrenados, por lo que los utilizaremos en <http://nlp.stanford.edu/data/glove.6B.zip>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67b5594b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unpacking ...OK\n"
     ]
    }
   ],
   "source": [
    "GLOVE_URL = 'http://nlp.stanford.edu/data/glove.6B.zip'\n",
    "GLOVE_FILE = 'tmp/glove.6B.zip'\n",
    "\n",
    "# Download the compressed GloVe dataset (if you don't already have it)\n",
    "if not os.path.exists(GLOVE_FILE):\n",
    "    print('Downloading ...', end='')\n",
    "    with open(GLOVE_FILE, 'wb') as f:\n",
    "        r = requests.get(GLOVE_URL, allow_redirects=True)\n",
    "        f.write(r.content)\n",
    "    print('OK')\n",
    "\n",
    "# Unzip it in the directory 'glove'.\n",
    "print('Unpacking ...', end='')\n",
    "unpack_archive(GLOVE_FILE, 'tmp')\n",
    "print('OK')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "39fc8ea3",
   "metadata": {},
   "source": [
    "Mediante su uso podemos aprovechar la gran cantidad de conocimiento codificado en estos _embeddings_, lo que seguramente mejore (y mucho)el rendimiento de nuestro modelo lingüístico.\n",
    "\n",
    "Ahora carguemos el _embedding_ de la dimensión especificada en la configuración. El archivo se compone de líneas de tuplas, donde el primer elemento es la palabra (en texto) y el segundo es ese vector de palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98b853ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading GloVe 300-d embedding... "
     ]
    }
   ],
   "source": [
    "print(f'Loading GloVe {EMBEDDING_DIM}-d embedding... ', end='')\n",
    "word2vec = {}\n",
    "with open(f'tmp/glove.6B.{EMBEDDING_DIM}d.txt') as f:\n",
    "    for line in f:\n",
    "        word, vector = line.split(maxsplit=1)\n",
    "        word2vec[word] = np.fromstring(vector,'f', sep=' ')\n",
    "print(f'done ({len(word2vec)} word vectors loaded)')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5c6ece6e",
   "metadata": {},
   "source": [
    "Bueno, $400.000$ _tokens_ son bastantes. Como nuestro vocabulario es menor, vamos a crear una capa de incrustación más pequeña, del tamaño de nuestro vocabulario. Para ello, incluiremos en ésta sólo los vectores de las palabras que nos devolverá la capa `TextVectorization`.\n",
    "\n",
    "Comenzaremos creando la matriz de incrustación con los vectores del guante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3344464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating embedding matrix with GloVe vectors... done (3425 words unassigned)\n"
     ]
    }
   ],
   "source": [
    "print('Creating embedding matrix with GloVe vectors... ', end='')\n",
    "\n",
    "# Our newly created embedding: a matrix of zeros\n",
    "embedding_matrix = np.zeros((MAX_VOCAB_SIZE + 2, EMBEDDING_DIM))\n",
    "\n",
    "ko_words = 0\n",
    "for i, word in enumerate(vectorize_layer.get_vocabulary()):\n",
    "    if word == '[UNK]':\n",
    "        # The second word is for an unknown token, in glove is 'unk'\n",
    "        word = 'unk'\n",
    "\n",
    "    # Get the word vector and overwrite the row in its corresponding position\n",
    "    word_vector = word2vec.get(word)\n",
    "    if word_vector is not None:\n",
    "        embedding_matrix[i] = word_vector\n",
    "    else:\n",
    "        ko_words += 1\n",
    "\n",
    "print(f'done ({ko_words} words unassigned)')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f9f9bae0",
   "metadata": {},
   "source": [
    "Bueno, al parecer hay muchas palabras que no tienen correspondencia en el _embedding_ descargada. Después de todo $400000$ _tokens_ igual no eran tantos después de todo.\n",
    "\n",
    "Una vez hecho esto, podemos crear una capa de incrustación con la matriz de pesos precargada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b548d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = tf.keras.layers.Embedding(\n",
    "    input_dim=embedding_matrix.shape[0],\n",
    "    output_dim=embedding_matrix.shape[1],\n",
    "    weights=[embedding_matrix],\n",
    "    input_length=MAX_SEQUENCE_LEN,\n",
    "    trainable=False,\n",
    "    name='Embedding',\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9b6eedd5",
   "metadata": {},
   "source": [
    "## Clasificación basada en redes neuronales convolucionales"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8ee0758b",
   "metadata": {},
   "source": [
    "Haremos una aproximación al problema utilizando redes convolucionales. En este caso, nuestras frases estarán representadas por «imágenes» de una sola fila, con tantas columnas como la longitud de la secuencia especificada y tantos canales como la dimensión de cada valabra de la secuencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50554551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "text_vectorization_2 (TextVe (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "Embedding (Embedding)        (None, 32, 300)           4915800   \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 30, 32)            28832     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 30, 32)            128       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 960)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 3)                 2883      \n",
      "=================================================================\n",
      "Total params: 4,947,643\n",
      "Trainable params: 31,779\n",
      "Non-trainable params: 4,915,864\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.Input(shape=(1,), dtype=tf.string),\n",
    "    vectorize_layer,  # [[1, 2, 3, 4, 5], [6, 7, 8, 9, 0]]\n",
    "    embedding_layer,\n",
    "    tf.keras.layers.Conv1D(32, kernel_size=3, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(3, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['sparse_categorical_accuracy'],\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f4550806",
   "metadata": {},
   "source": [
    "Entrenemos al modelo y esperemos que todo salga bien."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccda9aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-25 17:54:49.495306: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2023-05-25 17:54:49.514546: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 1900000000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "5305/5305 [==============================] - 24s 4ms/step - loss: 0.1713 - sparse_categorical_accuracy: 0.9539\n",
      "Epoch 2/5\n",
      "5305/5305 [==============================] - 22s 4ms/step - loss: 0.1424 - sparse_categorical_accuracy: 0.9593\n",
      "Epoch 3/5\n",
      "5305/5305 [==============================] - 22s 4ms/step - loss: 0.1304 - sparse_categorical_accuracy: 0.9616\n",
      "Epoch 4/5\n",
      "5305/5305 [==============================] - 22s 4ms/step - loss: 0.1210 - sparse_categorical_accuracy: 0.9638\n",
      "Epoch 5/5\n",
      "5305/5305 [==============================] - 22s 4ms/step - loss: 0.1137 - sparse_categorical_accuracy: 0.9653\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=50)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b2d17311",
   "metadata": {},
   "source": [
    "Echemos un vistazo al progreso del entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddec59a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1280x384 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot()\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Epoch num.')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b16b83b4",
   "metadata": {},
   "source": [
    "Veamos ahora cómo interpreta el sentimiento de una reseña buena, regular y mala extraída del sitio web de amazon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0fc59e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good was classified as 2\n",
      "Poor was classified as 2\n",
      "Evil was classified as 1\n"
     ]
    }
   ],
   "source": [
    "good = \"My nephew is on the autism spectrum and likes to fidget with things so I knew this toy would be a hit. Was concerned that it may not be \\\"complex\\\" enough for his very advanced brain but he really took to it. Both him (14 yrs) and his little brother (8 yrs) both enjoyed playing with it throughout Christmas morning. I'm always happy when I can find them something unique and engaging.\"\n",
    "poor = \"I wasn't sure about this as it's really small. I bought it for my 9 year old grandson. I was ready to send it back but my daughter decided it was a good gift so I'm hoping he likes it. Seems expensive for the price though to me.\"\n",
    "evil = \"I just wanted to follow up to say that I reported this directly to the company and had no response. I have not gotten any response from my review. The level of customer service goes a long way when an item you purchase is defective and this company didn’t care to respond. No I am even more Leary about ordering anything from this company. I never asked for a refund or replacement since I am not able to return it. I’m just wanted to let them know that this was a high dollar item and I expected it to be a quality item. Very disappointed! I bought this for my grandson for Christmas. He loved it and played with it a lot. My daughter called to say that the stickers were peeling on the corners. I am not able to take it from my grandson because he is autistic and wouldn’t understand. I just wanted to warn others who are wanting to get this. Please know that this is a cool toy and it may not happen to yours so it is up to you.\"\n",
    "\n",
    "probabilities = model.predict([good, poor, evil], verbose=0)\n",
    "print(f'Good was classified as {np.argmax(probabilities[0])}')\n",
    "print(f'Poor was classified as {np.argmax(probabilities[1])}')\n",
    "print(f'Evil was classified as {np.argmax(probabilities[2])}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "43585490",
   "metadata": {},
   "source": [
    "## Conclusiones"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e7defd88",
   "metadata": {},
   "source": [
    "Hemos demostrado cómo utilizar una red neuronal convolucional para clasificar texto, en concreto, reseñas de productos como buenas, medias o malas. También hemos analizado las ventajas de utilizar incrustaciones de palabras preentrenadas, que pueden ayudar a mejorar el rendimiento del modelo aprovechando las relaciones semánticas entre las palabras del corpus preentrenado. También exploramos la capa TextVectorization, que proporciona una forma flexible de preprocesar datos de texto y convertirlos en vectores numéricos.\n",
    "\n",
    "Se trata de un ejemplo que puede servir de punto de partida para multitud de proyectos de NLP."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "33005bde",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "<div><img style=\"float: right; width: 120px; vertical-align:top\" src=\"https://mirrors.creativecommons.org/presskit/buttons/88x31/png/by-nc-sa.png\" alt=\"Creative Commons by-nc-sa logo\" />\n",
    "\n",
    "[Volver al inicio](#top)\n",
    "\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
