{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "010176d1",
   "metadata": {},
   "source": [
    "<div><img style=\"float: right; width: 120px; vertical-align:middle\" src=\"https://www.upm.es/sfs/Rectorado/Gabinete%20del%20Rector/Logos/EU_Informatica/ETSI%20SIST_INFORM_COLOR.png\" alt=\"ETSISI logo\" />\n",
    "\n",
    "\n",
    "# Perceptrón simple y perceptrón multicapa<a id=\"top\"></a>\n",
    "\n",
    "<i><small>Última actualización: 2024-03-04</small></i></div>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554fb61b",
   "metadata": {},
   "source": [
    "## Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4c114e",
   "metadata": {},
   "source": [
    "En el aprendizaje profundo , o _deep learning_, los perceptrones y los perceptrones multicapa se erigen como fundamentos esenciales para entender el desarrollo y la implementación de redes neuronales artificiales. Este _notebook_ tiene como objetivo adentrarse en la comprensión teórica y práctica de estas estructuras, desde sus principios básicos hasta su aplicación en problemas complejos de clasificación y regresión.\n",
    "\n",
    "El perceptrón, introducido por Frank Rosenblatt en 1957, es el bloque constructivo más simple de una red neuronal, diseñado para realizar clasificaciones binarias de manera eficiente. Aunque su utilidad se ve limitada por su incapacidad para resolver problemas no linealmente separables, su estudio sienta las bases para comprender algoritmos más complejos. Por otro lado, el perceptrón multicapa, o red neuronal de varias capas, supera estas limitaciones mediante la incorporación de una o más capas ocultas entre la entrada y la salida, permitiendo la aproximación a cualquier función continua y la solución de problemas no lineales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f243ba3",
   "metadata": {},
   "source": [
    "## Objetivos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc68420",
   "metadata": {},
   "source": [
    "Los objetivos que trataremos de cubrir en este _notebook_ son los siguientes:\n",
    "\n",
    "1. Introducir los conceptos básicos: Explicar de manera clara y concisa qué es un perceptrón y un perceptrón multicapa, destacando sus diferencias y el papel que juegan dentro del campo del aprendizaje automático,\n",
    "2. Explorar el funcionamiento: Desglosar los componentes internos de estos modelos, incluyendo las neuronas, pesos, sesgos y funciones de activación, y explicar cómo interactúan durante el proceso de aprendizaje,\n",
    "3. Implementación desde cero: Guiar al lector a través de la creación de un perceptrón y un perceptrón multicapa utilizando solamente Python puro, con el fin de solidificar la comprensión de su mecánica interna y los algoritmos de entrenamiento,\n",
    "4. Implementación con Keras: Introducir el uso de Keras, una biblioteca de alto nivel para redes neuronales, para construir y entrenar perceptrones multicapa de manera más eficiente, permitiendo al lector familiarizarse con herramientas modernas de aprendizaje profundo, y\n",
    "5. Aplicación práctica: Demostrar la aplicación de estos modelos en tareas de clasificación y regresión, proporcionando ejemplos prácticos sobre _datasets_ para que el lector pueda experimentar y observar su rendimiento.\n",
    "\n",
    "Con estos objetivos en mente, este notebook aspira no solo a educar sino también a inspirar a los lectores a profundizar en el estudio de las redes neuronales y a explorar sus aplicaciones en el mundo real."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67582fcc",
   "metadata": {},
   "source": [
    "## Bibliotecas y configuración\n",
    "\n",
    "A continuación importaremos las bibliotecas que se utilizarán a lo largo del _notebook_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58374f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1716ef",
   "metadata": {},
   "source": [
    "Si salen algunos _warning_ es porque `tensorflow` es así. Seguramente sea una compilación genérica y requiera de una compilación específica para que desaparezcan. Afortunadamente, no suele pasar nada porque salgan estos warning, sobreviviremos.\n",
    "\n",
    "Configuraremos también algunos parámetros para adecuar la presentación gráfica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f428e5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams.update({'figure.figsize': (20, 6),'figure.dpi': 64})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06541e93",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb7467c",
   "metadata": {},
   "source": [
    "## Perceptrón simple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee16f318",
   "metadata": {},
   "source": [
    "El perceptrón simple, también conocido simplemente como perceptrón, es un modelo de aprendizaje automático lineal que se utiliza para clasificaciones binarias. Como decíamos enla introducción, este modelo fue desarrollado en 1957 por Frank Rosenblatt y puede considerarse como la unidad básica de una red neuronal artificial. La idea central detrás del perceptrón es simular el funcionamiento de una neurona biológica, donde recibe múltiples señales de entrada, las procesa y produce una salida única. En términos matemáticos, el perceptrón toma un vector de características de entrada, les aplica pesos correspondientes, suma estos productos y luego aplica una función de activación, típicamente la función escalón, para determinar si la entrada pertenece a una clase o a otra. Llamaremos de ahora en adelante a este proceso **inferencia**.\n",
    "\n",
    "El funcionamiento del perceptrón se basa en la actualización iterativa de los pesos asociados a cada característica de entrada. Durante el proceso de entrenamiento, el modelo ajusta estos pesos para minimizar el error en sus predicciones. Si la predicción es incorrecta, los pesos se actualizan en función del error cometido, utilizando una tasa de aprendizaje para controlar la magnitud del ajuste. Esta regla de aprendizaje, conocida como regla de aprendizaje del perceptrón o **regla delta**, permite al modelo aprender la frontera de decisión que mejor separa las dos clases. A pesar de su simplicidad y de estar limitado a problemas linealmente separables, el perceptrón sienta las bases para algoritmos más complejos y constituye el primer paso hacia el entendimiento de las redes neuronales multicapa y el aprendizaje profundo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0cfe2d",
   "metadata": {},
   "source": [
    "### Inferencia en el perceptrón"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7239527e",
   "metadata": {},
   "source": [
    "Como hemos indicado, el funcionamiento del perceptrón simple es dar una salida en función de la suma de las entradas ponderadas por sus respectivos pesos. Esta función es la función escalón, que devuelve 1 si la suma es mayor que un umbral $\\mathcal{U}$ y 0 en caso contrario. Matemáticamente, la salida $\\hat{y}$ de un perceptrón simple se calcula como sigue:\n",
    "\n",
    "$$\n",
    "\\hat{y} = f_a(X \\cdot W) = f_a\\left(\\sum_{i=0}^{n} x_i w_i + b\\right)\n",
    "$$\n",
    "\n",
    "La matriz de pesos tendrá tantas filas como componentes tiene el vector de entrada. De hecho, podemos tener varias salidas (neuronas) diferentes, por lo que si tenemos más de una, la matriz $W$ tendrá tantas columnas como valores de salida\n",
    "\n",
    "Este proceso se conoce como «inferencia». Vamos a implementarlo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d23bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, n_inputs, n_outputs):\n",
    "        # W: (filas + 1 (bias), columnas)\n",
    "        self.W = np.random.uniform(-0.5, 0.5, (n_inputs + 1, n_outputs))\n",
    "\n",
    "    def activation(self, X):\n",
    "        # Función de activación: función escalón\n",
    "        return np.piecewise(X, [X <= 0, 0 < X], [0, 1])\n",
    "        \n",
    "    def inference(self, X):\n",
    "        if len(X.shape) == 1:\n",
    "            X = np.expand_dims(X, axis=0)\n",
    "        # Añadimos una columna entera de 1s (la entrada del bias)\n",
    "        X = np.c_[np.ones(X.shape[0]), X]\n",
    "        # Calculamos la entrada neta\n",
    "        Z = X @ self.W\n",
    "        # Aplicamos la función de activación\n",
    "        return self.activation(Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf48361b",
   "metadata": {},
   "source": [
    "Su funcionamiento sería el siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5039f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tenemos las entradas (3)\n",
    "X = np.array([1, 2, 3])\n",
    "# Creamos el modelo, del que obtendremos dos salidas dadas las entradas\n",
    "model = Perceptron(n_inputs=3, n_outputs=2)\n",
    "# Inferimos a ver qué sale\n",
    "ŷ = model.inference(X)\n",
    "print(ŷ)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f3f9ba",
   "metadata": {},
   "source": [
    "Fantástico, ya tenemos un perceptrón. ¿Para qué nos vale? Realmente para nada. Los valores de los pesos se han inicializado aleatoriamente. Si queremos que de verdad de respuestas a un problema tenemos dos opciones:\n",
    "\n",
    "1. Poner los valores de los pesos nosotros a mano (tedioso, sobre todo si la matriz de pesos es muy grande).\n",
    "2. Que se pongan automáticamente de acuerdo al problema.\n",
    "\n",
    "Evidentemente este segundo paso es el que queremos. De hecho, este paso es lo que hace que estos modelos estén dentro del área del «aprendizaje automático». La neurona va a aprender automáticamente a dar buenos resultados (o al menos lo va a intentar).\n",
    "\n",
    "El esquema de entrenamiento será de **aprendizaje supervisado**, esto es, el modelo aprenderá a partir de un conjunto de datos en el que se encuentran tanto los valores de entrada como los valores de salida esperados a dichas entradas.\n",
    "\n",
    "El algoritmo que usaremos será la [regla delta](https://en.wikipedia.org/wiki/Delta_rule)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b598dfdc",
   "metadata": {},
   "source": [
    "### Regla delta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b866b614",
   "metadata": {},
   "source": [
    "Disponemos de una implementación para la inferencia de un perceptrón, pero no sabemos los pesos. Para ello, vamos a introducir un algoritmo a través del cual, disponiendo de un conjunto de datos con entradas y salidas esperadas, tratará de encontrar los pesos idóneos para aproximar los valores todo lo posible a los presentados.\n",
    "\n",
    "La regla delta calcula cómo tienen que variar los pesos actuales en función del error que se ha cometido. Esta variación obedece a las siguientes ecuaciones:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\Delta W       &= \\alpha X^t (y - \\hat{y}) \\\\\n",
    "\\Delta \\vec{b} &= \\alpha (y - \\hat{y})\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Siendo:\n",
    "\n",
    "- $\\alpha$: El factor de aprendizaje, generalmente en el intervalo $(0, 1)$\n",
    "- $X^t$: La traspuesta de las entradas.\n",
    "- $y$ e $\\hat{y}$: Las salidas esperada y real de la red, respectivamente.\n",
    "\n",
    "Como se puede observar, la cantidad que variarán los pesos son directamente proporcionales al error cometido (i.e. cuanto mayor es el error más varían) y a la entrada (i.e. cuanto mayor es la entrada, más ha influido en el error).\n",
    "\n",
    "Tras calcular esa variación, basta con sumársela a los pesos para obtener los nuevos, tal y como se expresa a continuación:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "W_{t+1}       &= W_{t}       + \\Delta W_{t+1} \\\\\n",
    "\\vec{b_{t+1}} &= \\vec{b_{t}} + \\Delta \\vec{b_{t}}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Vamos a implementar el cálculo de los errores en un nuevo método."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6ee69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, n_inputs, n_outputs):\n",
    "        self.W = np.random.uniform(-0.5, 0.5, (n_inputs + 1, n_outputs))\n",
    "\n",
    "    def activation(self, X):\n",
    "        # Función de activación: función escalón\n",
    "        return np.piecewise(X, [X <= 0, 0 < X], [0, 1])\n",
    "        \n",
    "    def inference(self, X):\n",
    "        if len(X.shape) == 1:\n",
    "            X = np.expand_dims(X, axis=0)\n",
    "        # Añadimos una columna entera de 1s (la entrada del bias)\n",
    "        X = np.c_[np.ones(X.shape[0]), X]\n",
    "        # Calculamos la entrada neta\n",
    "        Z = X @ self.W\n",
    "        # Aplicamos la función de activación\n",
    "        return self.activation(Z)\n",
    "    \n",
    "    def learn(self, X, y, alpha):\n",
    "        if len(X.shape) == 1:\n",
    "            X = np.expand_dims(X, axis=0)\n",
    "        # Calculamos cuál es la salida para la entrada suministrada\n",
    "        ŷ = self.inference(X)\n",
    "        # Con ella, calculamos el error cometido\n",
    "        error = y - ŷ\n",
    "        # Añadimos una columna entera de 1s (la entrada del bias)\n",
    "        X = np.c_[np.ones(X.shape[0]), X]\n",
    "        # Con el error y las entradas, calculamos lo que variarán los pesos\n",
    "        delta_W = alpha * X.T @ error\n",
    "        # Por último, actualizamos los pesos de nuestra red\n",
    "        self.W = self.W + delta_W"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba97eb38",
   "metadata": {},
   "source": [
    "**NOTA**: Hay un if donde se llama a la función `expand_dims`. Esto es debido a que, cuando el vector de entrada es es un array de una dimensión, cuando se le pide las traspuesta (con `.T`) numpy nos devuelve el mismo vector, sin trasponer, por lo que antes de pedir la traspuesta nos aseguramos de que tiene al menos dos dimensiones. Esto convertiría, por ejemplo, la entrada `[0, 1]` (una dimensión) en la entrada `[[0, 1]]` (dos dimensiones).\n",
    "\n",
    "Con este cálculo, conseguimos que los pesos se acerquen un poquito hacia valores que producen salidas con menor error. Veamos cómo se usaría:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89015093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entradas para la puera OR\n",
    "X = np.array([[0, 0],\n",
    "              [0, 1],\n",
    "              [1, 0],\n",
    "              [1, 1]])\n",
    "# Salidas esperadas para cada una de las entradas\n",
    "y = np.array([[0],\n",
    "              [1],\n",
    "              [1],\n",
    "              [1]])\n",
    "# Creamos el modelo, del que obtendremos dos salidas dadas las entradas\n",
    "model = Perceptron(n_inputs=2, n_outputs=1)\n",
    "# Veamos sus pesos y salidas correspondientes\n",
    "print(f'Pesos antes de \"learn\":\\n {model.W}')\n",
    "print(f'Salida para {X[0]}: {model.inference(X[0])} (esperada {y[0]})')\n",
    "print(f'Salida para {X[1]}: {model.inference(X[1])} (esperada {y[1]})')\n",
    "print(f'Salida para {X[2]}: {model.inference(X[2])} (esperada {y[2]})')\n",
    "print(f'Salida para {X[3]}: {model.inference(X[3])} (esperada {y[3]})')\n",
    "# Ahora, a aprender de nuestro errores\n",
    "model.learn(X[0], y[0], alpha=0.5)\n",
    "model.learn(X[1], y[1], alpha=0.5)\n",
    "model.learn(X[2], y[2], alpha=0.5)\n",
    "model.learn(X[3], y[3], alpha=0.5)\n",
    "print(f'Pesos después de \"learn\":\\n {model.W}')\n",
    "print(f'Salida para {X[0]}: {model.inference(X[0])} (esperada {y[0]})')\n",
    "print(f'Salida para {X[1]}: {model.inference(X[1])} (esperada {y[1]})')\n",
    "print(f'Salida para {X[2]}: {model.inference(X[2])} (esperada {y[2]})')\n",
    "print(f'Salida para {X[3]}: {model.inference(X[3])} (esperada {y[3]})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63da79db",
   "metadata": {},
   "source": [
    "Podemos ver que los pesos han cambiado y, a lo mejor, que las predicciones son más certeras. Un par de apuntes:\n",
    "\n",
    "- Hemos enseñado los cuatro ejemplos de nuestro conjunto de entrenamiento (sí, se llama conjunto de entrenamiento al conjunto con el que entrenamos, en aprendizaje automático somos así de originales). A esto se le conoce como _epoch_. Los entrenamientos se miden en epochs.\n",
    "- La implementación que hemos hecho permite trabajar con matrices en la entrada y salida. Esto quiere decir que el anterior _epoch se podría haber implementado así:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b899b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Perceptron(n_inputs=2, n_outputs=1)\n",
    "print(f'Pesos antes de \"learn\":\\n {model.W}')\n",
    "model.learn(X, y, alpha=0.5)\n",
    "print(f'Pesos después de \"learn\":\\n {model.W}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93eb05aa",
   "metadata": {},
   "source": [
    "Así completamos un epoch en mucho menos tiempo. De hecho, las tarjetas gráficas hacen las operaciones con matrices extremadamente rápidas, y es por ello por lo que se usan tanto en aprendizaje automático.\n",
    "\n",
    "Y ahora que las redes saben aprender de sus errores, vamos a escribir el proceso por el cual aprenderán (o lo intentarán) todo el problema. A este proceso se le llama entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94b6a82",
   "metadata": {},
   "source": [
    "### Entrenamiento de un perceptrón\n",
    "\n",
    "El proceso de entrenamiento es realizar _epochs_ de aprendizaje uno detrás de otro hasta que la red haya aprendido lo que queremos que sepa hacer. O al menos hasta que lo haga «suficientemente» bien. ¡O no! porque siempre puede pasar que la red no aprenda.\n",
    "\n",
    "Aquí vamos a usar como condición de parada un número fijo de _epochs_. Crearemos un nuevo método que llamaremos `train` que entrenará el modelo un número determinado de `epochs` sobre un conjunto de datos de entrenamiento  `X, y` y con un factor de aprendizaje `alpha`.\n",
    "\n",
    "Aprovecharemos y añadiremos un parámetro opcional, `trace`, que indicará cada cuantos epochs nos muestra información por pantalla. Por el momento nos ceñiremos la medida de exactitud (_accuracy_) que es el número resultados acertados con respecto del total. Vamos allá"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfaeaecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, n_inputs, n_outputs):\n",
    "        # Matriz de pesos: (filas: entradas, columnas: salidas, +1: bias)\n",
    "        self.W = np.random.uniform(-0.5, 0.5, (n_inputs + 1, n_outputs))\n",
    "\n",
    "    def activation(self, X):\n",
    "        # Función de activación: función escalón\n",
    "        return np.piecewise(X, [X <= 0, 0 < X], [0, 1])\n",
    "        \n",
    "    def inference(self, X):\n",
    "        if len(X.shape) == 1:\n",
    "            X = np.expand_dims(X, axis=0)\n",
    "        # Añadimos una columna entera de 1s (la entrada del bias)\n",
    "        X = np.c_[np.ones(X.shape[0]), X]\n",
    "        # Calculamos la entrada neta\n",
    "        Z = X @ self.W\n",
    "        # Aplicamos la función de activación\n",
    "        return self.activation(Z)\n",
    "    \n",
    "    def learn(self, X, y, alpha):\n",
    "        if len(X.shape) == 1:\n",
    "            X = np.expand_dims(X, axis=0)\n",
    "        # Calculamos cuál es la salida para la entrada suministrada\n",
    "        ŷ = self.inference(X)\n",
    "        # Con ella, calculamos el error cometido\n",
    "        error = y - ŷ\n",
    "        # Añadimos una columna entera de 1s (la entrada del bias)\n",
    "        X = np.c_[np.ones(X.shape[0]), X]\n",
    "        # Con el error y las entradas, calculamos lo que variarán los pesos\n",
    "        delta_W = alpha * X.T @ error\n",
    "        # Por último, actualizamos los pesos de nuestra red\n",
    "        self.W = self.W + delta_W\n",
    "    \n",
    "    def train(self, X, y, epochs, alpha, trace=1):\n",
    "        for epoch in range(0, epochs):\n",
    "            if epoch % trace == 0:\n",
    "                print(f'Epoch {epoch}: Accuracy: {self.accuracy(X, y)}')\n",
    "            self.learn(X, y, alpha)\n",
    "        print(f'End -> {epochs} epochs, accuracy: {self.accuracy(X, y)}')\n",
    "    \n",
    "    def accuracy(self, X, y):\n",
    "        ŷ = self.inference(X)\n",
    "        return (y == ŷ).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a46d5ec",
   "metadata": {},
   "source": [
    "Ahora vamos a probar a entrenar nuestro perceptrón para una puerta AND de tres entradas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e832a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_AND = np.array([\n",
    "    [0, 0, 0, 0],\n",
    "    [0, 0, 1, 0],\n",
    "    [0, 1, 0, 0],\n",
    "    [0, 1, 1, 0],\n",
    "    [1, 0, 0, 0],\n",
    "    [1, 0, 1, 0],\n",
    "    [1, 1, 0, 0],\n",
    "    [1, 1, 1, 1],\n",
    "])\n",
    "X = DATASET_AND[:, :-1]  # Entradas: Todas las columnas hasta la última\n",
    "y = DATASET_AND[:, -1:]  # Salidas: Todas las columnas desde la última\n",
    "\n",
    "model = Perceptron(n_inputs=3, n_outputs=1)\n",
    "model.train(X, y, 100, 0.1, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d48fee",
   "metadata": {},
   "source": [
    "Bueno, parece que aprende. Vamos a la principal limitación de este modelo. ¿qué pasaría si intentamos entrenar una puerta XOR?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d0014f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_XOR = np.array([\n",
    "    [0, 0, 0],\n",
    "    [0, 1, 1],\n",
    "    [1, 0, 1],\n",
    "    [1, 1, 0],\n",
    "])\n",
    "X = DATASET_XOR[:, :-1]  # Entradas: Todas las columnas hasta la última\n",
    "y = DATASET_XOR[:, -1:]  # Salidas: Todas las columnas desde la última\n",
    "\n",
    "model = Perceptron(n_inputs=2, n_outputs=1)\n",
    "model.train(X, y, 100, 0.1, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025fb615",
   "metadata": {},
   "source": [
    "Da igual el número de _epochs_, factor de aprendizaje o parámetros que usemos. La red nunca aprenderá. La explicación es la siguiente:\n",
    "\n",
    "**Un perceptrón es un [clasificador lineal](https://es.wikipedia.org/wiki/Clasificador_lineal)**, lo que quiere decir que clasifica basándose en la combinación lineal de las entradas. Dicho de otro modo, tiene que haber una recta en el plano (o un plano en un espacio, o ...) que separe los diferentes ejemplos a un lado y a otro.\n",
    "\n",
    "¿Y esto qué? Bueno, el problema con la puerta XOR se ve muy fácilmente en la siguiente imagen:\n",
    "\n",
    "<center>\n",
    "<figure class=\"image\">\n",
    "    <img src=\"images/puertas-or-y-xor.png\" alt=\"Representación en el plano de las puertas OR y XOR\" />\n",
    "    <figcaption><em><strong>Figura 1.</strong>Hay problemas muy simples que no son separables linealmente.</em></figcaption>\n",
    "</figure>\n",
    "</center>\n",
    "\n",
    "Para la puerta OR es fácil encontrar una línea que separe los ejemplos cuyo valor es 1 de los ejemplos cuyo valor es 0. Para la puerta XOR es imposible. A estos problemas se los denomina, respectivamente, separables y no separables linealmente. Y el problema es que en el mundo real apenas hay problemas que sean separables linealmente, por lo que un perceptrón simple no suele ser la mejor opción casi nunca."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887c97b9",
   "metadata": {},
   "source": [
    "## Perceptrón multicapa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfa06ce",
   "metadata": {},
   "source": [
    "El perceptrón multicapa (MLP, del inglés _multilayer perceptron_), representa una evolución significativa del perceptrón simple hacia una arquitectura capaz de abordar la complejidad inherente a problemas no linealmente separables. A diferencia de su predecesor, el MLP incorpora una o más capas ocultas entre la capa de entrada y la capa de salida, lo que le permite modelar funciones no lineales y realizar tareas de clasificación y regresión más sofisticadas.\n",
    "\n",
    "Cada neurona en estas capas ocultas realiza cálculos similares a los del perceptrón simple, pero la introducción de múltiples capas y la aplicación de **funciones de activación no lineales**, como la función sigmoide, ReLU o tanh, en cada neurona, permiten a la red aprender patrones complejos en los datos.\n",
    "\n",
    "El entrenamiento de un perceptrón multicapa se realiza a través del algoritmo de retropropagación, un método que ajusta los pesos de la red de manera iterativa con el objetivo de minimizar la diferencia entre las salidas predichas y las salidas reales (error). Este proceso involucra el cálculo del gradiente de la función de pérdida respecto a cada peso en la red, utilizando el cálculo diferencial, y la actualización de los pesos en la dirección que reduce el error. Gracias a esta capacidad de ajuste fino y a la flexibilidad arquitectónica, los perceptrones multicapa han encontrado aplicaciones en una amplia gama de campos, desde el reconocimiento de voz y de imágenes hasta la modelización del lenguaje natural y la predicción de series temporales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5103e3f5",
   "metadata": {},
   "source": [
    "### ¿Por qué esas dos diferencias cambian tanto el comportamiento de las redes?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7c68b7",
   "metadata": {},
   "source": [
    "Las dos diferencias (varias capas y función de activación no lineal) trabajan conjuntamente para abordar el problema de la no linealidad.\n",
    "\n",
    "Comencemos con el perceptrón de una sola capa. Aunque tengamos varias neuronas en esa capa, cada una funcionará independiente de las demás y decisión será lineal. Por tanto, por muchas neuronas que tenga, podremos dividir el espacio de entrada en muchas regiones diferentes, pero los límites de estas regiones estarán limitadas a dichos planos, por lo que podrán clasificar más de dos grupos, pero los grupos deberán ser linealmente separables.\n",
    "\n",
    "¿Y por qué no basta con añadir más capas? ¿Por qué ese requisito de la no linealidad en las funciones de activación? Bueno, la respuesta es que una combinación lineal de funciones lineales sigue siendo una función lineal. Veámoslo con matrices que intimida más aunque es más sencillo:\n",
    "\n",
    "Una función lineal $f_a$ tiene siempre una matriz asociada a la que llaaremos $M_a$. Ahora, recordemos la fórmula de la salida $ŷ$ de un perceptrón en función de su entrada $X$ con una activación lineal $f_a$:\n",
    "\n",
    "$$\n",
    "ŷ = f_a(X \\cdot W)\n",
    "$$\n",
    "\n",
    "Si tenemos varias capas, digamos 2, la salida de una capa será la entrada de la siguiente, por lo que la función de salida quedaría como sigue:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "S^{(1)} &= f_a(X \\cdot W^{(1)}) \\\\\n",
    "S^{(2)} &= f_a(S^{(1)} \\cdot W^{(2)}) = ŷ \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Ahora bien, dado que la función de activación $f_a$ es lineal, tiene una matriz asociada, por lo que podemos reemplazar la función con un producto de matrices:\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "ŷ &= f_a(S^{(1)} \\cdot W^{(2)}) \\\\\n",
    "  &= W_a \\cdot S^{(1)} \\cdot W^{(2)} \\\\\n",
    "  &= W_a \\cdot W_a \\cdot X \\cdot W^{(1)} W^{(2)} \\\\\n",
    "  &= W'_a \\cdot X \\cdot W'^{(1)} \\\\\n",
    "  &= f_a' (X \\cdot W'^{(1)})\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Sin funciones de activación no lineales, el perceptrón multicapa no podrá aprender relaciones no lineales de los datos, básicamente tendría las mismas capacidades que una red con una sola capa. Así que si hay una relación no lineal entre la entrada y la salida, o hay interacciones entre las variables, la red no será capaz de aprenderlas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70305b8",
   "metadata": {},
   "source": [
    "### Inferencia en el perceptrón multicapa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e970bf",
   "metadata": {},
   "source": [
    "La inferencia es similar a la del perceptrón simple. Lo único que variará es que, como podremos tener varias capas, la salida de cada capa será la entrada de la siguiente, por lo que lo tendremos que implementar como un bucle de inferencias capa a capa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc391dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultilayerPerceptron:\n",
    "    def __init__(self, n_inputs, n_hidden, n_outputs):\n",
    "        # Matriz de pesos capa 1: (filas: entradas, columnas: salidas)\n",
    "        self.W1 = np.random.uniform(-0.5, 0.5, (n_inputs, n_hidden))\n",
    "        self.b1 = np.random.uniform(-0.5, 0.5, (1, n_hidden))\n",
    "        # Matriz de pesos capa 2: (filas: entradas, columnas: salidas)\n",
    "        self.W2 = np.random.uniform(-0.5, 0.5, (n_hidden, n_outputs))\n",
    "        self.b2 = np.random.uniform(-0.5, 0.5, (1, n_outputs))\n",
    "\n",
    "    def activation(self, X):\n",
    "        # Función de activación: función sigmoidal\n",
    "        return 1 / (1 + np.exp(-X))\n",
    "        \n",
    "    def inference(self, X):\n",
    "        if len(X.shape) == 1:\n",
    "            X = np.expand_dims(X, axis=0)\n",
    "        # Calculamos la salida de la capa 1\n",
    "        S1 = self.activation(X @ self.W1 + self.b1)\n",
    "        # Calculamos la salida de la capa 2\n",
    "        S2 = self.activation(S1 @ self.W2 + self.b2)\n",
    "        return S2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc781b9",
   "metadata": {},
   "source": [
    "Su funcionamiento sería el siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a69d9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tenemos las entradas (3)\n",
    "X = np.array([1, 2, 3])\n",
    "# Creamos el modelo, del que obtendremos dos salidas dadas las entradas\n",
    "model = MultilayerPerceptron(n_inputs=3, n_hidden=2, n_outputs=2)\n",
    "# Inferimos a ver qué sale\n",
    "ŷ = model.inference(X)\n",
    "print(ŷ)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0975b31f",
   "metadata": {},
   "source": [
    "Ya tenemos la inferencia programada. Ahora vamos con el algoritmo a través del que aprende la red. Ya hemos visto que la regla delta no nos vale porque para las capas ocultas no sabemos la salida esperada y, por tanto, no sabemos lo que nos estamos equivocando en ellas. Usaremos un truco, que es usar el error de las capas posteriores para estimar el error de la capa en la que nos encontramos, y usar la derivada de la función de activación para saber hacia qué punto desciende el error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9eb3f8a",
   "metadata": {},
   "source": [
    "### Regla delta generalizada (_backpropagation_) y entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6181a325",
   "metadata": {},
   "source": [
    "Consiste en propagar desde la última capa hasta la primera el error existente entre el valor $ŷ$ que devuelve la red para la entrada $X$ y el valor de salida esperado $y$.\n",
    "\n",
    "Lo primero que hay que hacer es calcular el error cometido en cada una de las capas para actualizar sus correspondientes pesos. La clave aquí es que hay que calcular **primero el error de la última capa**, y luego el error en las capas anteriores a partir del error inmediatamente posterior. Este error se denote como $\\vec{\\delta^(k)}$ y se define como sigue:\n",
    "\n",
    "$$\n",
    "\\vec{\\delta^{(k)}} =\n",
    "  \\left\\{\n",
    "    \\begin{array}{lcc}\n",
    "      &(y - ŷ) &\\odot f'_a(S^(k))                              & si & k = L \\\\\n",
    "      &\\vec{\\delta^{(k+1)}} \\cdot W^{(k+1)T} &\\odot f'_a(S^(k)) & si & k < L\n",
    "    \\end{array}\n",
    "  \\right.\n",
    "$$\n",
    "\n",
    "Tras calcular los errores de todas las capas, las matrices de cambio de pesos se definen de forma muy parecida a la regla delta, sólo que con los nuevos errores:\n",
    "\n",
    "$$\n",
    "\\Delta W^{(k)} = \\alpha S^{(k-1)T} \\delta^{(k)}\n",
    "$$\n",
    "\n",
    "Con todos los $\\Delta W^{(k)}$ calculados podemos actualizar los pesos de cada capa $k$ de la red. De esta manera habríamos realizdo un paso de aprendizaje en nuestro proceso de entrenamiento.\n",
    "\n",
    "Ahora implementaremos tanto el algoritmo de aprendizaje como el proceso de entrenamiento en nuestro perceptrón, ya que este no cambia: al ser un esquema de aprendizaje supervisado, el principio es el mismo. Además, implementaremos un nuevo indicador del error, el RMSE, ya que al ser la función de activación una sigmoidal, jamás llegará a los valores 0 o 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1b6d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultilayerPerceptron:\n",
    "    def __init__(self, n_inputs, n_hidden, n_outputs):\n",
    "        # Matriz de pesos capa 1: (filas: entradas, columnas: salidas)\n",
    "        self.W1 = np.random.uniform(-0.5, 0.5, (n_inputs, n_hidden))\n",
    "        self.b1 = np.random.uniform(-0.5, 0.5, (1, n_hidden))\n",
    "        # Matriz de pesos capa 2: (filas: entradas, columnas: salidas)\n",
    "        self.W2 = np.random.uniform(-0.5, 0.5, (n_hidden, n_outputs))\n",
    "        self.b2 = np.random.uniform(-0.5, 0.5, (1, n_outputs))\n",
    "\n",
    "    def activation(self, X):\n",
    "        # Función de activación: función sigmoidal\n",
    "        return 1 / (1 + np.exp(-X))\n",
    "    \n",
    "    def d_activation(self, X):\n",
    "        # Derivada de la función de activación\n",
    "        return X * (1 - X)\n",
    "        \n",
    "    def inference(self, X):\n",
    "        if len(X.shape) == 1:\n",
    "            X = np.expand_dims(X, axis=0)\n",
    "        # Calculamos la salida de la capa 1\n",
    "        self.S1 = self.activation(X @ self.W1 + self.b1)\n",
    "        # Calculamos la salida de la capa 2\n",
    "        self.S2 = self.activation(self.S1 @ self.W2 + self.b2)\n",
    "        return self.S2\n",
    "    \n",
    "    def learn(self, X, y, alpha):\n",
    "        if len(X.shape) == 1:\n",
    "            X = np.expand_dims(X, axis=0)\n",
    "        # Calculamos cuál es la salida para la entrada suministrada\n",
    "        ŷ = self.inference(X)\n",
    "        # Con ella, calculamos el error y la matriz de actualización de la última capa\n",
    "        d2 = (y - ŷ) * self.d_activation(ŷ)\n",
    "        dW2 = alpha * self.S1.T @ d2\n",
    "        db2 = alpha * np.ones((1, d2.shape[0])) @ d2\n",
    "        # Lo mismo pero con la primera capa\n",
    "        d1 = d2 @ self.W2.T * self.d_activation(self.S1)\n",
    "        dW1 = alpha * X.T @ d1\n",
    "        db1 = alpha * np.ones((1, d1.shape[0])) @ d1\n",
    "        # Por último, actualizamos los pesos de nuestra red\n",
    "        self.W1 = self.W1 + dW1\n",
    "        self.b1 = self.b1 + db1\n",
    "        self.W2 = self.W2 + dW2\n",
    "        self.b2 = self.b2 + db2\n",
    "    \n",
    "    def train(self, X, y, epochs, alpha, trace=1):\n",
    "        for epoch in range(0, epochs):\n",
    "            if epoch % trace == 0:\n",
    "                accuracy, error = self.measures(X, y)\n",
    "                print(f'Epoch {epoch}: Accuracy: {accuracy}, RMSE: {error}')\n",
    "            self.learn(X, y, alpha)\n",
    "        accuracy, error = self.measures(X, y)\n",
    "        print(f'End -> {epoch}: Accuracy: {accuracy}, RMSE: {error}')\n",
    "    \n",
    "    def measures(self, X, y):\n",
    "        ŷ = self.inference(X)\n",
    "        accuracy = (y == ŷ).mean()\n",
    "        rmse = np.sqrt(np.mean((y - ŷ)**2))\n",
    "        return accuracy, rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86b2ce8",
   "metadata": {},
   "source": [
    "Hay un detalle a la hora de actualizar los bias. Sólo hay un bias por neurona, por lo que si trabajamos con conjuntos de datos en lugar de ejemplos sueltos, hay que tenerlo en cuenta. Por eso se multiplica por un vector de 1s de la misma longitud que la de neuronas.\n",
    "\n",
    "Ahora vamos a probar a entrenar nuestro perceptrón multicapa para una puerta OR de tres entradas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d2b503",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_AND = np.array([\n",
    "    [0, 0, 0, 0],\n",
    "    [0, 0, 1, 1],\n",
    "    [0, 1, 0, 1],\n",
    "    [0, 1, 1, 1],\n",
    "    [1, 0, 0, 1],\n",
    "    [1, 0, 1, 1],\n",
    "    [1, 1, 0, 1],\n",
    "    [1, 1, 1, 1],\n",
    "])\n",
    "X = DATASET_AND[:, :-1]  # Entradas: Todas las columnas hasta la última\n",
    "y = DATASET_AND[:, -1:]  # Salidas: Todas las columnas desde la última\n",
    "\n",
    "model = MultilayerPerceptron(n_inputs=3, n_hidden=2, n_outputs=1)\n",
    "model.train(X, y, 1000, 0.5, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582ee9ab",
   "metadata": {},
   "source": [
    "Veamos qué tal predice nuestro conjunto de datos de la puerta AND tras el entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014624c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ŷ = model.inference(X)\n",
    "np.piecewise(ŷ, [ŷ < 0.5, 0.5 <= ŷ], [0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04410381",
   "metadata": {},
   "source": [
    "Bueno, parece que aprende. Vamos a ver qué tal lo hace con la puerta XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bc58eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_XOR = np.array([\n",
    "    [0, 0, 0],\n",
    "    [0, 1, 1],\n",
    "    [1, 0, 1],\n",
    "    [1, 1, 0],\n",
    "])\n",
    "X = DATASET_XOR[:, :-1]  # Entradas: Todas las columnas hasta la última\n",
    "y = DATASET_XOR[:, -1:]  # Salidas: Todas las columnas desde la última\n",
    "\n",
    "model = MultilayerPerceptron(n_inputs=2, n_hidden=3, n_outputs=1)\n",
    "model.train(X, y, 1000, 0.5, 100)\n",
    "ŷ = model.inference(X)\n",
    "np.piecewise(ŷ, [ŷ < 0.5, 0.5 <= ŷ], [0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca613fb",
   "metadata": {},
   "source": [
    "¡Fantástico! ¡Parece que lo ha aprendido! Acabamos de resolver el problema que causó que durante una decada ni se hablase de redes neuronales. Hablamos de uno de los múltiples [Inviernos de la IA](https://en.wikipedia.org/wiki/AI_winter). En este en concreto, se abandonó durante algo más de una década la investigación en redes neuronales debido a las limitaciones del perceptrón.\n",
    "\n",
    "Ahora vamos a continuar con nuestro perceptrón multicapa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f19407a",
   "metadata": {},
   "source": [
    "### MLP con varias capas ocultas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16964d35",
   "metadata": {},
   "source": [
    "Una pequeña vuelta de tuerca a nuestra implementación. Con una única capa oculta nos basta para aproximar cualquier función (son [aproximadores universales](https://en.wikipedia.org/wiki/Universal_approximation_theorem) de funciones), pero no son suficientes para generalizar. De hecho, más capas ocultas con menos neuronas en total suelen resolver mejor los problemas gracias a su capacidad de generalización.\n",
    "\n",
    "Por tanto, reimplementaremos el perceptrón, esta vez para que admita un número indefinido de capas y neuronas. Concretamente, en el constructor se recibirá una lista de enteros cuyo primer valor será el número de valores de entrada, su último valor el número de neuronas de salida y los valores intermedios el número de neuronas de cada una de las capas. Por ejemplo, `layers = [2, 3, 4, 1]` se correspondería con 2 neuronas de entrada, una capa oculta de 3 neuronas, otra capa oculta de 4 neuronas y una capa de salida de una neurona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8189f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultilayerPerceptron:\n",
    "    def __init__(self, layers):\n",
    "        # Los pesos de cada capa. Añadimos un elemento vacío al principio para que\n",
    "        # los índices se correspondan con los de las funciones.\n",
    "        self.W = [None] + [\n",
    "            np.random.uniform(-0.5, 0.5, (prev_neurons, curr_neurons))\n",
    "            for prev_neurons, curr_neurons in zip(layers[:-1], layers[1:])\n",
    "        ]\n",
    "        # Los bias de cada capa. Lo mismo que antes con el elemento vacío al ppio.\n",
    "        self.b = [None] + [\n",
    "            np.random.uniform(-0.5, 0.5, (1, curr_neurons))\n",
    "            for curr_neurons in layers[1:]\n",
    "        ]\n",
    "        # La caché de salidas intermedias\n",
    "        self.S = [None for _ in layers]\n",
    "\n",
    "    def activation(self, X):\n",
    "        # Función de activación: función sigmoidal\n",
    "        return 1 / (1 + np.exp(-X))\n",
    "    \n",
    "    def d_activation(self, X):\n",
    "        # Derivada de la función de activación\n",
    "        return X * (1 - X)\n",
    "        \n",
    "    def inference(self, X):\n",
    "        if len(X.shape) == 1:\n",
    "            X = np.expand_dims(X, axis=0)\n",
    "        # La salida 0 será la entrada a la red\n",
    "        self.S[0] = X\n",
    "        # El resto de salidas se calculan a partir de la salida anterior\n",
    "        for i in range(1, len(self.S)):\n",
    "            self.S[i] = self.activation(self.S[i-1] @ self.W[i] + self.b[i])\n",
    "        # La última de nuestras salidas es la salida de la red\n",
    "        return self.S[-1]\n",
    "    \n",
    "    def learn(self, X, y, alpha):\n",
    "        if len(X.shape) == 1:\n",
    "            X = np.expand_dims(X, axis=0)\n",
    "        # Calculamos todas las salidas de nuestra red\n",
    "        ŷ = self.inference(X)\n",
    "        # Con ellas, vamos calculando los sucesivos errores y matrices de\n",
    "        # actualización. Comenzamos por la última capa:\n",
    "        δ = (y - ŷ) * self.d_activation(ŷ)\n",
    "        δW = [alpha * self.S[-2].T @ δ]\n",
    "        δb = [alpha * np.ones((1, δ.shape[0])) @ δ]\n",
    "        # Seguimos por las capas intermedias hasta el principio de la red\n",
    "        for i in range(len(self.S) - 2, 0, -1):\n",
    "            δ = δ @ self.W[i+1].T * self.d_activation(self.S[i])\n",
    "            δW.append(alpha * self.S[i-1].T @ δ)\n",
    "            δb.append(alpha * np.ones((1, δ.shape[0])) @ δ)\n",
    "        # Por último, actualizamos los pesos de nuestra red\n",
    "        for i, (δW, δb) in enumerate(zip(reversed(δW), reversed(δb)), 1):\n",
    "            self.W[i] = self.W[i] + δW\n",
    "            self.b[i] = self.b[i] + δb\n",
    "    \n",
    "    def train(self, X, y, epochs, alpha, trace=1):\n",
    "        for epoch in range(1, epochs):\n",
    "            if epoch % trace == 0:\n",
    "                accuracy, error = self.measures(X, y)\n",
    "                print(f'Epoch {epoch}: Accuracy: {accuracy}, RMSE: {error}')\n",
    "            self.learn(X, y, alpha)\n",
    "        accuracy, error = self.measures(X, y)\n",
    "        print(f'End -> {epoch}: Accuracy: {accuracy}, RMSE: {error}')\n",
    "    \n",
    "    def measures(self, X, y):\n",
    "        ŷ = self.inference(X)\n",
    "        accuracy = (y == ŷ).mean()\n",
    "        rmse = np.sqrt(np.mean((y - ŷ)**2))\n",
    "        return accuracy, rmse\n",
    "\n",
    "\n",
    "DATASET_XOR = np.array([\n",
    "    [0, 0, 0],\n",
    "    [0, 1, 1],\n",
    "    [1, 0, 1],\n",
    "    [1, 1, 0],\n",
    "])\n",
    "X = DATASET_XOR[:, :-1]  # Entradas: Todas las columnas hasta la última\n",
    "y = DATASET_XOR[:, -1:]  # Salidas: Todas las columnas desde la última\n",
    "\n",
    "model = MultilayerPerceptron([2, 2, 2, 1])\n",
    "model.train(X, y, 10000, 0.5, 1000)\n",
    "ŷ = model.inference(X)\n",
    "np.piecewise(ŷ, [ŷ < 0.5, 0.5 <= ŷ], [0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a2e0b3",
   "metadata": {},
   "source": [
    "El problema del XOR tiene bastantes mínimos locales que hacen que en ocasiones el entrenamiento se quede estancado en un punto concreto. Por ello, probablemente se necesiten varias ejecuciones del entrenamiento para tener un modelo que sea capaz de clasificar esta puerta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8669ae1c",
   "metadata": {},
   "source": [
    "## Implementación con Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df0d89a",
   "metadata": {},
   "source": [
    "Hasta ahora hemos implementado desde cero un perceptrón y un perceptrón multicapa. Sin embargo, existen bibliotecas de alto nivel que nos permiten crear y entrenar redes neuronales de manera más eficiente y sencilla. Una de las bibliotecas más populares para este propósito es Keras, una API de redes neuronales de código abierto que se ejecuta sobre TensorFlow, Theano o CNTK."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a030ea27",
   "metadata": {},
   "source": [
    "### Conjunto de datos sobre el que trabajar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cab3a8",
   "metadata": {},
   "source": [
    "Ahora estamos trabajando con modelos que aprenden bajo un esquema de aprendizaje supervisado por lo que necesitamos un conjunto de datos con entradas y sus salidas esperadas de los que aprender.\n",
    "\n",
    "Keras nos proporciona varios conjuntos de datos bajo el módulo `datasets`. De ellos vamos a usar el de `mnist`, que es un conjunto de 70000 imágenes (60000 en el conjunto de entrenamiento, 10000 en el conjunto de test) de dígitos escritos a mano de $28 \\times 28$ píxeles junto con su correspondiente etiqueta indicando qué número es exactamente.\n",
    "\n",
    "<center>\n",
    "<figure class=\"image\">\n",
    "    <img src=\"https://upload.wikimedia.org/wikipedia/commons/2/27/MnistExamples.png\" alt=\"Conjunto de datos MNIST\" />\n",
    "    <figcaption><em><strong>Figura 1.</strong>Ilustración de imágenes de ejemplo del conjunto de datos MNIST. Fuente: [Wikipedia](https://es.wikipedia.org/wiki/Base_de_datos_MNIST).</em></figcaption>\n",
    "</figure>\n",
    "</center>\n",
    "\n",
    "Los _datasets_ del módulo ofrecen una función `load_data` para cargar los datos, descargándolos si es necesario. En el caso del `mnist`, los datos vienen separados en dos conjuntos, entrenamiento y test, en dos partes cada uno, entradas y salidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbe4c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "print(f'Training shape: {x_train.shape} input, {y_train.shape} output')\n",
    "print(f'Test shape:     {x_test.shape} input, {y_test.shape} output')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44be97c4",
   "metadata": {},
   "source": [
    "Con los conjuntos de datos cargados y preparados, ya tenemos suficiente para trabajar. ¡Vamos allá!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb962f6e",
   "metadata": {},
   "source": [
    "### El API secuencial\n",
    "\n",
    "La primera forma que vamos a ver para crear modelos en `keras` es su API secuencial. Es la más sencilla, ya que el modelo se crea como una lista de capas sucesivas y por debajo este las conecta (esto es, las salidas de una capa con las entradas de la siguiente). Por ejemplo, el perceptrón que implementamos anteriormente (bueno, lo más parecido a lo que podemos llegar) se implementaría como sigue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74f1198",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(3, activation='sigmoid', input_shape = [2,]),\n",
    "    tf.keras.layers.Dense(2, activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid'),\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c259f900",
   "metadata": {},
   "source": [
    "Esto sería únicamente la arquitectura. Para poder entrenarlo tendríamos que especificar de qué manera calculamos el error (en nuestro caso antes usábamos la diferencia entre valor esperado y valor inferido), qué optimizador (en nuestro caso usábamos _backpropagation_) y si queremos o no alguna métrica más (antes sacábamos exactitud y rmse)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dedf7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss = tf.keras.losses.MeanSquaredError(),\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=0.5),\n",
    "    metrics = [tf.keras.metrics.Accuracy()]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89beb117",
   "metadata": {},
   "source": [
    "Con esto podemos entrenar el modelo. Por ejemplo, en el problema de la puerta XOR de antes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828e97f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_XOR = np.array([\n",
    "    [0, 0, 0],\n",
    "    [0, 1, 1],\n",
    "    [1, 0, 1],\n",
    "    [1, 1, 0],\n",
    "])\n",
    "X = DATASET_XOR[:, :-1]  # Entradas: Todas las columnas hasta la última\n",
    "y = DATASET_XOR[:, -1:]  # Salidas: Todas las columnas desde la última\n",
    "\n",
    "model.fit(X, y, epochs=1000, verbose=0)\n",
    "ŷ = model.predict(X)\n",
    "np.piecewise(ŷ, [ŷ < 0.5, 0.5 <= ŷ], [0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160aaa82",
   "metadata": {},
   "source": [
    "Ahora bien, con el conjunto de datos de `mnist` tenemos que hacer algunos cambios porque este modelo no nos vale:\n",
    "\n",
    "1. La entrada es una matriz de $28 \\times 28$, y hasta ahora hemos visto modelos que esperan un vector de entrada. Afortunadamente para esto último `keras` proporciona una capa denominada `Flatten`, que simplifica nuestros datos eliminando la información sobre la estructura 2D de la imagen.\n",
    "2. La salida de nuestro modelo no es 0 o 1. Es un valor del 0 al 10. Si fuese una clasificación binaria valdría, pero es una clasificación denominada \"multiclase\". Para estos casos, se suele trabajar con varias clasificaciones binarias, una para cada clase. Como tenemos 10 posibles valores de salida, usaremos 10 neuronas, una para cada clase, y como función de activación y loss usaremos dos funciones que trabajan juntas para hacer las labores de clasificación. Esto lo veremos más adelante; por ahora basta pensar que funcionan juntas en este tipo de problemas multiclase.\n",
    "3. El learning_rate que se suele usar para empezar a entrenar modelos suele ser bajo, del orden de 0.1 o inferior. Usaremos los valroes por defecto de nuestro optimizador.\n",
    "4. Existe una métrica más adecuada para nuestro cálculo del error que la simple exactitud.\n",
    "\n",
    "Con estos cambios nuestro modelo quedaría como sigue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1086230",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    # La primera capa del modelo toma entradas de 28x28 y las \"aplana\"\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(3, activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(2, activation='sigmoid'),\n",
    "    # La salida la cambiamos a 10 neuronas y una función de activación softmax\n",
    "    tf.keras.layers.Dense(10, activation='softmax'),\n",
    "])\n",
    "model.compile(\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    optimizer = tf.keras.optimizers.SGD(),\n",
    "    metrics = [tf.keras.metrics.SparseCategoricalAccuracy()]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a81d2ec",
   "metadata": {},
   "source": [
    "Es curioso ver cómo han cambiado los parámetros. De 2 entradas que teníamos antes a 768, con lo que ahora tenemos que ajustar 2393 parámetros en lugar de sólo 20. Bueno, veamos qué tal se comporta con el conjunto de entrenamiento de `mnist`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6118d765",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09407a3f",
   "metadata": {},
   "source": [
    "Como vemos, el método `fit` devuelve un objeto al que apuntará la variable `history`. Este objeto guarda un histórico de todos los indicadores de nuestro proceso de entrenamiento (incluidas las métricas especificadas en el método `compile`) _epoch_ por _epoch_. Podemos aprovechar este objeto para imprimir por pantalla la evolución del entrenamiento, lo que nos daría información acerca de cómo ha ido:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477b3769",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history).plot()\n",
    "plt.xlabel('Epoch num.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd81063",
   "metadata": {},
   "source": [
    "Esta gráfica nos dice más o menos tres cosas:\n",
    "\n",
    "1. El error (_loss_) va bajando durante el entrenamiento, cosa que está muy bien.\n",
    "2. La exactitud (_accuracy_) va subiendo, cosa que también está muy bien.\n",
    "3. La exactitud sigue siendo baja, por lo que queda mucho que entrenar.\n",
    "\n",
    "Vamos a ver la evolución de los indicadores con unos cuantos _epochs_ más de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9ece09",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train, epochs=100)\n",
    "pd.DataFrame(history.history).plot()\n",
    "plt.xlabel('Epoch num.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f84fea",
   "metadata": {},
   "source": [
    "Hemos realizado 100 epochs a partir del modelo ya entrenado y parece que, aunque sigue evolucionando, su capacidad predictiva deja un poco que desear. Vamos a entrenar un modelo un poco más complejo a ver si somos capaces de que la precisión aumente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c940c140",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(5, activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(5, activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax'),\n",
    "])\n",
    "model.compile(\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    optimizer = tf.keras.optimizers.SGD(),\n",
    "    metrics = [tf.keras.metrics.SparseCategoricalAccuracy()]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3418f7c1",
   "metadata": {},
   "source": [
    "Para el entrenamiento vamos a hacer uso de un argumento más, `validation_split=0.1`. Con este argumento el conjunto de entrenamiento se separará en 2 conjuntos diferentes durante cada _epoch_: uno con el 90% de los datos, con el que se realizará el entrenamiento y otro con el 10% de datos restante para evaluar la red tras el entrenamiento de ese epoch. Vamos allá:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3eedb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train, epochs=100, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b09442",
   "metadata": {},
   "source": [
    "Con este argumento podemos ser capaces de tener una intuición no solo de cómo va aprendiendo la red, sino de su evolución en la capacidad de predicción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac18131",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history).plot()\n",
    "plt.xlabel('Epoch num.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3019070d",
   "metadata": {},
   "source": [
    "Un entrenamiento que tiene mejor pinta. parece que más o menos el modelo acierta un 77% de los casos en entrenamiento y un 74% de los casos en validación. No es una diferencia muy grande, así que podemos decir que no está sobreespecializado (sufriendo _overfitting_).\n",
    "\n",
    "Si damos como bueno este modelo, el siguiente (y último paso) para determinar si es apto para usarse en el mundo real sería comprobar con el conjunto de test. Veamos como se comporta con este:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd98715b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d5ed83",
   "metadata": {},
   "source": [
    "Aproximadamente un 75% de exactitud, no está mal. O no. Todo depende del problema, ya que un 75% de aciertos en reconocer un cáncer de mama no es una estadística muy halagüeña. Pero no nos preocupemos, hay más modelos que aprenderemos para abordar diferentes casos. Por ahora, estamos aprendiendo las diferentes formas de aprender modelos con Keras. Vamos a por la segunda forma."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a00b366",
   "metadata": {},
   "source": [
    "### El API funcional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e573f1c0",
   "metadata": {},
   "source": [
    "Muchos modelos de aprendizaje profundo son grafos acíclicos dirigidos (DAG, del inglés _directed acyclic graph_) donde cada nodo se corresponde con una capa. El API funcional nos permite construirlos en términos de entradas y salidas de capas.\n",
    "\n",
    "Esto es debido a que, en el momento que queremos interconectar las capas de una manera diferente (por ejemplo una entrada común que va a dos subredes independientes que luego convergen en una capa común), el API secuencial no nos sirve.\n",
    "\n",
    "Nos encontraremos con redes complicadas de este tipo más adelante. Por ahora nos ceñiremos a nuestro perceptrón multicapa y su definición con este API. Veamos cómo sería:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927605cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos las capas con sus conexiones explícitamente\n",
    "input_layer = tf.keras.layers.Input(shape=(28, 28))\n",
    "flatten = tf.keras.layers.Flatten()(input_layer)\n",
    "hidden_1 = tf.keras.layers.Dense(5, activation='sigmoid')(flatten)\n",
    "hidden_2 = tf.keras.layers.Dense(5, activation='sigmoid')(hidden_1)\n",
    "output_layer = tf.keras.layers.Dense(10, activation='softmax')(hidden_2)\n",
    "# Creamos el modelo especificando cuáles son las entradas y cuáles las salidas\n",
    "model = tf.keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "# La arquitectura ya está definida, así que ya podemos compilarlo\n",
    "model.compile(\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    optimizer = tf.keras.optimizers.SGD(),\n",
    "    metrics = [tf.keras.metrics.SparseCategoricalAccuracy()]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d0aa02",
   "metadata": {},
   "source": [
    "Exactamente los mismos parámetros y la misma arquitectura, sólo que definido de manera diferente. Ahora vamos a realizar un nuevo entrenamiento para ver si la tendencia es similar a la anterior (que esperemos que lo sea):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e09d907",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train, epochs=100, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc987419",
   "metadata": {},
   "source": [
    "Desde luego por los valores de los indicadores en entrenamiento y en validación, parece que se está comportando de la misma manera. Veamos la tendencia en una gráfica, que siempre es más agradecida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d4bbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history).plot()\n",
    "plt.xlabel('Epoch num.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f6ae5f",
   "metadata": {},
   "source": [
    "En efecto, se parecen bastante. Y menos mal, porque si no todo esto no valdría para nada. Ya conocemos las dos formas que tiene Keras para definir modelos de redes neuronales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89064f29",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df01c480",
   "metadata": {},
   "source": [
    "## Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89233727",
   "metadata": {},
   "source": [
    "Hemos cubierto un espectro amplio y fundamental del aprendizaje automático y el aprendizaje profundo. Cada uno de estos modelos nos ha ofrecido una perspectiva única sobre la resolución de problemas mediante algoritmos de inteligencia artificial, destacando tanto sus fortalezas como sus limitaciones.\n",
    "\n",
    "Con el **perceptrón simple**, hemos establecido las bases del aprendizaje automático, comprendiendo la importancia de la linealidad y sus limitaciones inherentes al enfrentarnos a problemas más complejos y no lineales. Este modelo nos sirve como un recordatorio de que, aunque algunos problemas pueden ser abordados con soluciones simples y elegantes, el mundo real a menudo demanda enfoques más sofisticados.\n",
    "\n",
    "Avanzando hacia el perceptrón multicapa y el aprendizaje profundo, exploramos la capacidad de estas redes para modelar complejidades mucho mayores gracias a sus capas ocultas y funciones de activación no lineales. Sin embargo, también observamos la creciente complejidad en su implementación y la necesidad de considerar aspectos críticos como la elección de funciones de activación adecuadas, la inicialización de pesos y técnicas para mejorar el entrenamiento y evitar el sobreajuste.\n",
    "\n",
    "La introducción de Keras representa un hito, facilitando la implementación de perceptrones multicapa y abriendo la puerta a experimentar con arquitecturas más avanzadas de manera intuitiva y eficiente. Keras no solo simplifica el proceso de construcción y entrenamiento de modelos sino que también democratiza el acceso a tecnologías de aprendizaje profundo, permitiendo a investigadores y desarrolladores concentrarse en la resolución de problemas sin preocuparse excesivamente por los detalles de bajo nivel.\n",
    "\n",
    "Finalmente, al considerar las posibilidades que ofrece la API de Subclassing de Keras, reconocemos la flexibilidad y el poder que se nos otorga para diseñar modelos que se salen del paradigma tradicional, abordando problemas que requieren estructuras dinámicas y personalizadas. Esto subraya la importancia de entender los fundamentos detrás de cada herramienta y modelo, ya que solo así podemos expandir creativamente sus límites."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2147861b",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc657f4",
   "metadata": {},
   "source": [
    "## Referencias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d54d756",
   "metadata": {},
   "source": [
    "[1] Guía para la creación de capas y modelos personalizados (<https://www.tensorflow.org/guide/keras/custom_layers_and_models>)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582efec2",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "<div><img style=\"float: right; width: 120px; vertical-align:top\" src=\"https://mirrors.creativecommons.org/presskit/buttons/88x31/png/by-nc-sa.png\" alt=\"Creative Commons by-nc-sa logo\" />\n",
    "\n",
    "[Volver al inicio](#top)\n",
    "\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
