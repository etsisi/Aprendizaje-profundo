{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div><img style=\"float: right; width: 120px; vertical-align:middle\" src=\"https://www.upm.es/sfs/Rectorado/Gabinete%20del%20Rector/Logos/EU_Informatica/ETSI%20SIST_INFORM_COLOR.png\" alt=\"ETSISI logo\" />\n",
    "\n",
    "# Generando música<a id=\"top\"></a>\n",
    "\n",
    "<i>Última actualización: 2024-03-07</small></i></div>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "En este _notebook_ vamos a crear un modelo que aprenderá a tocar «música». El entrecomillado es porque, para tocar música bien, se necesitan modelos y técnicas muy complejas que quedan un poco fuera del alcance de un tutorial como éste.\n",
    "\n",
    "Sin embargo, en este ejercicio tocaremos los fundamentos de la generación basada en notas y acordes y, junto con los modelos que veremos más adelante en este tema más conceptos como redes bidireccionales e incrustaciones de la parte de procesamiento del lenguaje natural (NLP, del inglés _natural language processing_), podremos generar música con un poco más de sentido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crearemos un modelo de predicción de notas basado en una secuencia de notas anteriores. Al final habremos aprendido a:\n",
    "\n",
    "- Leer y escribir ficheros midi,\n",
    "- Generar secuencias siguiendo una tipología de red recurrente _one-to-many_, y\n",
    "- Guardar modelos entrenados en disco para entrenarlos en diferentes momentos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliotecas y configuración"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A continuación importaremos las librerías que se utilizarán a lo largo del _notebook_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "import music21\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También vamos a configurar algunos parámetros para adaptar la presentación grafica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "plt.rcParams.update({'figure.figsize': (20, 6),'figure.dpi': 64})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y crearemos los directorios necesarios en caso de que no se hayan creado previamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('tmp', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga y preparación de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empezaremos cargando todas las notas de los archivos `.mid` ubicados en la ruta relativa `datasets/Music`. Estas notas se almacenarán en una lista llamada `notes`. Algunos detalles de implementación:\n",
    "\n",
    "- Para parsear un fichero midi utilizaremos la función `parse(file)` del módulo `converter` de la librería `music21`,\n",
    "- Las notas que queremos obtener están en el atributo `.flat.notes` del midi analizado. Sin embargo, tenemos que tener en cuenta que contiene dos tipos de datos:\n",
    "  - Notas normales, que son del tipo `note.Note`. Si la nota es `note`, almacenaremos directamente en la lista de notas la representación en cadena de `note.pitch`.\n",
    "  - Acordes, que son del tipo `chord.Chord`. Son una lista de notas, y lo que almacenaremos será la lista de sus notas (si el acorde es `chord`, la lista será `chord.normalOrder`) como una cadena de texto donde cada nota irá separada por un punto (`'.'`).\n",
    "\n",
    "Esto no espor capricho; es una forma de representar las notas que facilitará la conversión posterior de las notas generadas en una nueva pista de audio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes = []  # Almacenará todas las notas y acordes de los ficheros\n",
    "\n",
    "for file in glob.glob('datasets/music/doom/*.mid'):\n",
    "    print(f'Parsing {file}')\n",
    "\n",
    "    midi = music21.converter.parse(file)\n",
    "    \n",
    "    for note_or_chord in midi.flat.notes:\n",
    "        if isinstance(note_or_chord, music21.note.Note):\n",
    "            notes.append(str(note_or_chord.pitch))\n",
    "        elif isinstance(note_or_chord, music21.chord.Chord):\n",
    "            notes.append('.'.join(str(n) for n in note_or_chord.normalOrder))\n",
    "notes[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuestro siguiente paso será crear dos diccionarios: `note_to_int` y `int_to_note`. ¿Cuál será su significado? Pues que tenemos la lista de todas las notas de todas las pistas de sonido. Como las redes trabajan con números, no con símbolos, lo que haremos será asignar un valor único a cada nota diferente. Con estos dos diccionarios sabremos traducir de nota a número y de un número a su nota para poder traducir dentro y fuera de la red.\n",
    "\n",
    "Por lo tanto, crearemos estos dos diccionarios con las diferentes notas en orden ascendente, desde 0 hasta el número de notas menos una."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_to_int = {note: i for i, note in enumerate(sorted(set(notes)))}\n",
    "int_to_note = {i: note for i, note in enumerate(sorted(set(notes)))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continuamos con la preparación de los conjuntos de datos. En `notas` tenemos la lista ordenada de notas. Se espera que las notas estén determinadas por la secuencia anterior. Por facilitar la implementación, no hemos creado un nuevo token para indicar que una canción ha terminado, por lo que habrá ciertas pausas que no se correspondan con un compás real. Si te apetece modificarlo, ¡adelante!\n",
    "\n",
    "Lo que crearemos ahora será el conjunto de entrenamiento, las variables `x_train` y `y_train`. `y_train` estará formado por las secuencias de entrada, que tendrán una longitud de 50 (la variable SEQUENCE_LEN, ya creada), mientras que `y_train` tendrá la nota correspondiente a continuación de esa secuencia. Construiremos este conjunto a partir de la lista `notas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQUENCE_LEN = 20\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for i in range(SEQUENCE_LEN, len(notes)):\n",
    "    input_notes = notes[i - SEQUENCE_LEN: i]\n",
    "    output_note = notes[i]\n",
    "    x_train.append([note_to_int[note] for note in input_notes])\n",
    "    y_train.append(note_to_int[output_note])\n",
    "\n",
    "for i in range(10):\n",
    "    print(f'{x_train[i]} -> {y_train[i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Como vamos a alimentar una red recurrente, las dimensiones de entrada deben ser $M \\times T \\times C$, siendo:\n",
    "\n",
    "- $M$: El número de ejemplos, es decir, el número total de secuencias.\n",
    "- $T$: El tamaño de la secuencia, que hemos definido en la constante anterior.\n",
    "- $C$: El número de parámetros que tiene cada elemento de la secuencia, que en nuestro caso es $1$ (cada nota es un único entero).\n",
    "\n",
    "El problema es que las dimensiones de nuestro conjunto de entrenamiento no son esas, por lo que tendremos que remodelar el conjunto de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.reshape(x_train, (len(x_train), SEQUENCE_LEN, 1)) # (M, T, C)\n",
    "\n",
    "print(f'x_train shape: {x_train.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora normalizaremos los datos de entrada para que caigan dentro del intervalo $[0, 1]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train / len(note_to_int)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "print(f'An x_train value: {x_train[0][0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y con los conjuntos creados y listos para entrenar, pasamos a trabajar con el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Implementando y entrenando el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a añadir un nuevo elemento que no habíamos visto hasta ahora pero que es muy útil cuando trabajamos con modelos grandes: un callback para almacenar puntos de control con los estados del modelo. Los argumentos del inicializador de la clase son bastante descriptivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    'tmp/music-generator-{loss:.4f}.keras',\n",
    "    monitor='loss',\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    mode='min'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Ahora crearemos un modelo para que aprenda a predecir la siguiente nota dada una secuencia de notas. El modelo se compilará con la pérdida correspondiente a un problema de clasificación y se utilizará el algoritmo Adam como optimizador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_PREVIOUS = True\n",
    "\n",
    "checkpoints = sorted(glob.glob('tmp/music-generator-*.h5'))\n",
    "if LOAD_PREVIOUS and checkpoints:\n",
    "    print(f'Loading previous model: {checkpoints[0]}')\n",
    "    model = tf.keras.models.load_model(checkpoints[0])\n",
    "else:\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.GRU(512, activation='relu', return_sequences=True, input_shape=x_train.shape[1:]),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.GRU(512, activation='relu', return_sequences=True),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.GRU(512, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(len(set(y_train)), activation='softmax')\n",
    "    ])\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['sparse_categorical_accuracy'],\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora entrenaremos el modelo con nuestro conjunto de datos durante 25 épocas; no son muchas, pero la carga computacional derivada del entrenamiento de este tipo de modelos es bastante pesada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train, epochs=25, callbacks=[checkpoint], batch_size=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de ver la evolución del error, podríamos modificar la creación del modelo para que cargue el mejor punto de control si existe y si queremos (mediante una variable, por ejemplo `LOAD_PREVIOUS`).\n",
    "\n",
    "Ahora, veamos cómo han evolucionado error y exactitud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history).plot()\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Epoch num.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A generar música"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya tenemos un modelo entrenado para generar música. Ahora procederemos a generar una canción. Para hacerlo sencillo, generaremos una canción de N notas (digamos 100, y veremos cómo se comporta. Para ello haremos lo siguiente\n",
    "\n",
    "1. Crear una secuencia aleatoria de inicio del tamaño de secuencia esperado, lo que constituirá nuestra primera entrada,\n",
    "2. Pasar esa secuencia al modelo y recoger la siguiente nota que predice,\n",
    "3. Eliminar la primera nota de la secuencia y añadir la nueva nota al final, lo que constituirá la siguiente secuencia, y\n",
    "4. Continuar así hasta terminar de generar notas.\n",
    "\n",
    "El resultado será una lista con la secuencia y todas las notas generadas. La lista con las notas generadas se llamará `new_song`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = np.random.randint(len(x_train) - 1)\n",
    "pattern = x_train[start]\n",
    "\n",
    "new_song = []\n",
    "for _ in range(100):\n",
    "    X = np.reshape(pattern, (1, SEQUENCE_LEN, 1))\n",
    "\n",
    "    next_note_softmax = model.predict(X, verbose=0)\n",
    "    next_note = np.argmax(next_note_softmax)\n",
    "\n",
    "    new_song.append(int_to_note[next_note])\n",
    "\n",
    "    pattern[:-1] = pattern[1:]\n",
    "    pattern[-1] = next_note / len(note_to_int)\n",
    "    \n",
    "print(f'New song: {new_song}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente fragmento de código transforma la lista de notas en un midi, separando cada nota por medio segundo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's create the midi given the song\n",
    "offset = 0\n",
    "output_notes = []\n",
    "\n",
    "# Create notes and chords according with the specified song\n",
    "for pattern in new_song:\n",
    "    if ('.' in pattern) or pattern.isdigit():\n",
    "        # Pattern is a chord, so let's split into notes and create it\n",
    "        notes = []\n",
    "        for current_note in pattern.split('.'):\n",
    "            new_note = music21.note.Note(int(current_note))\n",
    "            new_note.storedInstrument = music21.instrument.Violin()\n",
    "            notes.append(new_note)\n",
    "        new_chord = music21.chord.Chord(notes)\n",
    "        new_chord.offset = offset\n",
    "        output_notes.append(new_chord)\n",
    "    else:\n",
    "        # Pattern is a note, so let's create it and that's all\n",
    "        new_note = music21.note.Note(pattern)\n",
    "        new_note.offset = offset\n",
    "        new_note.storedInstrument = music21.instrument.Violin()\n",
    "        output_notes.append(new_note)\n",
    "\n",
    "    # Increase note ofet so no notes stack\n",
    "    offset += 0.5\n",
    "\n",
    "midi_stream = music21.stream.Stream(output_notes)\n",
    "midi_stream.write('midi', fp='tmp/test_output.mid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como puedes ver, el modelo ha generado una canción. Sí, no respetamos los tiempos, hay secuencias que no tienen sentido (los cortes entre canciones), etc., pero nos ha servido como experimento para ver el desarrollo de un proyecto de principio a fin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hemos implementado un modelo recurrente que aprende de muchos datos para resolver un problema _de_uno_a_muchos_: generar música a partir de una semilla inicial.\n",
    "\n",
    "Os animamos a modificar la arquitectura para ver si encontráis una que genere canciones que tengan algún sentido, y a probar a añadir entradas aleatorias durante el entrenamiento para que durante la inferencia se puedan añadir dichas entradas para alterar la generación de melodías."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "<div><img style=\"float: right; width: 120px; vertical-align:top\" src=\"https://mirrors.creativecommons.org/presskit/buttons/88x31/png/by-nc-sa.png\" alt=\"Creative Commons by-nc-sa logo\" />\n",
    "\n",
    "[Volver al inicio](#top)\n",
    "\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
