{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4480ff39",
   "metadata": {},
   "source": [
    "<div><img style=\"float: right; width: 120px; vertical-align:middle\" src=\"https://www.upm.es/sfs/Rectorado/Gabinete%20del%20Rector/Logos/EU_Informatica/ETSI%20SIST_INFORM_COLOR.png\" alt=\"ETSISI logo\" />\n",
    "\n",
    "\n",
    "# Compressing Data with Vanilla Autoencoders<a id=\"top\"></a>\n",
    "\n",
    "<i><small>Authors: Alberto Díaz Álvarez<br>Last update: 2023-04-24</small></i></div>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2489222",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17030ba",
   "metadata": {},
   "source": [
    "An autoencoder is a type of neural network that consists of two parts: an encoder and a decoder. The encoder takes in the input data and compresses it into a lower-dimensional representation, while the decoder takes this representation and reconstructs the original input data.\n",
    "\n",
    "\n",
    "| <img src=\"https://upload.wikimedia.org/wikipedia/commons/3/37/Autoencoder_schema.png\" alt=\"Autoencoder Schema\" width=\"50%\"> | \n",
    "|:--:| \n",
    "| *Autoencoder schema. Source: Autoencoder_schema.png, <https://commons.wikimedia.org/wiki/File:Autoencoder_schema.png> (last visited April 24).* |\n",
    "\n",
    "The encoder and decoder are typically symmetric in structure, and the network is trained to minimize the reconstruction error between the original input and the output of the decoder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7d1e17",
   "metadata": {},
   "source": [
    "## Goals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b9e324",
   "metadata": {},
   "source": [
    "In this notebook, we will explore how to use a type of neural network called an autoencoder for compressing data. We will use the data provided in the `mnist` dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d401eac",
   "metadata": {},
   "source": [
    "## Libraries and configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa528aec",
   "metadata": {},
   "source": [
    "Next we will import the libraries that will be used throughout the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a8c29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174e97df",
   "metadata": {},
   "source": [
    "We will also configure some parameters to adapt the graphical presentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca72f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams[\"axes.grid\"] = False\n",
    "plt.rcParams.update({'figure.figsize': (20, 6),'figure.dpi': 64})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4fec89",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7223928",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d3a3bc",
   "metadata": {},
   "source": [
    "As stated before, we will use the `mnist` dataset as source to be compressed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07075092",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, _), (x_test, _) = tf.keras.datasets.mnist.load_data()\n",
    "x_train, x_test = x_train / 255, x_test / 255\n",
    "\n",
    "print(f'Training shape: {x_train.shape} input')\n",
    "print(f'Test shape:     {x_test.shape} input')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3048a8a2",
   "metadata": {},
   "source": [
    "Now we can start working with _autoencoders_ to learn how to use them as a compression tool for small grayscale images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f9cb29",
   "metadata": {},
   "source": [
    "## Vanilla autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbc803a",
   "metadata": {},
   "source": [
    "In this example, we are going to create a vanilla autoencoder. The encoder part will be the _input-to-latent-space_ component, whereas the decoder part will be just the opposite, the _latent-space-to-output_ component.\n",
    "\n",
    "Since we are working with $28 \\times 28$ images, we will have to play with flattening and reconstructing the input before going in and out to and from those layers, but there is no mystery to that.\n",
    "\n",
    "We will create the autoencoder as a `Model` subclass. So far we have created models indicating inputs and outputs defined outside their _scope_. This way we can have our models as classes that we can reuse more easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc7e4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(tf.keras.models.Model):\n",
    "    \"\"\"Represents a vanilla autoencoder.\"\"\"\n",
    "\n",
    "    def __init__(self, input_dim, latent_dim, name=None ,*args, **kwargs):\n",
    "        super().__init__(*args, name=name, **kwargs)\n",
    "\n",
    "        # We calculate sizes and shapes of inputs, outputs and latent spaces\n",
    "        flatten_dim = None\n",
    "        if isinstance(input_dim, (list, tuple)):\n",
    "            flatten_dim = math.prod(input_dim)\n",
    "        elif isinstance(input_dim, int):\n",
    "            flatten_dim = input_dim\n",
    "            input_dim = (input_dim,)\n",
    "        else:\n",
    "            raise ValueError('Argument input_dim must be a tuple or an int')\n",
    "        \n",
    "        # Encoder definition: Connection between input and latent space\n",
    "        self.encoder = tf.keras.Sequential([\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(latent_dim, activation=tf.keras.layers.LeakyReLU()),\n",
    "        ], name='Encoder')\n",
    "\n",
    "        # Decoder definition: Connection between latent space and output\n",
    "        self.decoder = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(flatten_dim, activation='sigmoid'),\n",
    "            tf.keras.layers.Reshape(input_dim)\n",
    "        ], name='Decoder')\n",
    "        \n",
    "        # Weights construction (just to have summary model's method working)\n",
    "        self.build((None, *input_dim))\n",
    "\n",
    "    def call(self, x):\n",
    "        return self.decoder(self.encoder(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7656c968",
   "metadata": {},
   "source": [
    "Now this model can be used for the creation of a vanilla autoencoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972a27bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = Autoencoder(input_dim=(28, 28), latent_dim=64, name='Vanilla')\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d0ab75",
   "metadata": {},
   "source": [
    "Let's train our autoencoder with the `mnist` training set. Since it is a model, we have to compile it beforehand by specifying which loss function and which opticizer we are going to use. We will also be able to invoke model methods on it, such as `fit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0daf891",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "history = autoencoder.fit(\n",
    "    x_train,\n",
    "    x_train,  # Watch out! we are using the inputs also as output\n",
    "    epochs=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176a8ffb",
   "metadata": {},
   "source": [
    "Let's see how training has evolved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5833d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history).plot()\n",
    "plt.xlabel('Epoch num.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb4f2b2",
   "metadata": {},
   "source": [
    "The training looks pretty good. Let's see how some examples of the training set are encoded and decoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d0a7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 4\n",
    "images = np.array(random.sample(list(x_train), n))\n",
    "\n",
    "encoded = autoencoder.encoder(images).numpy()\n",
    "decoded = autoencoder.decoder(encoded).numpy()\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(images[i])\n",
    "    plt.title('Original')\n",
    "\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded[i])\n",
    "    plt.title('Reconstructed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9944de34",
   "metadata": {},
   "source": [
    "And now, what will happen to data it has theoretically never seen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce93f965",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.array(random.sample(list(x_test), n))\n",
    "encoded = autoencoder.encoder(images).numpy()\n",
    "decoded = autoencoder.decoder(encoded).numpy()\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(images[i])\n",
    "    plt.title('Original')\n",
    "\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded[i])\n",
    "    plt.title('Reconstructed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925fbfcc",
   "metadata": {},
   "source": [
    "Almost perfect, so we were able to compress the images from 28x28=784 bytes (they are monochrome) to 100 bytes, which is just over 78% compression ratio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed780916",
   "metadata": {},
   "source": [
    "## Use case: Noise reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11437a5",
   "metadata": {},
   "source": [
    "Even though it is not a Denoising Autoencoder (we will see them later), one of the utilities of autoencoders in general is that of denoising. Once it has learned the fundamental features from which to reconstruct the images, it is able to overcome the noise by bypassing it in the encoding.\n",
    "\n",
    "Let's take again some images from the test set, because they are the ones it has never seen before, and let's add some noise to see how it is able to extract the original image with almost no noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9415c53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.array(random.sample(list(x_test), n))\n",
    "noise_factor = 0.3\n",
    "noisy_images = images + noise_factor * tf.random.normal(shape=images.shape)\n",
    "noisy_images = tf.clip_by_value(noisy_images, clip_value_min=0, clip_value_max=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d345c1c6",
   "metadata": {},
   "source": [
    "Now let's see how it regenerates images with noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49dfd37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "simple_decoded = autoencoder.decoder(autoencoder.encoder(noisy_images)).numpy()\n",
    "\n",
    "plt.figure(figsize=(9,9)) \n",
    "for i in range(n):\n",
    "    ax = plt.subplot(4, n, i + 1)\n",
    "    plt.imshow(images[i])\n",
    "    plt.title('Original')\n",
    "\n",
    "    ax = plt.subplot(4, n, i + 1 + n)\n",
    "    plt.imshow(noisy_images[i])\n",
    "    plt.title('Noisy')\n",
    "\n",
    "    ax = plt.subplot(4, n, i + 1 + 2 * n)\n",
    "    plt.imshow(simple_decoded[i])\n",
    "    plt.title('Simple AE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f745db4",
   "metadata": {},
   "source": [
    "Quite well, considering that what we are trying to compress are images in a rough way, without taking advantage of their two-dimensional structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43585490",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7defd88",
   "metadata": {},
   "source": [
    "Autoencoders are a very useful and versatile tool in the field of machine learning and artificial intelligence. They are capable of learning complex patterns in data, compressing them into a lower dimensional space and then reconstructing them with high accuracy. In addition, they are highly adaptable and can be tuned and trained for a wide variety of applications.\n",
    "\n",
    "However, it is important to note that autoencoders have some limitations. One of the main challenges is the selection of the right size of the encoding space, as too small a space can result in a loss of information, while too large a space can be inefficient. In addition, in some cases, autoencoders can be susceptible to overfitting and must be carefully adjusted.\n",
    "\n",
    "Overall, they are a valuable tool to store in our machine learning toolbox."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33005bde",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "<div><img style=\"float: right; width: 120px; vertical-align:top\" src=\"https://mirrors.creativecommons.org/presskit/buttons/88x31/png/by-nc-sa.png\" alt=\"Creative Commons by-nc-sa logo\" />\n",
    "\n",
    "[Volver al inicio](#top)\n",
    "\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
