{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "010176d1",
   "metadata": {},
   "source": [
    "<div><img style=\"float: right; width: 120px; vertical-align:middle\" src=\"https://www.upm.es/sfs/Rectorado/Gabinete%20del%20Rector/Logos/EU_Informatica/ETSI%20SIST_INFORM_COLOR.png\" alt=\"ETSISI logo\" />\n",
    "\n",
    "# Adaptive Learning Rate<a id=\"top\"></a>\n",
    "\n",
    "<i><small>Authors: Alberto Díaz Álvarez<br>Last update: 2023-04-09</small></i></div>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554fb61b",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ba017a",
   "metadata": {},
   "source": [
    "Although not directly related to gradient-related problems, the learning factor is a hyperparameter that greatly affects training behavior:\n",
    "\n",
    "- When it is high, it accelerates movements over the error space looking for promising regions, but makes convergence more difficult since large jumps make it difficult to stay in local minima\n",
    "- When it is low, the opposite happens; it allows the exploitation of the region in which we are, but makes it difficult (or impossible) to escape from these local minima in search of better solutions.\n",
    "\n",
    "This hyperparameter can be useful to explore regions that we suspect to be difficult (e.g. with many local minima). The idea is usually to start training with a high learning factor, and decrease it as we learn. In this way we try to favor a high exploitation at the beginning, when the algorithm is not yet converging towards a solution, and then continue towards a higher exploitation later on when the algorithm has (supposedly) found a sufficiently promising area."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f243ba3",
   "metadata": {},
   "source": [
    "## Goals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d6d24f",
   "metadata": {},
   "source": [
    "In Keras we have implementations of algorithms called \"learning rate schedulers\". These algorithms act as a learning factor, only that they vary according to the evolution of the training.\n",
    "\n",
    "For the rest of the section we will create a function to visualize the evolution of our learning factor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67582fcc",
   "metadata": {},
   "source": [
    "## Libraries and configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7611546",
   "metadata": {},
   "source": [
    "Next we will import the libraries that will be used throughout the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58374f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a34c1a8",
   "metadata": {},
   "source": [
    "Configuraremos también algunos parámetros para adecuar la presentación gráfica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861cbb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams.update({\"axes.grid\" : False})\n",
    "plt.rcParams.update({'figure.figsize': (20, 6),'figure.dpi': 64})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06541e93",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1198454a",
   "metadata": {},
   "source": [
    "## Sample model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8ab16e",
   "metadata": {},
   "source": [
    "Let's create a metric to tell us how much the learning factor is worth at each epoch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf912c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_spy(optimizer):\n",
    "    def lr(y_true, y_pred):\n",
    "        return optimizer.lr\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffd9fe8",
   "metadata": {},
   "source": [
    "We can use this metric in the same way as we use the precision, RMSE, etc.\n",
    "\n",
    "As a problem, we will use a small classification problem to make the training much faster, for example the three-input AND gate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd2d105",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[0, 0, 0], [0, 0, 1], [0, 1, 0], [0, 1, 1], [1, 0, 0], [1, 0, 1], [1, 1, 0], [1, 1, 1]])\n",
    "y = np.array([0, 1, 1, 1, 1, 1, 1, 1])\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(3,)),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid'),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2a2506",
   "metadata": {},
   "source": [
    "Let us now look at some implementation options."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a951579f",
   "metadata": {},
   "source": [
    "### `ExponentialDecay`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5d3c2a",
   "metadata": {},
   "source": [
    "This component performs an exponential learning factor decrease. It corresponds to the following formula:\n",
    "\n",
    "$$\n",
    "\\alpha_i = \\alpha_o \\cdot \\gamma^{\\frac{i}{s}}\n",
    "$$\n",
    "\n",
    "Being $i$ the current **batch** (not epoch), $alpha_i$ the learning factor in the current batch, $alpha_o$ the initial learning factor, $gamma$ the learning factor decrease rate, and $s$ the number of batches needed to decrease the learning factor.\n",
    "\n",
    "Actually the decrement is continuous as long as the division of the exponent of $\\gamma$ is an integer division, in which case the decrement will be stepwise. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ef07a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_exponential_decay = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=0.1,\n",
    "    decay_steps=5,\n",
    "    decay_rate=0.95,\n",
    "    staircase=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b452c29d",
   "metadata": {},
   "source": [
    "The learning factor starts at 0.1, and every 5 batches will be multiplied by 0.75; moreover, since `staircase` is `True`, the decrease will be stepwise instead of continuous.\n",
    "\n",
    "Let us see how the learning factor evolves during the training of a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813f570f",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(learning_rate=lr_exponential_decay)\n",
    "lr_metric = lr_spy(optimizer)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=[lr_metric])\n",
    "\n",
    "history = model.fit(X, y, batch_size=X.shape[0], epochs=500, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032ba6e6",
   "metadata": {},
   "source": [
    "We have specified the batch size equal to that of the epoch so that both match, but it must be remembered that **the iterations defined refer to _batches_ and not to _epochs_**.\n",
    "\n",
    "Graphically, the evolution of the learning factor is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5840ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history['lr']).plot()\n",
    "plt.xlabel('Epoch num.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354c3f73",
   "metadata": {},
   "source": [
    "### `PiecewiseConstantDecay`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c1a7ec",
   "metadata": {},
   "source": [
    "Here the decrease is by means of a step function in which we define exactly what learning factor we want in each range of training _batches_. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e307422",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_piecewise_constant_decay = tf.keras.optimizers.schedules.PiecewiseConstantDecay(\n",
    "    boundaries=[125, 250, 375],\n",
    "    values=[0.1, 0.075, 0.05, 0.025],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910af367",
   "metadata": {},
   "source": [
    "The learning factor remains at 0.1 for the first 126 _batches_ (from 0 to 125), at 0.075 for the next 125, at 0.05 for the next 125, and at 0.025 for the rest.\n",
    "\n",
    "Let us see how the learning factor evolves during the training of a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f237d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(learning_rate=lr_piecewise_constant_decay)\n",
    "lr_metric = lr_spy(optimizer)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=[lr_metric])\n",
    "\n",
    "history = model.fit(X, y, batch_size=X.shape[0], epochs=500, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c4bbea",
   "metadata": {},
   "source": [
    "Graphically, the evolution of the learning factor is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218c08d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history['lr']).plot()\n",
    "plt.xlabel('Epoch num.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7a2a2b",
   "metadata": {},
   "source": [
    "### `PolinomialDecay`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d981956",
   "metadata": {},
   "source": [
    "This component performs a monotonic decrease of the learning factor given an initial and final learning factor, as well as the number of iterations to reach the latter from the former.\n",
    "\n",
    "It follows the equation:\n",
    "\n",
    "$$\n",
    "\\alpha_i = (\\alpha_o - \\alpha_n) \\cdot \\frac{1 - \\min(i, S_\\alpha)}{\\delta\\alpha}^p + \\alpha_n\n",
    "$$\n",
    "\n",
    "Where $i$ is the current batch, $alpha_i$ the learning factor in the current batch, $alpha_o$ and $alpha_n$ the initial and final learning factors, $S_alpha$ the number of _batches_ to reach $alpha_n$ and $p$ an exponent that determines the degree of the polynomial.\n",
    "\n",
    "Since it is possible to reach the value $\\alpha_n$ without having completed the training, and therefore with many iterations ahead, there is the option of converting this descent into a descent that occurs again, each time from a value slightly less than the previous $\\alpha_o$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab33e1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_polynomial_decay = tf.keras.optimizers.schedules.PolynomialDecay(\n",
    "    initial_learning_rate=0.1,\n",
    "    end_learning_rate=0.001,\n",
    "    decay_steps=100,\n",
    "    power=1,\n",
    "    cycle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa154043",
   "metadata": {},
   "source": [
    "The learning factor starts at 0.1 and ends at 0.001 after 100 _batches_. The degree of the polynomial is 1, so the decrease will be in a straight line. Moreover, since we have set the `cycle` argument to `true`, the decrease will be repeated, each time from a smaller initial learning factor.\n",
    "\n",
    "Let us see how the learning factor evolves during the training of a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0066804",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(learning_rate=lr_polynomial_decay)\n",
    "lr_metric = lr_spy(optimizer)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=[lr_metric])\n",
    "\n",
    "history = model.fit(X, y, batch_size=X.shape[0], epochs=500, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c593ccd6",
   "metadata": {},
   "source": [
    "Gráficamente, la evolución del factor de aprendizaje queda como sigue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2cca5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history['lr']).plot()\n",
    "plt.xlabel('Epoch num.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd46e79",
   "metadata": {},
   "source": [
    "### `InverseTimeDecay`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b29811",
   "metadata": {},
   "source": [
    "Decay in this strategy applies an inverse decay function at each iteration of the optimizer, given an initial learning rate. It responds to the equation:\n",
    "\n",
    "\n",
    "$$\n",
    "\\alpha_i = \\frac{\\alpha_o}{1 + \\alpha_r \\cdot \\frac{i}{\\delta i}}\n",
    "$$\n",
    "\n",
    "With $alpha_i$ being the learning factor in the $i$-th batch, $alpha_o$ and $alpha_r$ being its initial value and descent ratio, respectively, and $delta i$ being the number of batches to descend.\n",
    "\n",
    "As in other cases, the descent can be specified to be staggered rather than continuous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0508cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_inverse_time_decay = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
    "    initial_learning_rate=0.1,\n",
    "    decay_steps=50,\n",
    "    decay_rate=0.1,\n",
    "    staircase=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a493e5b3",
   "metadata": {},
   "source": [
    "The learning factor starts at 0.1, and every 50 _batches_ decreases by 0.1 (10%) from the previous value. Also, since `staircase` is `True`, the decrease will be stepwise instead of continuous.\n",
    "\n",
    "Let us see how the learning factor evolves during the training of a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd61ee66",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(learning_rate=lr_inverse_time_decay)\n",
    "lr_metric = lr_spy(optimizer)\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[lr_metric])\n",
    "\n",
    "history = model.fit(X, y, batch_size=X.shape[0], epochs=500, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a790fc",
   "metadata": {},
   "source": [
    "Graphically, the evolution of the learning factor is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23c201c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history['lr']).plot()\n",
    "plt.xlabel('Epoch num.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e972718d",
   "metadata": {},
   "source": [
    "Es similar, aunque no tan pronunciado, al descenso del factor de aprendizaje exponencial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a8cd5d",
   "metadata": {},
   "source": [
    "### `CosineDecay`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd84a244",
   "metadata": {},
   "source": [
    "The decrease in this case is achieved by applying a cosine-based function ([SGDR: Stochastic Gradient Descent with Warm Restarts](https://arxiv.org/abs/1608.03983) by Ilya Loshchilov, Frank Hutter). Specifically, the equation of the function is as follows:\n",
    "\n",
    "$$\n",
    "\\alpha_i = \\alpha_o \\frac{1 + \\cos(\\pi \\min(i, S_\\alpha))}{2 S_\\alpha}\n",
    "$$\n",
    "\n",
    "With $alpha_i$ being the learning factor in the $i$-th _batch_, $alpha_o$ being its initial value and $S_alpha$ being the number of _batches_ to reach 0. It is logical that the parameter $S_alpha$ should be equal to the number of _batches_ our training will perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299351dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_cosine_decay = tf.keras.optimizers.schedules.CosineDecay(\n",
    "    initial_learning_rate=0.1,\n",
    "    decay_steps=500,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55dc4248",
   "metadata": {},
   "source": [
    "The learning factor starts at 0.1, and in 500 batches it reaches the minimum, i.e. 0.\n",
    "\n",
    "Let us see how the learning factor evolves during the training of a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a236609",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(learning_rate=lr_cosine_decay)\n",
    "lr_metric = lr_spy(optimizer)\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[lr_metric])\n",
    "\n",
    "history = model.fit(X, y, batch_size=X.shape[0], epochs=500, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6bb6173",
   "metadata": {},
   "source": [
    "Graphically, the evolution of the learning factor is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bba42c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history['lr']).plot()\n",
    "plt.xlabel('Epoch num.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebc58f6",
   "metadata": {},
   "source": [
    "### `CosineDecayRestarts`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b9837e",
   "metadata": {},
   "source": [
    "This scheme is very similar to the previous one, but in this case the evolution is repeated by varying the frequency of descent. Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5af470",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_exponential_decay = tf.keras.optimizers.schedules.CosineDecayRestarts(\n",
    "    initial_learning_rate=0.1,\n",
    "    first_decay_steps=10,\n",
    "    t_mul=2.0,\n",
    "    m_mul=0.9,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f1a4e6",
   "metadata": {},
   "source": [
    "The learning factor starts at 0.1 and decays to 0 for the first 10 _batches_. At the $i+1$-th iteration, the descent rate and the learning factor will be those they had at the $i$-th iteration, but multiplied by 2 (`t_mul`) and by 0.9 (`m_mul`) respectively.\n",
    "\n",
    "Let us see how the learning factor evolves during the training of a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8832be82",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(learning_rate=lr_exponential_decay)\n",
    "lr_metric = lr_spy(optimizer)\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[lr_metric])\n",
    "\n",
    "history = model.fit(X, y, batch_size=X.shape[0], epochs=500, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc78736f",
   "metadata": {},
   "source": [
    "Graphically, the evolution of the learning factor is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4582c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history['lr']).plot()\n",
    "plt.xlabel('Epoch num.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28719b2",
   "metadata": {},
   "source": [
    "### Custom learning factor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fcb6a6",
   "metadata": {},
   "source": [
    "All the classes we have seen before inherit from the `LearningRateSchedule` class. To create our own adaptive learning factor it would be enough to inherit from this class and implement the `__call__(self, step)` method (well, and the `get_config` and `from_config` methods if we wanted to make it serializable).\n",
    "\n",
    "However, invoking the power of _duck typing_, it would be enough to provide a class with a `__call__` method (a _functor_) that accepts an `int` (the current iteration) and returns a `float` (the value of the learning factor). Note that the operations we are going to work with are tensor operations.\n",
    "\n",
    "We are going to create a strategy that generates random values between two configurable limits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09816245",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomScheduler(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, lower_bound, upper_bound, name=None):\n",
    "        self.lower_bound = lower_bound\n",
    "        self.upper_bound = upper_bound\n",
    "        self.name = name or 'RandomScheduler'\n",
    "\n",
    "    def __call__(self, step):\n",
    "        with tf.name_scope(self.name) as name:\n",
    "            return tf.random.uniform(\n",
    "                shape=[],\n",
    "                minval=self.lower_bound,\n",
    "                maxval=self.upper_bound,\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f611f98f",
   "metadata": {},
   "source": [
    "Yes, it is somewhat absurd and does not take into account the iteration we are in, but it is useful to illustrate how it works. Let's see how it would evolve during the training of a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10eadd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(learning_rate=RandomScheduler(lower_bound=0.001, upper_bound=0.1))\n",
    "lr_metric = lr_spy(optimizer)\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[lr_metric])\n",
    "\n",
    "history = model.fit(X, y, batch_size=X.shape[0], epochs=500, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9295a205",
   "metadata": {},
   "source": [
    "Graphically, the evolution of the learning factor is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc90caf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history['lr']).plot()\n",
    "plt.xlabel('Epoch num.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05096b5",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd65fcd4",
   "metadata": {},
   "source": [
    "El factor de aprendizaje adaptativo en redes neuronales es un mecanismo útil el rendimiento del entrenamiento de un modelo basado en redes neuronales. Existen varias implementaciones que permiten ajustar el factor de aprendizaje en función de varios parámetros ya implementadas en Keras, pero además es posible desarrollar una implementación propia, adaptada a las necesidades específicas del problema a resolver.\n",
    "\n",
    "En general, el factor de aprendizaje adaptativo es una técnica esencial para la construcción de redes neuronales que pueden ser entrenadas de manera efectiva en una amplia variedad de problemas de aprendizaje automático."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582efec2",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "<div><img style=\"float: right; width: 120px; vertical-align:top\" src=\"https://mirrors.creativecommons.org/presskit/buttons/88x31/png/by-nc-sa.png\" alt=\"Creative Commons by-nc-sa logo\" />\n",
    "\n",
    "[Back to top](#top)\n",
    "\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
