{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4480ff39",
   "metadata": {},
   "source": [
    "<div><img style=\"float: right; width: 120px; vertical-align:middle\" src=\"https://www.upm.es/sfs/Rectorado/Gabinete%20del%20Rector/Logos/EU_Informatica/ETSI%20SIST_INFORM_COLOR.png\" alt=\"ETSISI logo\" />\n",
    "\n",
    "\n",
    "# Text classification with CNNs<a id=\"top\"></a>\n",
    "\n",
    "<i><small>Author: Alberto Díaz Álvarez<br>Last update: 2023-05-25</small></i></div>\n",
    "\n",
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d2489222",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e17030ba",
   "metadata": {},
   "source": [
    "In natural language processing (NLP), a very typical task is text classification. In this task, a given text is classified according to its meaning. It is often used, for example, for the problem of sentiment analysis.\n",
    "\n",
    "This is a so-called _many-to-one_ problem, i.e., one where the input sequence size is $T_X = 1$, but the output sequence size is $T_Y = 1$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fc7d1e17",
   "metadata": {},
   "source": [
    "## Goals"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d0b9e324",
   "metadata": {},
   "source": [
    "Let's do an exercise in which we will use the amazon reviews dataset for sentiment analysis. From the reviews and ratings data, we will identify whether a review is positive, neutral or negative. For this we will use a first approach using a Convolutional Neural Network (CNN) model network model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5d401eac",
   "metadata": {},
   "source": [
    "## Libraries and configuration"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fa528aec",
   "metadata": {},
   "source": [
    "Next we will import the libraries that will be used throughout the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00a8c29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-25 18:25:27.677882: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "import requests\n",
    "from shutil import unpack_archive\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ff3a5f84",
   "metadata": {},
   "source": [
    "We will also configure some parameters to adapt the graphic presentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d522d503",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "plt.rcParams.update({'figure.figsize': (20, 6),'figure.dpi': 64})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8ea7481e",
   "metadata": {},
   "source": [
    "And create the necessary directories in case they have not been created previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64979a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('tmp', exist_ok=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ee4fec89",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b6d22a2c",
   "metadata": {},
   "source": [
    "## Common parameters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "231d1a4e",
   "metadata": {},
   "source": [
    "We will start by defining the parameters that we will use throughout the notebook, which will consist of the maximum length of the sequences (remember that they must have a fixed length) and the dimension of the vector of each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51a1ad15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many dimensions our word vectors have (50, 100, 200 or 300)\n",
    "EMBEDDING_DIM = 300\n",
    "# Our vocabulary max. size (the most frequent ones will be chosen)\n",
    "MAX_VOCAB_SIZE = 16384\n",
    "# Maximum sentence length\n",
    "MAX_SEQUENCE_LEN = 32"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e86b03b1",
   "metadata": {},
   "source": [
    "## Dataset processing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9b1ff85c",
   "metadata": {},
   "source": [
    "We are going to load the training data, which will consist of the Amazon review data from the \"Digital Music\" category (https://nijianmo.github.io/amazon/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "564710a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>vote</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>style</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>True</td>\n",
       "      <td>06 3, 2013</td>\n",
       "      <td>A2TYZ821XXK2YZ</td>\n",
       "      <td>3426958910</td>\n",
       "      <td>{'Format:': ' Audio CD'}</td>\n",
       "      <td>Garrett</td>\n",
       "      <td>This is awesome to listen to, A must-have for ...</td>\n",
       "      <td>Slayer Rules!</td>\n",
       "      <td>1370217600</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>10 11, 2014</td>\n",
       "      <td>A3OFSREZADFUDY</td>\n",
       "      <td>3426958910</td>\n",
       "      <td>{'Format:': ' Audio CD'}</td>\n",
       "      <td>Ad</td>\n",
       "      <td>bien</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1412985600</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>02 11, 2014</td>\n",
       "      <td>A2VAMODP8M77NG</td>\n",
       "      <td>3426958910</td>\n",
       "      <td>{'Format:': ' Audio CD'}</td>\n",
       "      <td>JTGabq</td>\n",
       "      <td>It was great to hear the old stuff again and I...</td>\n",
       "      <td>SLAYER!!!!!!!!!!!!!!!!!!!!!</td>\n",
       "      <td>1392076800</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>False</td>\n",
       "      <td>12 7, 2013</td>\n",
       "      <td>AAKSLZ9IDTEH0</td>\n",
       "      <td>3426958910</td>\n",
       "      <td>{'Format:': ' Audio CD'}</td>\n",
       "      <td>john F&amp;#039;n doe</td>\n",
       "      <td>well best of's are a bit poison normally but t...</td>\n",
       "      <td>slayer greatest hits! you mean everything righ...</td>\n",
       "      <td>1386374400</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>06 12, 2016</td>\n",
       "      <td>A3OH43OZJLKI09</td>\n",
       "      <td>5557706259</td>\n",
       "      <td>{'Format:': ' Audio CD'}</td>\n",
       "      <td>melinda a goodman</td>\n",
       "      <td>What can I say? This is Casting Crowns!!!This ...</td>\n",
       "      <td>This is a good, blessing filled</td>\n",
       "      <td>1465689600</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall  vote  verified   reviewTime      reviewerID        asin  \\\n",
       "0        5   3.0      True   06 3, 2013  A2TYZ821XXK2YZ  3426958910   \n",
       "1        5   NaN      True  10 11, 2014  A3OFSREZADFUDY  3426958910   \n",
       "2        5   NaN      True  02 11, 2014  A2VAMODP8M77NG  3426958910   \n",
       "3        4   3.0     False   12 7, 2013   AAKSLZ9IDTEH0  3426958910   \n",
       "4        5   NaN      True  06 12, 2016  A3OH43OZJLKI09  5557706259   \n",
       "\n",
       "                      style       reviewerName  \\\n",
       "0  {'Format:': ' Audio CD'}            Garrett   \n",
       "1  {'Format:': ' Audio CD'}                 Ad   \n",
       "2  {'Format:': ' Audio CD'}             JTGabq   \n",
       "3  {'Format:': ' Audio CD'}  john F&#039;n doe   \n",
       "4  {'Format:': ' Audio CD'}  melinda a goodman   \n",
       "\n",
       "                                          reviewText  \\\n",
       "0  This is awesome to listen to, A must-have for ...   \n",
       "1                                               bien   \n",
       "2  It was great to hear the old stuff again and I...   \n",
       "3  well best of's are a bit poison normally but t...   \n",
       "4  What can I say? This is Casting Crowns!!!This ...   \n",
       "\n",
       "                                             summary  unixReviewTime image  \n",
       "0                                      Slayer Rules!      1370217600   NaN  \n",
       "1                                         Five Stars      1412985600   NaN  \n",
       "2                        SLAYER!!!!!!!!!!!!!!!!!!!!!      1392076800   NaN  \n",
       "3  slayer greatest hits! you mean everything righ...      1386374400   NaN  \n",
       "4                    This is a good, blessing filled      1465689600   NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATASET_URL = 'https://jmcauley.ucsd.edu/data/amazon_v2/categoryFilesSmall/Digital_Music_5.json.gz'\n",
    "DATASET_ZIP = 'tmp/Digital_Music_5.json.gz'\n",
    "\n",
    "# Download the remote file if it does not exist\n",
    "if not os.path.exists(DATASET_ZIP):\n",
    "    with open(DATASET_ZIP, 'wb') as f:\n",
    "        print(f'Downloading {DATASET_ZIP}...')\n",
    "        r = requests.get(DATASET_URL, verify=False)\n",
    "        f.write(r.content)\n",
    "        print('OK')\n",
    "\n",
    "corpus = pd.read_json(DATASET_ZIP, lines=True)\n",
    "corpus.dropna(subset=['overall', 'reviewText'], inplace=True)\n",
    "corpus.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bace8799",
   "metadata": {},
   "source": [
    "The process we will perform in this notebook will be to see how to build a convolutional model to work with this type of data sets. Therefore we will not go into the detail of obtaining a test data set.\n",
    "\n",
    "However, it should be noted that in a real problem it would be necessary to train with validation and contrast with a test set before putting our model into production."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5719ffd0",
   "metadata": {},
   "source": [
    "### Preparing the dataset input"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "074e95f9",
   "metadata": {},
   "source": [
    "The input to our model will be the reviews as such. Therefore, we will take the `reviewText` column as our training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32f62d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training input shape: (169623,)\n"
     ]
    }
   ],
   "source": [
    "x_train = corpus['reviewText'].astype(str).str.strip()\n",
    "print(f'Training input shape: {x_train.shape}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6464895c",
   "metadata": {},
   "source": [
    "We will now create a [`TextVectorization`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/TextVectorization) layer, which will be responsible for:\n",
    "\n",
    "1. will convert a complete review into a sequence of integers (words), assigning each word a unique value.\n",
    "2. Truncate or padding so that the sequences maintain a fixed length previously established (in our case `MAX_SEQUENCE_LEN`).\n",
    "\n",
    "The vocabulary will be extracted from our input, taking the `MAX_VOCAB_SIZE` most common words. We have added `+ 2` to the length since there are two tokens preassigned: Padding (`''`) and words outside the vocabulary (`'[UNK]'`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c3221f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-25 18:25:33.556974: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2023-05-25 18:25:33.589490: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:37:00.0 name: Quadro RTX 8000 computeCapability: 7.5\n",
      "coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 47.46GiB deviceMemoryBandwidth: 625.94GiB/s\n",
      "2023-05-25 18:25:33.591575: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 1 with properties: \n",
      "pciBusID: 0000:86:00.0 name: Quadro RTX 8000 computeCapability: 7.5\n",
      "coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 47.46GiB deviceMemoryBandwidth: 625.94GiB/s\n",
      "2023-05-25 18:25:33.591614: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2023-05-25 18:25:33.595726: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2023-05-25 18:25:33.595806: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2023-05-25 18:25:33.597465: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2023-05-25 18:25:33.597807: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2023-05-25 18:25:33.598044: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.0/lib:/usr/local/cuda-11.0/lib\n",
      "2023-05-25 18:25:33.598961: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2023-05-25 18:25:33.599162: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2023-05-25 18:25:33.599176: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1766] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-05-25 18:25:33.599720: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-25 18:25:33.600482: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-05-25 18:25:33.600496: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary length: 16386\n"
     ]
    }
   ],
   "source": [
    "vectorize_layer = tf.keras.layers.experimental.preprocessing.TextVectorization(\n",
    "    max_tokens=MAX_VOCAB_SIZE + 2,\n",
    "    output_sequence_length=MAX_SEQUENCE_LEN,\n",
    ")\n",
    "vectorize_layer.adapt(x_train.to_numpy())\n",
    "\n",
    "print(f'Vocabulary length: {len(vectorize_layer.get_vocabulary())}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "88b782d0",
   "metadata": {},
   "source": [
    "### Preparing the dataset output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b394b67f",
   "metadata": {},
   "source": [
    "Based on the assumption that those reviews with high ratings will be positive and those with low ratings will be negative, we will keep only the review and the product rating from the dataset.\n",
    "\n",
    "In particular, we will convert review ratings to 0 if they are bad (1 or 2 stars), 1 if they are mediocre (3 stars) and 2 if they are good (4 or more stars)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d03f799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training output shape: (169623,)\n"
     ]
    }
   ],
   "source": [
    "y_train = corpus['overall'].astype(int).replace({\n",
    "    1: 0,\n",
    "    2: 0,\n",
    "    3: 1,\n",
    "    4: 2,\n",
    "    5: 2,\n",
    "})\n",
    "print(f'Training output shape: {y_train.shape}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d7223928",
   "metadata": {},
   "source": [
    "## Using pre-trained embeddings in our language model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d9977840",
   "metadata": {},
   "source": [
    "We have already seen that when building a language model, one important aspect is the representation of words. In order to capture the semantic meaning of words, we use word embeddings, which are dense vector representations of words in a high-dimensional space.\n",
    "\n",
    "This time, rather than training our own word embeddings from scratch, we can take advantage of pre-trained embeddings, which have been trained on large corpora of text data. One popular pre-trained embedding is the Global Vectors for Word Representation (GLoVe), which was trained on a dataset of over 6 billion tokens. It has several pre-trained word vectors, so we will make use of those provided at http://nlp.stanford.edu/data/glove.6B.zip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67b5594b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unpacking ...OK\n"
     ]
    }
   ],
   "source": [
    "GLOVE_URL = 'http://nlp.stanford.edu/data/glove.6B.zip'\n",
    "GLOVE_FILE = 'tmp/glove.6B.zip'\n",
    "\n",
    "# Download the compressed GloVe dataset (if you don't already have it)\n",
    "if not os.path.exists(GLOVE_FILE):\n",
    "    print('Downloading ...', end='')\n",
    "    with open(GLOVE_FILE, 'wb') as f:\n",
    "        r = requests.get(GLOVE_URL, allow_redirects=True)\n",
    "        f.write(r.content)\n",
    "    print('OK')\n",
    "\n",
    "# Unzip it in the directory 'glove'.\n",
    "print('Unpacking ...', end='')\n",
    "unpack_archive(GLOVE_FILE, 'tmp')\n",
    "print('OK')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "39fc8ea3",
   "metadata": {},
   "source": [
    "By using pre-trained embeddings like GLoVe, we can take advantage of the vast amount of knowledge encoded in these embeddings, which can improve the performance of our language model.\n",
    "\n",
    "Now let's load the embedding of the dimension specified in the configuration. The file is composed of lines of tuples, where the first element is the word (in text) and the second is that word vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98b853ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading GloVe 300-d embedding... "
     ]
    }
   ],
   "source": [
    "print(f'Loading GloVe {EMBEDDING_DIM}-d embedding... ', end='')\n",
    "word2vec = {}\n",
    "with open(f'tmp/glove.6B.{EMBEDDING_DIM}d.txt') as f:\n",
    "    for line in f:\n",
    "        word, vector = line.split(maxsplit=1)\n",
    "        word2vec[word] = np.fromstring(vector,'f', sep=' ')\n",
    "print(f'done ({len(word2vec)} word vectors loaded)')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5c6ece6e",
   "metadata": {},
   "source": [
    "400000 words are a lot of words. Since our vocabulary is smaller, we are going to create a smaller embedding layer, the size of our vocabulary. For it, we will include in this one only the vectors of the words that the `TextVectorization` layer will return us.\n",
    "\n",
    "We will begin by creating the embedding matrix with the glove vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3344464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating embedding matrix with GloVe vectors... done (3425 words unassigned)\n"
     ]
    }
   ],
   "source": [
    "print('Creating embedding matrix with GloVe vectors... ', end='')\n",
    "\n",
    "# Our newly created embedding: a matrix of zeros\n",
    "embedding_matrix = np.zeros((MAX_VOCAB_SIZE + 2, EMBEDDING_DIM))\n",
    "\n",
    "ko_words = 0\n",
    "for i, word in enumerate(vectorize_layer.get_vocabulary()):\n",
    "    if word == '[UNK]':\n",
    "        # The second word is for an unknown token, in glove is 'unk'\n",
    "        word = 'unk'\n",
    "\n",
    "    # Get the word vector and overwrite the row in its corresponding position\n",
    "    word_vector = word2vec.get(word)\n",
    "    if word_vector is not None:\n",
    "        embedding_matrix[i] = word_vector\n",
    "    else:\n",
    "        ko_words += 1\n",
    "\n",
    "print(f'done ({ko_words} words unassigned)')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f9f9bae0",
   "metadata": {},
   "source": [
    "Well, apparently there are a lot of words that have no correspondence in the downloaded embedding. It seems that 400000 tokens are not so many tokens.\n",
    "\n",
    "Once this is done, we can create an embedding layer with the preloaded weight matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b548d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = tf.keras.layers.Embedding(\n",
    "    input_dim=embedding_matrix.shape[0],\n",
    "    output_dim=embedding_matrix.shape[1],\n",
    "    weights=[embedding_matrix],\n",
    "    input_length=MAX_SEQUENCE_LEN,\n",
    "    trainable=False,\n",
    "    name='Embedding',\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9b6eedd5",
   "metadata": {},
   "source": [
    "## Classification model based on convolutional neural networks (CNNs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8ee0758b",
   "metadata": {},
   "source": [
    "We will make a first approximation to the problem using convolutional networks. In this case, our sentences will be represented by single-row \"images\", with as many columns as the length of the specified sequence and as many channels as the dimension of each valabra of the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50554551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "text_vectorization_2 (TextVe (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "Embedding (Embedding)        (None, 32, 300)           4915800   \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 30, 32)            28832     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 30, 32)            128       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 960)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 3)                 2883      \n",
      "=================================================================\n",
      "Total params: 4,947,643\n",
      "Trainable params: 31,779\n",
      "Non-trainable params: 4,915,864\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.Input(shape=(1,), dtype=tf.string),\n",
    "    vectorize_layer,  # [[1, 2, 3, 4, 5], [6, 7, 8, 9, 0]]\n",
    "    embedding_layer,\n",
    "    tf.keras.layers.Conv1D(32, kernel_size=3, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(3, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['sparse_categorical_accuracy'],\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f4550806",
   "metadata": {},
   "source": [
    "Let's train the model and hope for the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccda9aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-25 17:54:49.495306: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2023-05-25 17:54:49.514546: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 1900000000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "5305/5305 [==============================] - 24s 4ms/step - loss: 0.1713 - sparse_categorical_accuracy: 0.9539\n",
      "Epoch 2/5\n",
      "5305/5305 [==============================] - 22s 4ms/step - loss: 0.1424 - sparse_categorical_accuracy: 0.9593\n",
      "Epoch 3/5\n",
      "5305/5305 [==============================] - 22s 4ms/step - loss: 0.1304 - sparse_categorical_accuracy: 0.9616\n",
      "Epoch 4/5\n",
      "5305/5305 [==============================] - 22s 4ms/step - loss: 0.1210 - sparse_categorical_accuracy: 0.9638\n",
      "Epoch 5/5\n",
      "5305/5305 [==============================] - 22s 4ms/step - loss: 0.1137 - sparse_categorical_accuracy: 0.9653\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=50)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b2d17311",
   "metadata": {},
   "source": [
    "Let's take a look at the training progress:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddec59a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABAMAAAFRCAYAAAABwGR1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAnYAAAJ2AHHoLmtAAAwOklEQVR4nO3de5Rkd0En8G9V9Xue6SRDMsRJQpIxJDhBDa6AKItwUIFwIlFEF5YlZFdMiEgSgqzykmzIyQtDEIhAVByPCQgR9Q9RDjluVlwFgYEAYyA7eZJJMu9Xv6rv/lH9qu7q7nl2d839fM7pM3Xr3vu7v1u/uj1d3/r9frdSFEURAAAAoDSqi10BAAAAYGEJAwAAAKBkhAEAAABQMsIAAAAAKBlhAAAAAJRMx2IduCiKjI6OLtbhD0ulUombL7Qv7df+tGH704btTxu2N+3X/rRh+9OG7a1d269Wq814btHCgNHR0WzdunWxDn9Y+vv7s3379sWuBodJ+7U/bdj+tGH704btTfu1P23Y/rRhe2vX9lu7du2M5wwTAAAAgJIRBgAAAEDJCAMAAACgZIQBAAAAUDJHbQLBLVu25J//+Z8zPDycV73qVenv7z9aRQMAAABH0ZxhwODgYN7//vfnsccey2WXXZYXvvCFSZIvfelL+fKXv5xKpZLLLrss69aty7333pvf+I3fyFNPPZV/+Zd/yS/90i8tyAkAAAAAh2bOYQKdnZ255pprmj7Y7927N1/84hfz3ve+N295y1ty5513JmncbxEAAABY+ubsGVCtVrN69eqm577//e/n/PPPT0dHR9auXZs9e/ZkdHQ0P/dzP5fPfOYzGRkZyStf+cqW5f3v//2/c9999yVJfud3fqfthhJ0dna2XZ2ZpP3anzZsf9qw/WnD9qb92p82bH/asL0dT+13yHMG7N27N8uWLZtY7u3tzf79+3PGGWfkjDPOmHPfF73oRXnRi16UJKnX69m6deuhHn5R9ff3Z/v27YtdDQ6T9mt/2rD9acP2pw3bm/Zrf9qw/WnD9tau7bd27doZzx3y3QSWLVuWffv2TSwfOHAgfX19R1YzAAAAYMEccs+Ac845J3fffXfq9XqeeuqprFixItWqOxQCAAAcS0VRNC+33OYgyjmofY78WAezT9Fyq/mPM+OpGeUezD4zt5rx2kxbruwfymhRpHoczJk3bxhw0003ZcuWLenu7s4DDzyQN77xjfn5n//5vOc970mlUsmll166EPWEJaMoJn9ljf/+KDL1d0kxbXly/dRfdo3lxsoiU37RjJU/vm5i/zT/BzD1GJP1KJrLnnasYkqBLY8xVtBs59ey/k3LxUTZE+VMO3br16zF+RUz67F8V7Jnz56mOmZaGa0eN29THMQ2zefVcvumbWYpc9HKmbpN0fL5pu1n2fdoljFeTl/vgew/sH/28zjW7XmI5cx6Lke5PQ+1jEM/10M8vzm26e7ekcHBwVnfF4f+3j2Ico51e866zTEo5wheq4Nq01kqNP6ws/PxDA2PzF/OIZ7jIbfpQpbT5u+N6ZtXq9WMjo62Xt9iuVXFWm0z47linvUt95m51cHV7yCONe82LZ45iHLn2+dgjnVw+8x/rIPZh6Xh0685Oyt7Dvl79SWnUkyPlxZIO80ZcGB4NH/y9SfT3d2dgYHGH0DT/4Br/mBUNH3QG/9nfHniQ1Fm/iFYjG00dV3ztnMfuxh7opiyPsXU48997PG1B31+08sZO79W6w7mw/L0Y0+WeRjnN3Vd0bjjxWhRzKj/9HOffr7z/bFOuUzNgGcLhCst11daPJq/jMMpZ5bNm7dvsWPL9QdTxiGUU6tWUx8dnXWbVuc667nNsl/zNpWD2Gb+ciqzvAit23qWMpbC+2G+9QfRjp2dnRkeGZ5zm4Mp50jOdfq6pfq+mFHmbNscwXtjru0qLc6op6c7g4ODres3azmtVxzJ74zZ7kJ1qO+RIy7rWLftMXiP9PUty4H9+zOXVud7MN9hTt+v1Xto/n0O/TitjnUwX7rOfC8c+j6N/Q7iPI/CscaPs3z5suzdu2/mDrPWb55tDqK9W7blQbTd0TjW4bfLQew3baPDe58f2j4rV6zMM3tG0lE9mD2XjlZzBrR/nLEAihR5bPdQOjtHMzI8klQab5qJ5q9UJpan/6fSWK6MbzbjD8exNRPrxrefWM7khhPHnLLvxPYtyp18PPP4TcuVyuQ+U441Wc7k+pnHaP6joOn8p57D1H1mHKPS4jWdLG/qL5TW5zB5ftPrOXXdsmXLsn/fvhZt1PocJsuptF53sG001p4tj9HitW11fjNel6ZjVFqe+1zrmo9RaVHn8WPNcu6zHGOu8lsfY8p7d+r5Nb1ek9fDCSeckB07djQdf2qdpi8d0R/5x0HXr6WoXSfdYZI2bG/ar/1pw/bXaMPaYleDw9Tfv+q4uQaFAQehr7OWD7x0nV++bU77tb+ezlq6O8xRAgAAR8pf1QAAAFAywgAAAAAoGWEAAAAAlIwwAAAAAEpGGAAAAAAls+BhwKZNm7Jx48YMDw8v9KEBAACALMKtBTds2JANGzakXq8v9KEBAACAGCYAAAAApSMMAAAAgJIRBgAAAEDJCAMAAACgZIQBAAAAUDLCAAAAACgZYQAAAACUjDAAAAAASkYYAAAAACUjDAAAAICSEQYAAABAyQgDAAAAoGSEAQAAAFAyCx4GbNq0KRs3bszw8PBCHxoAAABI0rHQB9ywYUM2bNiQer2+0IcGAAAAYpgAAAAAlI4wAAAAAEpGGAAAAAAlIwwAAACAkhEGAAAAQMkIAwAAAKBkhAEAAABQMsIAAAAAKBlhAAAAAJSMMAAAAABKRhgAAAAAJSMMAAAAgJIRBgAAAEDJCAMAAACgZIQBAAAAUDILHgZs2rQpGzduzPDw8EIfGgAAAEjSsdAH3LBhQzZs2JB6vb7QhwYAAABimAAAAACUjjAAAAAASkYYAAAAACUjDAAAAICSEQYAAABAyQgDAAAAoGSEAQAAAFAywgAAAAAoGWEAAAAAlIwwAAAAAEpGGAAAAAAlIwwAAACAkhEGAAAAQMkIAwAAAKBkhAEAAABQMsIAAAAAKBlhAAAAAJTMgocBmzZtysaNGzM8PLzQhwYAAACSdCz0ATds2JANGzakXq8v9KEBAACAGCYAAAAApSMMAAAAgJIRBgAAAEDJCAMAAACgZIQBAAAAUDLCAAAAACgZYQAAAACUjDAAAAAASkYYAAAAACUjDAAAAICSEQYAAABAyQgDAAAAoGSEAQAAAFAywgAAAAAoGWEAAAAAlIwwAAAAAEpGGAAAAAAlIwwAAACAkhEGAAAAQMkIAwAAAKBkhAEAAABQMgseBmzatCkbN27M8PDwQh8aAAAASNKx0AfcsGFDNmzYkHq9vtCHBgAAAGKYAAAAAJSOMAAAAABKRhgAAAAAJSMMAAAAgJIRBgAAAEDJCAMAAACgZIQBAAAAUDLCAAAAACgZYQAAAACUjDAAAAAASkYYAAAAACUjDAAAAICSEQYAAABAyQgDAAAAoGSEAQAAAFAywgAAAAAoGWEAAAAAlIwwAAAAAEpGGAAAAAAlIwwAAACAkhEGAAAAQMkIAwAAAKBkhAEAAABQMsIAAAAAKBlhAAAAAJSMMAAAAABKZsHDgE2bNmXjxo0ZHh5e6EMDAAAASToW+oAbNmzIhg0bUq/XF/rQAAAAQAwTAAAAgNIRBgAAAEDJCAMAAACgZIQBAAAAUDLCAAAAACgZYQAAAACUjDAAAAAASkYYAAAAACUjDAAAAICSEQYAAABAyQgDAAAAoGSEAQAAAFAywgAAAAAoGWEAAAAAlIwwAAAAAEpGGAAAAAAlIwwAAACAkhEGAAAAQMkIAwAAAKBkhAEAAABQMsIAAAAAKBlhAAAAAJSMMAAAAABKRhgAAAAAJSMMAAAAgJIRBgAAAEDJCAMAAACgZIQBAAAAUDLCAAAAACgZYQAAAACUjDAAAAAASkYYAAAAACUjDAAAAICSEQYAAABAySx4GLBp06Zs3Lgxw8PDC31oAAAAIEnHQh9ww4YN2bBhQ+r1+kIfGgAAAIhhAgAAAFA6wgAAAAAoGWEAAAAAlIwwAAAAAEpGGAAAAAAlIwwAAACAkhEGAAAAQMkIAwAAAKBkhAEAAABQMsIAAAAAKBlhAAAAAJSMMAAAAABKRhgAAAAAJSMMAAAAgJIRBgAAAEDJCAMAAACgZIQBAAAAUDLCAAAAACgZYQAAAACUjDAAAAAASkYYAAAAACUjDAAAAICSEQYAAABAyQgDAAAAoGSEAQAAAFAywgAAAAAoGWEAAAAAlIwwAAAAAEpGGAAAAAAlIwwAAACAkhEGAAAAQMkIAwAAAKBkhAEAAABQMsIAAAAAKBlhAAAAAJSMMAAAAABKRhgAAAAAJSMMAAAAgJIRBgAAAEDJCAMAAACgZIQBAAAAUDLCAAAAACgZYQAAAACUjDAAAAAASkYYAAAAACUjDAAAAICSEQYAAABAyQgDAAAAoGSEAQAAAFAyCx4GbNq0KRs3bszw8PBCHxoAAABI0rHQB9ywYUM2bNiQer2+0IcGAAAAYpgAAAAAlI4wAAAAAEpGGAAAAAAlIwwAAACAkhEGAAAAQMkIAwAAAKBkhAEAAABQMsIAAAAAKBlhAAAAAJSMMAAAAABKRhgAAAAAJSMMAAAAgJIRBgAAAEDJCAMAAACgZIQBAAAAUDLCAAAAACgZYQAAAACUTMdiV6AdFIODGb3hHdl18ikZXbYiWd2frO5PZfWJY49PTJavTKUqWwEAAGDpEwYcjNF6Kuf9eCoH9qV48ofJA/cnO7enGDgwuU2tlqw6oREMTA0KVvWncsKU0KCnN5VKZfHOBQAAgNITBhyESm9fKpe8MSv7+7N9+/aJ54uB/cnO7cmObSl2bW883rk9xc5tKR76fvLNseX6yGRh3T2TgcGq/uSEFr0MVvWn0tm5CGcKAABAGQgDjkClpy85pS855bTM9l1/MTqa7NszFhRsSzEWHmTX9sbj7z7SCAz27EqKYnLH5Svm72WwYmUq1dqCnCsAAADHD2HAMVapVpMVqxo/P3Lm7KHByEiye0dzaLBzWyMo2PZk8oPvNR4f2De5U7WarOqfEhQ0/s0JJ6YyHhis7k96lxmaAAAAwARhwBJR6ehI+k9u/CSzhwYDB5JdO6YEBlNCg0f+X/KtrzUejwxP7tTV3XrSw4mhCicmq05Ipav72J8oAAAAi04Y0GYqPb1JT2/yjLWzBwZFMXNownhgsHN7svnbjXW7dzS2HTd+p4SJXgYnJif0N/cyWLna0AQAAIA2Jww4DlUqlWT5ysbPaWfMHhrU68nunc1BwfjjHduS//dA4/H+vVMKryarVrccjjDRy2B1f9K33NAEAACAJUoYUGKVWq3x4f2EExvLs2xXDA4mu2b2MsjO7Skeeyi5/+uNx8NDkzt1djUPTRi/c8LUSRBXnZhKt6EJAAAAC00YwLwq3d3JmlOTNafOPTRh/77WvQx2bku+/51GgLBrR4pidHLHvmWTvQym9CyYnMugvzGfQc3QBAAAgKNFGMBRUalUkmXLGz/PPH2OWy3Wk927moOC8V4GO7clD/+g8XjfnqmFJytXTxuO0OJWi8tWGJoAAABwEIQBLKhKtTYxfCCZY2jC8NCUkGDq0IRtKZ54NPnepsbjocHJnTo6WvYyGA8NRk4/M0WlI5XunmN/ogAAAEuYMIAlqdLZlZx8SnLyKXMPTTiwf/ahCT/43tjQhO0pRkezY3zH3r4WvQxOHLuDwlgvg1UnNG73CAAAcBzyaYe2ValUGnMO9C1L1q6bY2jCaLJ3V1aOjmT3Q1umDE0YmxDx0S2Nx3t3Ty28cTeGsXkLKuPzF6ye8viEsaEJ1epCnC4AAMBRIwzguFepVpOVJ6Szvz+V1SfPMTRheOyuCWO9CXZMCQ22Pp78x7eTHdtTDB6Y3KnWMTnsYWpocMJYr4PVJzYe9/QtyLkCAAAcDGEAjKl0diYnPaPxkznmMxjYn+yYeqvFyfCg2PJAsmNb464J9ZHJnbp7myc9bNXLYNUJqXR0HvsTBQAASk8YAIeo0tOXnNqXnHra3EMT9u0ZCwam9TLYuT15/OFkx7YUe3Y177hiVYugoD+VVY0eBlndnyxfZWgCAABwRIQBcAxUqtXGB/sVq5I8a/bQYGQ42bWzeRLEXdsawxGe3po88J1GmHBg/+ROtVqy6oTmOyeM3V6xsrp/Yp6D9Pa51SIAANCSMAAWUaWjMznx5MZP5hqacKB5LoNd2xu9DnZuT/HIg8mmf2usG5k6NKFnspfB2N0TZt45ob9x5wYAAKBUhAHQBio9vckpz0xOeebct1rcu6fRs2Dn1NBge4pd25PvbWos797Z2Hbc8hXNvQzG76AwtZfBylWpVGsLcq4AAMCxJwyA40SlUklWrGz8nHbm7KFBvZ7s2jHRu6CY2stgx9PJg5sbvQz275vcaeyODE3DEcYfj/U2yOr+pG+ZoQkAANAGhAFQMpVaLek/qfFz5hxDEwYHJm61OLWXQXZtT/HoluT+f2+ECSPDkzt1dbXsZdA0VGF1fypd3QtxqgAAwCyEAUBLle6eZM3aZM3auYcm7N/bmM9gvJfB1LsmbP52I0TYtTNFMTq5Y9/y5uEIY0FBUy+DlasbwQUAAHDUCQOAw1apVJJlKxo/zzx97qEJe3Y2BwU7GndOKHZuTx76fqMHwr49UwqvJitXT/YmOOHE7DvpGRlNGpMj9vSm0t2b9PROLGd8uadXkAAAAHMQBgDHXKVWG/v2/8Qk58weGgwNNuYzmNbLIDu3p3j84Qz+4Hsp9u1NBgeSgQMp6iOzlJSko7M5KJgIC3rGQoRpAUJ3T2OixukBQ09P0t2XdHWZDwEAgOOGMABYMipd3cnJpyQnn9IyMOjv78/27dsnlouR4WTgwEQ40Hh8IBkYaNyOcfz5wQNT1g+k2LMrefqJ5n0HBxrzJMxauepYMNA75d+xXggTPRNmCxh6kp6+GfvrvQAAwGIRBgBtq9LRmSzvTJavnLnuMMorRuvJ0OBYcDAwESxk4ECKwQPTwoMp4cLAgWT3zpbhQzE6OvsBO7um9FpoDhRmGwJRmRooTO/J0Kn3AgAAB0cYADCmUq2NfYPfN3PdYZRXFEUyMjwWKOxv6oXQOmBobFcMHEixe0fy5ONTQolGyFAMDc1+wGq1xTCH+YZA9DbWtezZ0N14TQAAOO4IAwCOkUql0vj2v7MrWXEUey8MDMzeQ2GiV8K0ng0DBxpzMMwIHw403+lhuq7uFhM09kz2XJgyF8OcwcPYclEUh3HWAAAcbcIAgDZSqdaSvmWNn+nrDqO8oiiS4aG5h0BM79kwcKAxv8KObU3bTuwzPHvvhadrtZbzLkyECHPOvdCiZ0NXTyrV6mGcOQBAuQkDAEqsUqk0vv3v6m69/jDKLEZGkqHm3gfjIcOyjo7sffqp1vMr7N+XbH+6dSgxV4+CGRM4NiZsnDGx49S5F6Zt29SzoaPzMM4aAKC9LJkwoCiK1Ov1Jd2FdGBgIMPDw4tdDQ5Tq/arVCqp1WomXYOjqNLRkXQsT/qWz1jX09+f/VPuCHEwiqJoTOw4dQhEq6ER00KEYuBAsv2p1utG5rotZUeLYQ6zTOw4NXyYbXLHrm6/YwCAJWdJhAFFUeTAgQOp1WqpLuHunnv27FnsKnAEWrVfvV7P0NBQent7/bEOS1SlUml84O7uSVae0LzuMMssRobHAoJ55l5o6tkwkGLfnmT7kzPnZRg8kFmj7In6zwwYKk09FqYFD3PMveC2lADAkVoSYUC9Xk+tVkt3d+tuqktFrVZLvV5f7GpwmGZrv8HBwdTr9XR0LInLAVgAlY7OpKMzWbZi5rrDKK8YHZ28LeX0XggzhkQMTOm9MJDs3d0UOEzcOWKu/286OmcZAjE+ueMs8y7MFjB0uS0lAJTNkvj0UxTFku4RwPGtWq0u6eEpwNJXqVYnP5RPX3eYZRbDw3MMgWi+W0TT3At7diVPPTFj32JocK4TmDKpY/PkjtPnXti/uj+j9Xpj8sbu7sk7TnT1JNOXhQwAsGQtiTAAAGhW6exMOjuT5UfxtpSDgy2GQAykmHq3iFZzL+zeObHuwPBQY/uhwRRDs985YsJEODAlKBhbrkwsj63rmlyX7u5GENE1uTxZztg+ncIGADhcpQ4DHnnkkbzzne/Mxo0bF7sqAHBMVaq1pLev8TN93SGU09/fn+1jk0BODI8YGmgEDUODjTBhaDAZHEwxNNC0nKGByW3G1+/eMbHcVNbgQGNuhzlPqtIcMkz7tzIeInRNWTdludLdojfD1OWOTmEDAMetUocBAMDhm2t4RHL4QyTGFaP1KUHCeIgwFigMDTbmY5iyPD1UKAYHkh37ZgksBua+q0TjBKeFBc29GypNy9N6N3SP9XyY1tuhabmjQ9gAwKJZkmFAMTyUPPnE0SlszSmpdHbNuclXv/rVvP/970+1Ws3555+f6667Lps3b85VV12Vnp6e9Pb25tOf/nQ+/vGP56/+6q+yfPnyvPzlL8+b3/zmo1NHAGCGSrWW9PQ1flqtP8Lyi3q9KRyYERbMCCGGxrYbGAsjBpN9e2bp/TCYoj5P2FCtzjqEYqLnQsteD41QodKit8PUYKLS0XmErxAAx7MlGQbkyScy+t4rjkpR1ffenjxz3ZzbvOc978nHP/7xnHbaabnyyitz7733ZvPmzbn44otz6aWXZnR0NEnymc98JnfddVdWr1498RwA0J4qtdmHTiRHIWwYGWkKByZCh/GwYKJXw8CU9ZMBRDE0mOzZNWP4xXggUcz3t0it1jz0oasnO5YtT30shKjMmPSxufdCpUVvh6nLbnEJ0N6WZhiw5pRU33v7UStrPnv37s1pp52WJLnwwgvzgx/8IK997Wtz22235fLLL895552Xyy+/PNddd13e9773ZWRkJG94wxvyvOc97+jUEQA47lQ6OpKO5Unf8tbrj7D8YmR4WojQHCoULXo7dFYqqe/e1QgTBg8ke3bOGH4xMadDMV/Y0DFt6EPXlDtJdDfChFkngRyfs2FaCDGld0OlKmwAOJaWZBhQ6eya99v8o2nZsmV59NFHc9ppp+WrX/1qLr744nR3d+fd7353kuS1r31tXvayl+XHfuzHcuutt+bxxx/PZZddlr/7u79bsDoCAExV6ehMOjqTZQcfNizv78/Q2ASQcymKIhnv2TA4M1RoTAA5s7fD5PJQigP7k53bp4UMk8Mt5r2tb0fnLHMyTJkgstUtLbunhA3Th2BMlCNsAFiSYcBCe9/73pe3vOUtqVarOe+88/LiF784f/mXf5m777471Wo1a9asyZlnnpnLL78827Zty+DgYP7rf/2vi11tAIBjolKpNG5t2dmZLFvRepsjKL8oimR4aNpdJJqHQhSD00OGaXeb2Lc32bFtyn7N/84TNSSdXS0mdpzs3VBp6s0ws3dDZUowMSN06OxqTLAJsIRVinlj2WOjXq9n69atSZLh4catgzo7l/ZEN7VaLfV6fbGrwWGarf3a5f1H8y3NaE/asP1pw/ZWlvYrimLGhI/Tb29ZtLjd5eR8DdN7Q0zrGTE0NH8lurqahz5Mm5thcs6G6aHClPkaWtzysv8Zp2T73r16NrSxslyHx6t2bb+1a9fOeE7PAAAAjiuVSmXsA3Z3smJV622OoPxidHSsZ0OLO02MD6GYPsRi2p0oij07k6fH9p0+ueTw7GHD0+MPah2NwKGza7KXQ2fnlMddjaG3Tdt0JZ3dzc91dqUyy/PN23cKIOA4IwwAAIBDUBm/LWR3T+v1R1h+MVqf0huheQjE8u6u7N2+LcXQUDIy1AgThsf/HWz8OzLcCB2Gh5I9uxvrh6dsO77d2HPzThY5TgABxxVhAAAALCGVai3p6Wv8TNPd359927cfceAwVTEyMjMkGJ4ZNBTDwzOChAwPJsPDY8sHE0A0ypj31pjjBBBwzAgDAACgxBq3wexIemeGD03bHcVjzgwgWgQNI0ONHhAzAoipgcU8AcTw8GSYsdgBxNgdMkYG9qbYf0AAwaITBgAAAAtq0QOIKSHB9IBhRgAxPYQYDyD27mkM32gZUsweQOxoVbljHEDoAUErwoA2cuedd+a//bf/dkzKfvLJJ3PHHXfk937v9w56n7vuuitPPfVUrrjiimNSJwAAOFoWN4CYDAlW9vZk99NPzRFADLcII8aGaRxmANGSAKL0hAFHwejoaKoLcC/ZYxUG1Ov1rFmz5pCCgMU0fjfMSuVo/qoGAICjq1UA0dnfn8rqk5q3O4rHLEZGZp9c8lACiPFtpgcQLcoWQLSnUocBmzdvzlVXXZWenp709vbmxBNPTKVSydatWzM8PJyPfexjOfHEE3PllVfm8ccfz759+/Ke97wnP/3TP523ve1t6e3tzaOPPprf+q3fyu23356BgYFUKpXccMMN+ZEf+ZFce+21efTRR1MURT74wQ/m7LPPnlGHoaGhXHvttXnooYdSrVZzww035Ic//GE+9KEPZXh4OOvWrcttt92WT37yk3nsscdyySWX5Nd+7dfy0pe+NNdcc0127tyZrq6u3HrrrVmzZk3uuOOO3HPPPTnzzDPz0EMP5aMf/WhOOumk/PZv/3a2bduWarWam266Kaeffnp+9md/Nr/wC7+Qr33ta/nQhz6Ud77zndm4cWPuv//+vOc970mSrFu3Lrfccks+8IEP5Bvf+Eb27NmTt771rXnlK18552t73333zTiHSqWST3ziE7nnnnvS09OTN7zhDbnooovygQ98IP/6r/+arq6uXH311XnooYcmehw88sgjE/W65JJLcsEFF+Q73/lObr755lx11VUZHh7O4OBgbr755qxfv35G3X/zN38zN954Y/74j/84SXLZZZflmmuuyfr164/yuwkAABbfRADRYgLKpu2O4jGLen32ySXHg4SpAcR8wzSmBhCzTWi5UAFEx+S6SldXBvtPTPHMZ6XS2XkUX8HFsSTDgKH6aJ7YM3xUyjplRWe6aq2/tb/33ntz8cUX59JLL83o6Gje/va3Z/369bn11ltz99135+Mf/3je9a535YMf/GD6+vry2GOP5a1vfWs+97nPJUlOP/30XH/99fnWt76V3t7ebNy4MUmjp8CnP/3pnHvuubn11lvz4IMP5g/+4A9y5513zqjDX/zFX2Tt2rW59dZbkzS+pT/11FPz2c9+NknyO7/zO7nvvvvy5je/OX/2Z3828fx1112Xiy++OL/0S7+Uf/qnf8rtt9+eK6+8Mp///OfzN3/zNxkYGMgLXvCCJMmf//mf5znPeU6uvPLK3HfffbnhhhvyR3/0RxkcHMwrXvGKvOtd78ojjzwyUaff/d3fzS233JKzzz479Xo9SfL2t789fX192bNnT1796lfPGwb8xE/8xIxzOPnkk/PFL34xf/3Xf51arZZ6vZ4vfelLefLJJ/OFL3xh4vwfeuihWcv98R//8fz+7/9+kuSTn/xk+vr68pWvfCUf/vCH8+EPf3hG3Wu1Wnbs2JHt27enWq1m27ZtggAAADiKKrVaUmt9B4ym7Y7iMVsHEJPDKpoDiIPoJTEeQIwMzxyKMT6hZb2e3Umqt/55I1Boc0syDHhiz3De+nf/76iU9eFXnJl1q7tbrnvta1+b2267LZdffnnOO++8JMlzn/vcJI0Ps3//93+f0dHR3Hjjjfn617+ejo6OPPHEExP7/+RP/mSS5DnPeU4uvPDCXHHFFenv78/VV1+dzZs352tf+1r+4R/+Yc76bd68uemDda1Wy3e/+93ceOONGR4ezuOPP57nP//5M/b73ve+l//7f/9vPvWpT6Ver+e0007Lww8/nHPPPTcdHR1Zvnz5xIfeH/zgB7nooouSJBdeeGH+4A/+IEnS2dmZCy64YEbZu3btmujFUKs1utXceeed+Yd/+IfUarU8/PDDc55TkpbnsGPHjvzUT/3URJm1Wi2bN2/OC1/4wqbzn9r9f3xIwLjx1/zAgQP5n//zf2bLli2p1+vp6uqate6/8iu/ks997nOpVCp5zWteM2/dAQCApW2xAogTli/Ljv0HjmKpi2dJhgGnrOjMh19x5lErazbd3d1597vfnaQRDKxevTrf/OY38/znPz/f+MY38qxnPSv3339/Hnzwwdxzzz159NFHc8kll0zsPz5PwODgYP7H//gfqVQq+dCHPpTPfe5zWb9+fdavX583vvGNSRrDAVr50R/90XzlK1+Z+EA8Ojo68Q33BRdckLe97W0TH4inzkuwfv36PP/5z89LX/rSifJ37dqVzZs3p16vZ2BgIA888ECS5KyzzspXv/rVvOAFL8hXv/rVPOtZz5pR3lQrV67Mgw8+mGc961kZHR3Nrl278vnPfz5f/OIXs3fv3vyn//Sf5n7Rk5bnsH79+mzcuHHiG/vR0dGsX78+f/u3f5vXvva1E+c/3g5JsmnTpqZyxz/gf/nLX05fX18+//nP55//+Z9zyy23tKx7tVrNq171qvyX//JfUq/XJ3pvAAAAHIpKrZZqb18qBwYWuypHxZIMA7pq1Vm/zT+a7rnnntx9992pVqtZs2ZNarVaHnzwwfz6r/96hoaG8tGPfjTLly/Pvn37cskll+TCCy9MZ4vuIA888EB+//d/Px0dHSmKIn/4h3+YNWvW5F3veld+5Vd+JUVR5Gd/9mdz5ZVXztj3da97Xa655ppcfPHFqdVq+eAHP5iLLroov/3bv52zzz676QP7BRdckEsvvTS//Mu/nLe+9a155zvfmY9//ONJkte85jX5tV/7tVx00UV55StfmTPOOCOnnnpqOjs78xu/8Ru58sor88u//MupVqu58cYb53xdrr/++lx99dWpVqtZt25dbr755px55pm5+OKLc95552XVqlXzvratzuHcc8/Nf/7P/zmvfvWr09vbm9e//vW56KKL8n/+z//Jq171qvT09OTtb397XvSiF+WOO+7Ir//6r0/02JjuJ3/yJ3P77bfnda97XdM20+t+yy23pK+vL+ecc04GBwezfPnyeesOAABwvKsU0/thL5B6vZ6tW7cmSYaHG/MDtPqgvZDe9ra35fWvf/1EV/Tpxse5L2XDw8Pp7OzM3r178/KXvzz/9E//NPFteplde+21ueSSS/K85z1vxrql8v5jfv39/dm+fftiV4MjoA3bnzZsb9qv/WnD9qcN21u7tt/atWtnPLckewYcr8Zn5B+3evXqfOITnziqx7jtttvyla98JXv27MnVV1+9IEHA+N0Wxp1zzjm5/vrrj/lxD9YVV1yRkZGR/PRP//SSD3MAAAAWgp4Bh6AdegYwu9nar13ef7RvEsskbdj+tGF7037tTxu2P23Y3tq1/Vr1DGg9gxwAAABw3FoSwwRqtVoOHDiQoiiabiu31NTr9YyOji52NThMrdqvKIoMDw+nt7d3kWoFAACw8JZEz4BqtZq+vr5Zb3W3VKxYsWKxq8ARaNV+7fLeAwAAOJqWRM+AJKlUKunoWDLVaamnpyf79+9f7GpwmLQfAABAg69DAQAAoGSEAQAAAFAywgAAAAAomUpRFMViV6JdDA4Opru7e7GrwWHSfu1PG7Y/bdj+tGF7037tTxu2P23Y3o6n9tMz4BDccssti10FjoD2a3/asP1pw/anDdub9mt/2rD9acP2djy1nzAAAAAASkYYcAh+5md+ZrGrwBHQfu1PG7Y/bdj+tGF7037tTxu2P23Y3o6n9jNnAAAAAJSMngEAAABQMh2LXYGl6Etf+lK+/OUvp1Kp5LLLLsu6desm1m3dujUf+9jHMjIykuc973m56KKLFrGmzGauNvzIRz6Shx9+OL29vVm7dm3++3//74tYU1oZHBzM+9///jz22GO57LLL8sIXvrBpvetw6ZuvDV2HS9sjjzySO+64I9VqNdVqNb/5m7+ZZzzjGRPrXYNL33xt6Bpc+p588sncdtttqdVqGR0dzZvf/OacfvrpE+tdh0vbfO3nGmwfjz/+eK666qq8733vy/r16yeePy6uwYIme/bsKd7xjncUw8PDxWOPPVa8973vbVp/8803F5s3by5GR0eLd7/73cXWrVsXqabMZr42vP3224vNmzcvUu04GPV6vdixY0dx1113Fffdd9+M9a7DpW++NnQdLm07d+4s9u3bVxRFUXz9618vPvKRjzStdw0uffO1oWtw6RsZGSnq9XpRFEXxrW99q7j11lub1rsOl7b52s812D5uu+224v3vf/+M9joerkE9A6b5/ve/n/PPPz8dHR1Zu3Zt9uzZk9HR0VSrjREVjz322EQi9BM/8RP5zne+kzVr1ixmlZlmvjZMkj/5kz9JZ2dnLr744jz3uc9dvMrSUrVazerVq2dd7zpc+uZrw8R1uJStWrVq4nGtVmv6/Zm4BtvBfG2YuAaXulqtNvF4//79Td8qJ67DpW6+9ktcg+3ggQceyOrVq1v+Dj0erkFhwDR79+7NsmXLJpZ7e3uzf//+LF++PEkyOjo6sW7ZsmXZu3fvgteRuc3Xhq9//euzcuXK7Ny5M+973/tyzjnnNG3P0uc6bH+uw/YwNDSUu+++O5dddlnT867B9jFbG7oG28OWLVvyx3/8x9m2bVuuvvrqpnWuw6VvrvZzDbaHz33uc/mt3/qt/Nmf/dmMdcfDNWgCwWmWLVuWffv2TSwfOHAgfX19E8uVSmXi8dQPmCwd87XhypUrkySrV6/OWWedlR/+8IcLXkeOjOuw/bkOl756vZ4//MM/zKte9aqmeVcS12C7mKsNXYPt4Ywzzsh1112Xd7zjHfnkJz/ZtM51uPTN1X6uwaXv3//933PWWWdlxYoVLdcfD9egMGCac845J9/97ndTr9fzxBNPZMWKFU3dQk477bR8//vfT1EU+frXv55nP/vZi1hbWpmvDffv35+k8W3Jli1bcvLJJy9WVTlMrsP25zpc2oqiyMc+9rFccMEF+amf+qkZ612DS998begaXPqGh4cnHvf19aW7u7tpvetwaZuv/VyDS9+WLVty//3357rrrsumTZvyp3/6p9mxY8fE+uPhGqwURVEsdiWWmn/8x3/Mvffem0qlkksvvTQ7d+7M3r178zM/8zN54okn8rGPfSz1ej0XXnhhXv3qVy92dWlhrja8/vrrs3///oyMjOTlL395XvziFy92dWnhpptuypYtW9Ld3Z0f+7Efy3Of+1zXYZuZqw1dh0vbN77xjdx00005++yzkzS+3XINtpf52tA1uPR9+9vfzmc+85lUq9UURZE3vOEN2b17t+uwTczXfq7B9vKRj3wkL3vZy7J///7j6hoUBgAAAEDJGCYAAAAAJSMMAAAAgJIRBgAAAEDJCAMAAACgZIQBAAAAUDIdi10BAODQ/Oqv/mpOP/30ieWTTjop11577TE5zt13333UywUAFp8wAADa0I033rjYVQAA2pgwAACOE/fee2/+5V/+JfV6PU8//XTWrl2byy+/PH19fdm/f38+8YlP5KGHHkqSvOIVr8hLXvKSJMnDDz+cO++8M3v37k2SvOlNb8qzn/3sJMk999yTr3zlKxkcHMzll1+ec845Z8ZxL7/88vzcz/1cvvGNb2T37t154xvfmAsvvDD3339/PvOZz+S9733vRP3uv//+XH755RN1rVarefTRR3PWWWflF3/xF7Nx48Y8/fTTueiii/Lyl798AV41ACgnYQAAtKFrrrlm4vGzn/3svOlNb0qSfPe7381NN92Uk08+OZ/61Kfy2c9+Nm94wxvy2c9+Nn19fbn55puze/fu/O7v/m7OPvvsrF27NjfeeGPe/OY354ILLki9Xs/g4OBE2atXr84NN9yQ++67L3fddVd+7/d+r2V9KpVK/tf/+l/5j//4j3zkIx/JhRdeOO85PPjgg7npppuyfPnyXHvttfnCF76Qd7/73dmxY0euuuqqvPSlL02tVjvCVwoAaEUYAABtaLZhAs95znNy8sknJ0le8pKX5KMf/WiS5P77789b3vKWJMnKlSvzvOc9L/fff3+SpLu7OxdccEGSpFarpa+vb6K8F7zgBUmSs88+O3fdddes9Zm63datWw/qHM4777ysXLkySbJu3bqce+65qdVqOemkk9Ld3Z2dO3fmxBNPPKiyAIBD424CAMCsurq6kiTVajWjo6OzbtfZ2Tlju1qtlqIoJrYZGhpquc/4ftOX6/X6kZ8AANCSMAAAjiPf/va38/TTTydpjNE///zzkyTnn39+vvSlLyVJ9uzZk3/7t3/L+eefn7Vr12ZwcDDf/OY3kySjo6PZv3//UanLmjVr8vjjj2dgYCAjIyP513/916NSLgBw5AwTAIA2NHXOgO7u7nzgAx9I0pg/4I477shTTz2VU089NVdccUWS5JJLLsknPvGJXHXVVUmS17zmNVm3bl2S5Oqrr86nPvWpfPrTn061Ws2b3vSmnHvuuUdcx/7+/rzsZS/LNddck9WrV+f0009vmo/gYF1//fX51V/91Zx11llHXCcAoKFSTO2/BwC0ramz9QMAzMUwAQAAACgZPQMAAACgZPQMAAAAgJIRBgAAAEDJCAMAAACgZIQBAAAAUDLCAAAAACiZ/w9ANQmr8e/ggwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1280x384 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot()\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Epoch num.')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b16b83b4",
   "metadata": {},
   "source": [
    "Now let's see how it interprets the sentiment of a good, fair and bad review extracted from the amazon website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0fc59e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good was classified as 2\n",
      "Poor was classified as 2\n",
      "Evil was classified as 1\n"
     ]
    }
   ],
   "source": [
    "good = \"My nephew is on the autism spectrum and likes to fidget with things so I knew this toy would be a hit. Was concerned that it may not be \\\"complex\\\" enough for his very advanced brain but he really took to it. Both him (14 yrs) and his little brother (8 yrs) both enjoyed playing with it throughout Christmas morning. I'm always happy when I can find them something unique and engaging.\"\n",
    "poor = \"I wasn't sure about this as it's really small. I bought it for my 9 year old grandson. I was ready to send it back but my daughter decided it was a good gift so I'm hoping he likes it. Seems expensive for the price though to me.\"\n",
    "evil = \"I just wanted to follow up to say that I reported this directly to the company and had no response. I have not gotten any response from my review. The level of customer service goes a long way when an item you purchase is defective and this company didn’t care to respond. No I am even more Leary about ordering anything from this company. I never asked for a refund or replacement since I am not able to return it. I’m just wanted to let them know that this was a high dollar item and I expected it to be a quality item. Very disappointed! I bought this for my grandson for Christmas. He loved it and played with it a lot. My daughter called to say that the stickers were peeling on the corners. I am not able to take it from my grandson because he is autistic and wouldn’t understand. I just wanted to warn others who are wanting to get this. Please know that this is a cool toy and it may not happen to yours so it is up to you.\"\n",
    "\n",
    "probabilities = model.predict([good, poor, evil], verbose=0)\n",
    "print(f'Good was classified as {np.argmax(probabilities[0])}')\n",
    "print(f'Poor was classified as {np.argmax(probabilities[1])}')\n",
    "print(f'Evil was classified as {np.argmax(probabilities[2])}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "43585490",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e7defd88",
   "metadata": {},
   "source": [
    "We have demonstrated how to use a convolutional neural network (CNN) to classify text, specifically, product reviews as good, average or bad. We also discussed the benefits of using pre-trained word embeddings, which can help improve the performance of the model by leveraging the semantic relationships between words in the pre-trained corpus. We also explored the TextVectorization layer, which provides a flexible way to preprocess text data and convert it into numerical vectors.\n",
    "\n",
    "This is an example that can serve as a starting point for a multitude of NLP projects."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "33005bde",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "<div><img style=\"float: right; width: 120px; vertical-align:top\" src=\"https://mirrors.creativecommons.org/presskit/buttons/88x31/png/by-nc-sa.png\" alt=\"Creative Commons by-nc-sa logo\" />\n",
    "\n",
    "[Back to top](#top)\n",
    "\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
