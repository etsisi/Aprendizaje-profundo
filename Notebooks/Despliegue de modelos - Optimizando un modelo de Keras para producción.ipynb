{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2dd84b7c",
   "metadata": {},
   "source": [
    "# Optimizando un modelo de Keras para producción\n",
    "\n",
    "Vamos a ver algunas de las utilidades para mejorar la latencia y el tamaño que ocupan los modelos de Keras. Para ello usaremos la librería `tensorflow-model-optimization` por lo que será necesario instalarla primero con pip.\n",
    "\n",
    "```bash\n",
    "$ pip install tensorflow-model-optimization\n",
    "```\n",
    "\n",
    "Empezamos importando las librerías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80889645",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_model_optimization as tfmot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bbafb9",
   "metadata": {},
   "source": [
    "Ahora declaramos una serie de constantes que usaremos a lo largo del ejercicio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db0e0654",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb920cc3",
   "metadata": {},
   "source": [
    "También aprovecharemos y crearemos una función para ver el tamaño que ocupan los modelos en memoria. Como dependiendo del formato, los modelos se salvarán en un directorio o en un único fichero, la función mirará esos dos casos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "060c508d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_size(path):\n",
    "    \"\"\"Returns the size of the model located in path in MiB.\"\"\"\n",
    "    if Path(path).is_dir():\n",
    "        size = sum(\n",
    "            f.stat().st_size\n",
    "            for f in Path(path).glob('**/*')\n",
    "            if f.is_file()\n",
    "        )\n",
    "    else:\n",
    "        size = Path(path).stat().st_size\n",
    "    \n",
    "    return size / 1024**2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d21446",
   "metadata": {},
   "source": [
    "Para hacer las pruebas usaremos el manido MNIST. Crearemos primero los conjuntos de entrenamiento y test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cee7d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a012da5d",
   "metadata": {},
   "source": [
    "Por último, crearemos el modelo base sobre el que trabajaremos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1baebc7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape (Reshape)            (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 26, 26, 4)         40        \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 8)         296       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 3, 3, 16)          1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 1, 1, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                170       \n",
      "=================================================================\n",
      "Total params: 1,674\n",
      "Trainable params: 1,674\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.InputLayer(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
    "  tf.keras.layers.Conv2D(filters=4, kernel_size=(3, 3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "  tf.keras.layers.Conv2D(filters=8, kernel_size=(3, 3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "  tf.keras.layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(10)\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f19062b",
   "metadata": {},
   "source": [
    "## Salvado de modelo en formato SavedModel\n",
    "\n",
    "El formato `SavedModel` se usa, entre otras cosas, como formato _de facto_ para servir a traves de TensorFlow Serve. El salvado y la carga de estos modelos es muy parecida a la del método `save` de los modelos de Keras.\n",
    "\n",
    "Vamos a salvar nuestro modelo recién creado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd9b50b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-31 22:26:17.548100: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: base_model.pb/assets\n"
     ]
    }
   ],
   "source": [
    "tf.keras.models.save_model(model, 'base_model.pb')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8882e77f",
   "metadata": {},
   "source": [
    "Para cargarlo, es prácticamente igual de sencillo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5822d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape (Reshape)            (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 26, 26, 4)         40        \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 8)         296       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 3, 3, 16)          1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 1, 1, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                170       \n",
      "=================================================================\n",
      "Total params: 1,674\n",
      "Trainable params: 1,674\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('base_model.pb')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702278ae",
   "metadata": {},
   "source": [
    "## Entrenamiento y cálculo de valores para el modelo base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2764649",
   "metadata": {},
   "source": [
    "Vamos a entrenar el modelo para usar los valores de _loss_, _accuracy_, tiempo de ejecución y tamaño del fichero como valores de referencia. Para ello entrenaremos primero el modelo base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b11919c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 2s 2ms/step - loss: 0.9727 - accuracy: 0.6872\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.3407 - accuracy: 0.8965\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2672 - accuracy: 0.9173\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2313 - accuracy: 0.9286\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2069 - accuracy: 0.9359\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1914 - accuracy: 0.9412\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1800 - accuracy: 0.9446\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1693 - accuracy: 0.9483\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1622 - accuracy: 0.9495\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1546 - accuracy: 0.9525\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fc57be",
   "metadata": {},
   "source": [
    "Ahora obtenemos los valores. No es la mejor forma de calcular los tiempos, pero nos puede dar una ligera idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94aef467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model.pb/assets\n",
      "Saved base model to: \"model.pb\" (0.153 MiB)\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "base_loss, base_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "base_time = time.time() - start\n",
    "tf.keras.models.save_model(model, 'model.pb', include_optimizer=False)\n",
    "base_size = model_size(\"model.pb\")\n",
    "\n",
    "print(f'Saved base model to: \"model.pb\" ({base_size:.4} MiB)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c95114",
   "metadata": {},
   "source": [
    "## Poda del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdfa688",
   "metadata": {},
   "source": [
    "La poda de pesos significa eliminar los valores innecesarios en los tensores que almacenan los pesos ajustados durante los entrenamiento. Prácticamente estamos poniendo a cero los valores de los parámetros de la red neuronal para eliminar lo que estimamos que son conexiones innecesarias entre las capas de una red neuronal. La siguiente figura lo representa de manera muy explícita.\n",
    "\n",
    "| <img src=\"https://miro.medium.com/max/1400/0*iNI8Oc80Eunm8NgI\" alt=\"Pruning example\" width=\"500\"> | \n",
    "|:--:| \n",
    "| *Ejemplo de poda. Fuente: [miro.medium.com](https://miro.medium.com)* |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48d71a8",
   "metadata": {},
   "source": [
    "Ahora aplicaremos la poda a todo el modelo. En este caso en concreto usamos la función `prune_low_magnitude` que tratará de encontrar pesos suficientemente pequeños como para convertirlos en 0 y así convertir la matriz de pesos en una matriz dispersa (menos espacio y más rapidez en los cálculos)\n",
    "\n",
    "En la [guía completa](https://www.tensorflow.org/model_optimization/guide/pruning/comprehensive_guide.md) se explica con más detalle las diferentes opciones tanto de objetos de configuración (e.g. `PolynomialDecay`, un detector de pesos pequeños similar al `LearningRateDecay` para el factor de aprendizaje) como de poda selectiva por capas.\n",
    "\n",
    "**NOTA**: La función `prune_low_magnitude` reescribe el modelo, y por tanto necesita una recompilación del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d738acbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/blazaid/.local/share/virtualenvs/deep-learning-99e-ingI/lib/python3.8/site-packages/keras/engine/base_layer.py:2223: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  warnings.warn('`layer.add_variable` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "prune_low_magnitude_reshape  (None, 28, 28, 1)         1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_conv2d ( (None, 26, 26, 4)         78        \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_max_pool (None, 13, 13, 4)         1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_conv2d_1 (None, 11, 11, 8)         586       \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_max_pool (None, 5, 5, 8)           1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_conv2d_2 (None, 3, 3, 16)          2322      \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_max_pool (None, 1, 1, 16)          1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_flatten  (None, 16)                1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_dense (P (None, 10)                332       \n",
      "=================================================================\n",
      "Total params: 3,323\n",
      "Trainable params: 1,674\n",
      "Non-trainable params: 1,649\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 1.1733 - accuracy: 0.6277\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.4492 - accuracy: 0.8646\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.3491 - accuracy: 0.8951\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.3070 - accuracy: 0.9070\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.2815 - accuracy: 0.9144\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.2625 - accuracy: 0.9203\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.2485 - accuracy: 0.9244\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.2373 - accuracy: 0.9271\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.2271 - accuracy: 0.9312\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.2181 - accuracy: 0.9333\n"
     ]
    }
   ],
   "source": [
    "pruned_model = tf.keras.models.load_model('base_model.pb')\n",
    "pruned_model = tfmot.sparsity.keras.prune_low_magnitude(pruned_model)\n",
    "\n",
    "pruned_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "pruned_model.summary()\n",
    "\n",
    "pruned_model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks = [tfmot.sparsity.keras.UpdatePruningStep()]\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534f4cf6",
   "metadata": {},
   "source": [
    "Ahora tomaremos los valores del modelo podado para compararlos con los valores del modelo base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4aa19b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as reshape_layer_call_fn, reshape_layer_call_and_return_conditional_losses, conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: pruned_model.pb/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: pruned_model.pb/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved pruned model to: \"pruned_model.pb\" (0.832 MiB)\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "pruned_loss, pruned_accuracy = pruned_model.evaluate(X_test, y_test, verbose=0)\n",
    "pruned_time = time.time() - start\n",
    "tf.keras.models.save_model(pruned_model, 'pruned_model.pb', include_optimizer=False)\n",
    "pruned_size = model_size(\"pruned_model.pb\")\n",
    "\n",
    "print(f'Saved pruned model to: \"pruned_model.pb\" ({pruned_size:.4} MiB)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044461a8",
   "metadata": {},
   "source": [
    "De hecho, vamos a compararlos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36fa79eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base loss:   0.1456; base accuracy:   0.957; model size: 0.153; inference time: 0.5205\n",
      "Pruned loss: 0.2011; pruned accuracy: 0.9394; model size: 0.832; inference time: 0.372\n"
     ]
    }
   ],
   "source": [
    "print(f'Base loss:   {base_loss:.4}; base accuracy:   {base_acc:.4}; model size: {base_size:.4}; inference time: {base_time:.4}')\n",
    "print(f'Pruned loss: {pruned_loss:.4}; pruned accuracy: {pruned_accuracy:.4}; model size: {pruned_size:.4}; inference time: {pruned_time:.4}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4755d441",
   "metadata": {},
   "source": [
    "En cuestion de espacio no sale muy bien parado. Esto es debido porque el modelo contiene información de parámetros que controlan las ramas a podar (en forma de _floats_ de 32 bits o 64 bits, dependiendo de donde se esté ejecutando). La _cuantización_, entre otras cosas, se encargará de comprimir al máximo estas ramas.\n",
    "\n",
    "En cuestión de tiempo, sin embargo, parece que ha mejorado algo. No es para tirar cohetes, pero algo es algo. Sigamos adelante."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc60438",
   "metadata": {},
   "source": [
    "## Cuantización"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44000d72",
   "metadata": {},
   "source": [
    "El primer paso para la cuantización es habilitar el entrenamiento para ella, similar a lo que hacíamos con la poda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42fbf923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "quantize_layer (QuantizeLaye (None, 28, 28)            3         \n",
      "_________________________________________________________________\n",
      "quant_reshape (QuantizeWrapp (None, 28, 28, 1)         1         \n",
      "_________________________________________________________________\n",
      "quant_conv2d (QuantizeWrappe (None, 26, 26, 4)         51        \n",
      "_________________________________________________________________\n",
      "quant_max_pooling2d (Quantiz (None, 13, 13, 4)         1         \n",
      "_________________________________________________________________\n",
      "quant_conv2d_1 (QuantizeWrap (None, 11, 11, 8)         315       \n",
      "_________________________________________________________________\n",
      "quant_max_pooling2d_1 (Quant (None, 5, 5, 8)           1         \n",
      "_________________________________________________________________\n",
      "quant_conv2d_2 (QuantizeWrap (None, 3, 3, 16)          1203      \n",
      "_________________________________________________________________\n",
      "quant_max_pooling2d_2 (Quant (None, 1, 1, 16)          1         \n",
      "_________________________________________________________________\n",
      "quant_flatten (QuantizeWrapp (None, 16)                1         \n",
      "_________________________________________________________________\n",
      "quant_dense (QuantizeWrapper (None, 10)                175       \n",
      "=================================================================\n",
      "Total params: 1,752\n",
      "Trainable params: 1,674\n",
      "Non-trainable params: 78\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.9961 - accuracy: 0.6871\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.3390 - accuracy: 0.8988\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.2567 - accuracy: 0.9212\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.2204 - accuracy: 0.9316\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.1975 - accuracy: 0.9389\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.1818 - accuracy: 0.9443\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.1680 - accuracy: 0.9487\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.1610 - accuracy: 0.9499\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.1522 - accuracy: 0.9533\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.1462 - accuracy: 0.9554\n"
     ]
    }
   ],
   "source": [
    "quantized_model = tf.keras.models.load_model('base_model.pb')\n",
    "quantized_model = tfmot.quantization.keras.quantize_model(quantized_model)\n",
    "\n",
    "quantized_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "quantized_model.summary()\n",
    "\n",
    "quantized_model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe479a5",
   "metadata": {},
   "source": [
    "Y ahora, cogemos los valores para comparar con los anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fbf0915d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as reshape_layer_call_fn, reshape_layer_call_and_return_conditional_losses, conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: quantized_model.pb/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: quantized_model.pb/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved quantized model to: \"quantized_model.pb\" (0.4978 MiB)\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "quantized_loss, quantized_accuracy = quantized_model.evaluate(X_test, y_test, verbose=0)\n",
    "quantized_time = time.time() - start\n",
    "tf.keras.models.save_model(quantized_model, 'quantized_model.pb', include_optimizer=False)\n",
    "quantized_size = model_size(\"quantized_model.pb\")\n",
    "\n",
    "print(f'Saved quantized model to: \"quantized_model.pb\" ({quantized_size:.4} MiB)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1996d46",
   "metadata": {},
   "source": [
    "Vamos a comparar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c8ce4fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base:      loss: 0.1456; accuracy:   0.957; size: 0.153; time: 0.5205\n",
      "Pruned:    loss: 0.2011; accuracy: 0.9394; size: 0.832; time: 0.372\n",
      "Quantized: loss: 0.1302; accuracy: 0.9631; size: 0.4978; time: 0.4859\n"
     ]
    }
   ],
   "source": [
    "print(f'Base:      loss: {base_loss:.4}; accuracy:   {base_acc:.4}; size: {base_size:.4}; time: {base_time:.4}')\n",
    "print(f'Pruned:    loss: {pruned_loss:.4}; accuracy: {pruned_accuracy:.4}; size: {pruned_size:.4}; time: {pruned_time:.4}')\n",
    "print(f'Quantized: loss: {quantized_loss:.4}; accuracy: {quantized_accuracy:.4}; size: {quantized_size:.4}; time: {quantized_time:.4}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4772e8",
   "metadata": {},
   "source": [
    "Ha reducido del tamaño, y si bien es algo más lento que el podado, no deja de ser mejor que un modelo normal sin optimizar. Además, este es el paso previo a optimizaciones de cuantización de verdad, porque aún no hemos cuantizado como tal (por ejemplo, los pesos siguen siendo de 32 bits o de 64 bits). Nosotros nos limitaremos a la optimización por defecto para la exportación a [TensorFlow Lite](https://www.tensorflow.org/lite), pero en la guía [_Quantization aware training comprehensive guide_](https://www.tensorflow.org/model_optimization/guide/quantization/training_comprehensive_guide) se exponen difeerntes métodos de optimización según plataformas objetivo.\n",
    "\n",
    "Por cierto, para cargar modelos entrenados para cuantización, es necesario hacerlo dentro del contexto `quantize_scope`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c380f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "with tfmot.quantization.keras.quantize_scope():\n",
    "    quantized_model = tf.keras.models.load_model(\"quantized_model.pb\")\n",
    "    quantized_model.compile(\n",
    "        optimizer='adam',\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=['accuracy']\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fedf9ca",
   "metadata": {},
   "source": [
    "### Cuantización por defecto del modelo base\n",
    "\n",
    "En este paso usaremos el convertidos a modelos de TensorFlow Lite. De esta manera conseguiremos unos modelos a priori más rápidos y compactos, aunque con cierta pérdida en la exactitud de las predicciones.\n",
    "\n",
    "En este caso nos centraremos únicamente en el espacio ocupado, ya que el trabajo con estos modelos es más tedioso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7993dfc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmptanac92u/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmptanac92u/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model size:      0.153\n",
      "Pruned model size:    0.832\n",
      "Quantized model size: 0.4978\n",
      "TFLite model size:    0.00769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-31 22:27:06.421257: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:351] Ignored output_format.\n",
      "2021-10-31 22:27:06.421275: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:354] Ignored drop_control_dependency.\n"
     ]
    }
   ],
   "source": [
    "tflite_model = tf.keras.models.load_model('model.pb')\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(tflite_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tf_lite_model = converter.convert()\n",
    "with open('tf_lite_model.pb', 'wb') as f:\n",
    "    f.write(tf_lite_model)\n",
    "tflite_size = model_size('tf_lite_model.pb')\n",
    "\n",
    "print(f'Base model size:      {base_size:.4}')\n",
    "print(f'Pruned model size:    {pruned_size:.4}')\n",
    "print(f'Quantized model size: {quantized_size:.4}')\n",
    "print(f'TFLite model size:    {tflite_size:.4}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850e95c8",
   "metadata": {},
   "source": [
    "### Cuantización por defecto en modelos marcados para cuantización\n",
    "\n",
    "Por último, al igual que antes, veamos en este caso los tamaños involucrados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2adb738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Found untraced functions such as reshape_layer_call_fn, reshape_layer_call_and_return_conditional_losses, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpd5d050w9/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpd5d050w9/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model size:             0.153\n",
      "Pruned model size:           0.832\n",
      "Quantized model size:        0.4978\n",
      "TFLite model size:           0.00769\n",
      "Quantized TFLite model size: 0.009331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-31 22:27:07.593395: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:351] Ignored output_format.\n",
      "2021-10-31 22:27:07.593416: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:354] Ignored drop_control_dependency.\n"
     ]
    }
   ],
   "source": [
    "q_tflite_model = tf.keras.models.load_model('quantized_model.pb')\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(q_tflite_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "q_tflite_model = converter.convert()\n",
    "with open('q_tflite_model.pb', 'wb') as f:\n",
    "    f.write(q_tflite_model)\n",
    "q_tflite_size = model_size('q_tflite_model.pb')\n",
    "\n",
    "print(f'Base model size:             {base_size:.4}')\n",
    "print(f'Pruned model size:           {pruned_size:.4}')\n",
    "print(f'Quantized model size:        {quantized_size:.4}')\n",
    "print(f'TFLite model size:           {tflite_size:.4}')\n",
    "print(f'Quantized TFLite model size: {q_tflite_size:.4}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
