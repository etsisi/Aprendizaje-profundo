{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div><img style=\"float: right; width: 120px; vertical-align:middle\" src=\"https://www.upm.es/sfs/Rectorado/Gabinete%20del%20Rector/Logos/EU_Informatica/ETSI%20SIST_INFORM_COLOR.png\" alt=\"ETSISI logo\" />\n",
    "\n",
    "# A ver si nos hacemos ricos<a id=\"top\"></a>\n",
    "\n",
    "<i>Última actualización: 2024-03-07</small></i></div>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Vamos a explorar el comportamiento de una red recurrente en el problema de predicción bursátil. Se trata de un problema muy difícil de resolver por varias razones.\n",
    "\n",
    "En primer lugar, el mercado de valores es un sistema **altamente complejo** y dinámico, en el que multitud de factores pueden influir en los precios de las acciones. Estos factores incluyen las condiciones económicas mundiales, los acontecimientos políticos, los resultados de las empresas y el sentimiento de los inversores, entre otros. Por lo tanto, es difícil captar y modelizar todas estas complejas relaciones utilizando una única arquitectura RNN.\n",
    "\n",
    "En segundo lugar, el mercado de valores se caracteriza por **patrones no estacionarios y no lineales**, en los que las relaciones entre entradas y salidas pueden cambiar con el tiempo. Las RNN son particularmente adecuadas para modelizar datos de series temporales, pero pueden tener dificultades para captar patrones no lineales y no estacionarios, especialmente en horizontes temporales largos.\n",
    "\n",
    "En tercer lugar, el mercado bursátil **está sujeto a acontecimientos impredecibles** que pueden tener un impacto significativo en los precios de las acciones. Por ejemplo, las noticias inesperadas o los cambios repentinos en la confianza del mercado pueden provocar cambios importantes y rápidos en los precios de las acciones que pueden ser difíciles de predecir utilizando únicamente datos históricos.\n",
    "\n",
    "Por último, el mercado bursátil es un entorno altamente competitivo, en el que inversores y operadores utilizan diversas técnicas sofisticadas para obtener una ventaja en el mercado. Esto significa que cualquier modelo de predicción debe ser capaz de superar al mercado para ser útil, lo cual es una tarea difícil."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crearemos un modelo de regresión para intentar predecir el valor de cierre que tendrán las acciones de Google (<https://es.finance.yahoo.com/quote/goog/>)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliotecas y configuración"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A continuación importaremos las bibliotecas que se utilizarán a lo largo del cuaderno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También configuraremos algunos parámetros para adaptar la presentación gráfica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams.update({'figure.figsize': (20, 6),'figure.dpi': 64})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descarga y preprocesamiento de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empezaremos cargando los datos del conjunto de datos de acciones de Google. Para ello tomaremos los datos históricos de la empresa de los últimos 5 años."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CODE = 'GOOG'\n",
    "BASE_URL = f'https://query1.finance.yahoo.com/v7/finance/download/{CODE}'\n",
    "# Interval\n",
    "today = datetime.datetime.now()\n",
    "five_years_ago = today - datetime.timedelta(days=365*5)\n",
    "# Timestamps (as integer) for the interval\n",
    "period2 = int(today.timestamp())\n",
    "period1 = int(five_years_ago.timestamp())\n",
    "# Now get the dataframe\n",
    "df = pd.read_csv(\n",
    "    f'{BASE_URL}?period1={period1}&period2={period2}&interval=1d',\n",
    "    index_col='Date',\n",
    "    parse_dates=['Date'],\n",
    "    dtype=np.float32\n",
    ")\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El conjunto de datos que hemos descargado guarda la información del día. Nuestro objetivo será predecir el valor de cierre del día a partir de los datos de la semana pasada, para saber qué tipo de inversión nos conviene.\n",
    "\n",
    "Alimentaremos la red con datos de hace 10 días para ver si la memoria sobre cómo evolucionan los valores se traduce en una mejor predicción. Para ello, empezaremos creando 95 nuevas columnas con el contenido de las columnas en cada paso temporal consecutivo.\n",
    "\n",
    "Nótese que primero debemos ordenar el conjunto en orden ascendente para asegurarnos de que tenemos los días correctamente colocados. En segundo lugar, la primera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQUENCE_LEN = 10\n",
    "\n",
    "df.sort_index(inplace=True)\n",
    "columns = df.columns\n",
    "for i in range(1, SEQUENCE_LEN):\n",
    "    for column in columns:\n",
    "        df[f'{column} t-{i}'] = df[column].shift(i)\n",
    "df.drop(df.head(SEQUENCE_LEN - 1).index, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continuaremos creando una nueva columna llamada `Y` con los valores de la columna `Close/Last` de una semana más tarde. Al igual que antes, las últimas 7 filas del conjunto de datos no nos servirán de nada, ya que no podemos ver el futuro, por lo que las eliminaremos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAYS_IN_FUTURE = 7\n",
    "\n",
    "df['Y'] = df['Close'].shift(-DAYS_IN_FUTURE)\n",
    "df.drop(df.tail(DAYS_IN_FUTURE).index, inplace=True)\n",
    "\n",
    "# Plot the dataset \n",
    "df[[c for c in df.columns if c in ('Close', 'Y')]].tail(DAYS_IN_FUTURE + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a extraer un conjunto de prueba para comprobar el comportamiento de nuestro modelo. Este estará compuesto por los últimos 100 días del _dataset_. Estos datos serán normalizados entre 0 y 1 con los normalizadores que hemos creado, y ya que estamos aprovecharemos y generaremos los datos de entrada y salida.\n",
    "\n",
    "Una nota; Para las redes recurrentes se espera que la entrada sea tridimensional, pero nuestro conjunto de datos es bidimensional. Tenemos que transformarlo a tridimensional, manteniendo la última dimensión de tamaño 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SIZE = 100\n",
    "\n",
    "train_df, test_df = df.iloc[:-TEST_SIZE,:], df.iloc[-TEST_SIZE:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Ahora normalizaremos los valores entre 0 y 1 para que el impacto de las entradas sea similar y no haya ninguna que destaque. Para ello haremos uso de la clase `MinMaxScaler`, que además de normalizar, mantiene el estado para que también podamos usarlo como mecanismo de desnormalización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "input_scaler.fit(train_df.iloc[:,:-1])\n",
    "output_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "output_scaler.fit(train_df.iloc[:,-1:]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nótese que al normalizar, hemos normalizado sólo con el conjunto de entrenamiento. La idea subyacente es que el conjunto de prueba debe ser desconocido no sólo al crear el modelo, sino también al trabajar con los datos.\n",
    "\n",
    "Ahora, vamos a ver en una gráfica a qué valores se corresponden estos conjuntos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = train_df.iloc[:,:-1], train_df.iloc[:,-1:]\n",
    "x_test, y_test = test_df.iloc[:,:-1], test_df.iloc[:,-1:]\n",
    "\n",
    "plt.plot(y_train, color='green', label='Train')\n",
    "plt.plot(y_test, color='red', label='Test')\n",
    "plt.title('GOOG Stock Price Datset')\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('GOOG Stock Price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will transform the data from the training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = input_scaler.transform(x_train)\n",
    "x_test = input_scaler.transform(x_test)\n",
    "y_train = output_scaler.transform(y_train)\n",
    "\n",
    "x_train = np.reshape(x_train, (\n",
    "    x_train.shape[0],                 # Examples\n",
    "    SEQUENCE_LEN,                     # Number of timesteps\n",
    "    x_train.shape[1] // SEQUENCE_LEN  # Number of components each sequence element\n",
    "))\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], SEQUENCE_LEN, x_test.shape[1] // SEQUENCE_LEN))\n",
    "\n",
    "print(f'Dataset shape:      {df.shape}')\n",
    "print(f'Training: X shape = {x_train.shape}; Y shape = {y_train.shape}')\n",
    "print(f'Test:     X shape = {x_test.shape}; Y shape = {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementando y entrenando nuestro modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Crearemos un modelo recurrente que, a partir de los datos de entrada (los datos bursátiles de un día determinado) sea capaz de inferir el valor de cierre del valor siete días después. Para ello, utilizaremos una unidad neuronal recurrente simple `SimpleRNN`.\n",
    "\n",
    "En concreto, la red que crearemos estará compuesta por dos capas de unidades recurrentes de 128 parámetros con una capa de abandono después de cada una de ellas, de la siguiente manera:\n",
    "\n",
    "`Input`->`SimpleRNN`->`Dropout`->`SimpleRnn`->`Dropout`->`Output`.\n",
    "\n",
    "Recuerda que cuando las unidades recurrentes se apilan unas sobre otras debemos utilizar el parámetro `return_sequences` para que se conecten a la secuencia completa, de lo contrario dará error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.SimpleRNN(128, return_sequences=True, input_shape=(10, 6)),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.SimpleRNN(128),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam', metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Ahora entrenaremos el modelo, a ver qué tal se comporta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['root_mean_squared_error'])\n",
    "plt.ylabel('rmse')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No sólo no ha ido mal, ¡ha ido genial! Igual hasta nos hacemos ricos y todo..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluando el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente vamos a predecir para el conjunto de test los valores de las acciones para luego compararlos con los valores de verdad.\n",
    "\n",
    "Una nota: los datos del test vienen con un índice de fecha (es un `Series` de pandas) mientras que la predicción viene como un array de `NumPy`. Hay que conseguir que ambos índices coincidan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = model.predict(x_test)\n",
    "# Denormalize the output\n",
    "predicted = output_scaler.inverse_transform(predicted)\n",
    "\n",
    "plt.plot(y_test.to_numpy(), label = 'Real')\n",
    "plt.plot(predicted, label = 'Predicted')\n",
    "plt.title('GOOG Stock Price Prediction')\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('GOOG Stock Price')\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A la vista de los resultados, parece que está ocurriendo algo extraño... ¿Vamos a hacernos ricos o no? ¿Se te ocurre alguna explicación para esta curiosa predicción? ¿A alguien se le ocurre una alternativa?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hemos visto cómo implementar redes neuronales recurrentes en un problema de series temporales puras. También hemos visto que no se comporta demasiado bien, pero no tiene por qué ser así (en este caso hay truco).\n",
    "\n",
    "Las series temporales mantienen correlaciones entre elementos consecutivos, y esas relaciones son las que aprenden las redes. Cuanto mayor sea la correlación (absoluta) entre elementos, más probabilidades tendrá la red de adivinarla. Sin embargo, las sucesiones de elementos valorados aleatoriamente (que no tienen nada que ver entre sí) no son problemas que puedan resolverse con este tipo de redes. Ni siquiera son series temporales por definición."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "<div><img style=\"float: right; width: 120px; vertical-align:top\" src=\"https://mirrors.creativecommons.org/presskit/buttons/88x31/png/by-nc-sa.png\" alt=\"Creative Commons by-nc-sa logo\" />\n",
    "\n",
    "[Volver al inicio](#top)\n",
    "\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
